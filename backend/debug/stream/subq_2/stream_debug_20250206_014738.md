# Stream Debug - 20250206_014738

# Original Question
```
How does uncertain analysis work?
```

# Context Content
```markdown
# Search Results for: How does uncertain analysis work?

Keywords: None


## Context

### Summary
**In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.**

### Header
**8.1 Introduction**

### Content
When run in “predictive analysis” mode, PEST solves the constrained predictive maximisation/minimisation problem described in section 8.4 of Doherty (2015). In solving this problem PEST evaluates the maximum or minimum value that a model prediction can take while other model outputs are such that the calibration objective function is maintained at or below a user-specified value. In doing so it evaluates the post-calibration uncertainty range of the prediction. Optionally, the prediction can be accompanied by “predictive noise”. Of course, there is no reason why the prediction cannot actually be a model parameter; the post-calibration uncertainty of any parameter can thereby be explored.
The constrained maximisation/minimisation process undertaken by PEST when it is run in “predictive analysis” mode must be undertaken following a calibration process wherein an objective function is minimised. The objective function constraint imposed during the predictive maximisation/minimisation process will be somewhat greater than the minimised objective function. Theoretically, the value of the constraining objective function can be related to a predictive confidence limit using equations provided in Doherty (2015) and derived by Cooley and Vecchia (1987), Vecchia and Cooley (1987) and Christensen and Cooley (1999). In practice, however, the constraining objective function will probably be determined subjectively, as the statistics of model-to-measurement misfit will rarely be known, given the fact that in most modelling contexts it is model imperfections, rather than measurement noise, which dictates the level of fit that can be achieved between field measurements and their model-generated counterparts.
In practical terms, predictive maximisation/minimisation as a means of exploring post-calibration predictive uncertainty works well where parameters are relatively few in number and where estimation of those parameters constitutes a well-posed inverse problem. If the inverse problem of model calibration is not well-posed, then prior information which encapsulates pre-calibration expected parameter values (or linear/nonlinear relationships between expected parameter values) must form a component of the calibration dataset to make it so; such prior information may need to be accompanied by a prior covariance matrix if full expression is to be given to expert knowledge. Given the manual regularisation required for formulation of a well-posed, or almost well-posed, inverse problem, determination of the relative weighting between expert-knowledge-based prior information on the one hand and measurements of system state on the other hand then becomes a problem.
Experience demonstrates that the numerical performance of the constrained maximisation/minimisation process can be delicate. The integrity of finite-difference derivatives must be high for the process to work well – higher than it needs to be for successful minimisation of an objective function. Model numerical performance must therefore be good. While some protection against poor numerical performance can be gained through undertaking a line search in conjunction with Marquardt-lambda-based parameter upgrade testing (see below), the line search procedure is inherently serial, and hence cannot be parallelised. This limits the run times of models with which PEST can be used when undertaking predictive uncertainty analysis in this way.
The PEST suite provides other options for undertaking post-calibration predictive uncertainty.
analysis, these including linear analysis, calibration-constrained Monte Carlo analysis (of which null space Monte Carlo is an example), and its Pareto functionality. All of these can work well in highly parameterized contexts where the constrained maximisation/minimisation process which PEST undertakes when run in “predictive analysis” mode may fail. Nevertheless, this mode of operation has proven itself useful in many real-world modelling contexts, and will continue to do so in the future, provided its strengths and weaknesses are properly understood.
This chapter describes how to use PEST in “predictive analysis” mode. Concepts and theory are fully described in section 8.4 of Doherty (2015).

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** An optional "sensitivity reuse" section (Figure 7.1, before "parameter groups," after SVD/LSQR sections) controls sensitivity reuse (activated by DOSENREUSE="senreuse").  SENRELTHRESH sets the relative sensitivity threshold for reuse. SENMAXREUSE sets the maximum number of parameters for reuse. SENALLCALCINT sets the interval for recalculating all sensitivities. SENPREDWEIGHT weights prediction sensitivities in "predictive analysis" mode. SENPIEXCLUDE excludes prior information from sensitivity calculations.
- **Next Summary:** In "predictive analysis" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior "estimation" run (Φmin). The prediction is in the "predict" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding "estimation" run.

### Metadata
- **Keywords:** 
- **Chunk ID:** c55285164f60
- **Chunk Index:** 1
- **Previous Chunk ID:** 17462e455db6
- **Next Chunk ID:** d8284352aeb8

---

## Context

### Summary
**In "predictive analysis" mode (see Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while keeping the objective function below a threshold (Φ0, slightly above minimum Φmin). This method is suitable for well-behaved models with few parameters; otherwise, other methods are recommended.**

### Header
**3.3.4 Predictive Analysis Mode**

### Content
When PEST is run in “predictive analysis” mode it solves a constrained maximisation/minimisation problem in which a prediction of interest is maximised or minimised subject to the constraint that the objective function rises no higher than a user-specified level. Theory on which this mode of PEST’s operation is based was derived by Cooley and Vecchia (1987) and Vecchia and Cooley (1987), and is described in detail in section 8.4 of Doherty (2015).
Use of PEST in “predictive analysis” mode should follow solution of a well posed, or only slightly ill-posed, inverse problem in which a model has been calibrated through reduction of an appropriate objective function to its minimum. Let us denote this minimised objective function as Φmin. Let Φ0 denote an objective function that is slightly higher than Φmin at which the model is deemed to be “uncalibrated” at a certain level of confidence. Let model output read by PEST that is actually a prediction, and is hence unused by the calibration process. The range of post-calibration uncertainty of this prediction can be determined through solution of two constrained optimisation problems in which the prediction is maximised, and then minimized, subject to the constraint that the objective.
This means of assessing predictive uncertainty can work well where a model does not have too many parameters, and where it is numerically well-behaved so that finite-difference-based derivatives of model outputs with respect to parameters have a high degree of integrity. If these conditions are not met then other methods of predictive uncertainty assessment should be pursued; these can include linear methods, null space Monte Carlo, and PEST’s “pareto” mode.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 3. What PEST Does
- **Subsection:** 3.3 Modes of Operation

### Additional Summaries
- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.
- **Detailed Summary:** PEST is a tool that iteratively solves inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses Jacobian matrices and Marquardt lambda for parameter estimation. Different methods are employed based on problem types, with options for uncertainty analysis and parallel processing to reduce computational costs.

### Related Context
- **Previous Summary:** PEST's "regularisation" mode uses Tikhonov regularization (see Doherty 2015), employing measurement and regularization objective functions.  A parameter covariance matrix is not recorded; however, posterior uncertainties are investigated using utilities like PREDUNC7.
- **Next Summary:** In "pareto" mode, PEST explores the trade-off between objective functions (e.g., measurement vs. regularization, or data fit vs. prediction proximity).  This allows assessment of fit quality and hypothesis testing regarding predictions (see Doherty 2015, section 8.5).  Parallel processing and SVD-assist mitigate computational costs.  Linear uncertainty analysis is possible using PEST utilities.

### Metadata
- **Keywords:** 
- **Chunk ID:** 2e473251b7f2
- **Chunk Index:** 1
- **Previous Chunk ID:** 2c26d6d34bff
- **Next Chunk ID:** 753954871395

---

## Context

### Summary
**In "predictive analysis" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior "estimation" run (Φmin). The prediction is in the "predict" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding "estimation" run.**

### Header
**8.2 Predictive Analysis Mode**

### Content
As was discussed earlier in this manual, PEST can run in four different modes – “estimation”, “regularisation”, “pareto” and “predictive analysis” modes. A PEST run in “predictive analysis” mode is designed to follow a run in “estimation” mode wherein PEST minimises an objective function.
Let Φmin designate the value of the minimised objective function as calculated during its previous “estimation” run. PEST’s task when run in “predictive analysis” mode is to find the point identified in figure 8.2 of Doherty (2015). This is a point lying on a contour along which the objective function is Φ0 and at which a prediction of interest has its maximum or minimum value along that contour. This point is referred to as the “critical point” in the discussion that follows. PEST finds the parameters which correspond to this point, and the value of the prediction which corresponds to this point. Φ, of course, must be greater than 0 Φmin. Often it is not much greater than Φmin and can thus be designated as being equal to Φmin + δ where δ is a small number. The means through which a suitable value can be assigned to Φ0 has been mentioned above and will be discussed in greater detail below.
If PEST runs in “predictive analysis” mode, then a particular model output must be identified as “the prediction” of interest. Of course, all model outputs (and parameters) that were employed in the previous “estimation” run must also be included in the PEST dataset for the “predictive analysis” run, as the objective function must be calculable just as before. However the model may need to be expanded to include the predictive output of interest. Also, it may need to be run into the future. Perhaps two versions of the model will need to be encapsulated in a single batch or script file which PEST runs through a system call; one of these may pertain to calibration conditions while the other may be run into the future to calculate the model output which must be maximised or minimised subject to an objective function constraint of Φ0.
The predictive model output must be read like any other model output which is of interest to PEST. An instruction must be provided in an instruction file. The model output must be classified as an “observation”. However it must be assigned to an observation group named “predict”. Furthermore it must be the sole member of that observation group. This is how PEST recognizes the model output that it must maximise or minimise subject to calibration constraints. It is important to note that PEST takes no notice of the “observed value” of this observation; depending on the setting of control variables discussed below, it may or may not take notice of the weight assigned to this observation. PEST’s job is to maximise or minimise the model output corresponding to this observation, while maintaining the objective function at or below Φmin + δ, i.e. at or below Φ0.
Though ostensibly different, PEST’s operation in “predictive analysis” mode has much in
common with its operation in “estimation” mode. In fact, the underlying mathematics is very similar; see Doherty (2015). Like parameter estimation, the process required to determine the critical point is an iterative one, beginning at some user-supplied initial parameter set. Initial parameters can be either inside the 0 preceding parameter estimation process. If they are initial values that were used for the contour or outside of it; in fact they can be the same outside of the 0 contour, PEST automatically works in “estimation” mode until it is “within reach” of 0, at which stage it modifies its operations to search for the critical point. It is normally good practice, however, for “predictive analysis” mode initial values to be the same as those determined through the previous “estimation” mode PEST run, and hence correspond to min.
When run in “predictive analysis” mode PEST still needs to calculate a Jacobian matrix, so derivatives of model outcomes with respect to adjustable parameters are still required. Derivatives can be calculated using two, three or five points; PEST can switch from one to the other as the solution process progresses. Parameters must still be assigned to groups for the purpose of assigning variables which govern derivatives calculation. Parameters can be bounded, log-transformed, linked to one another, or fixed in “predictive analysis” mode just as in “estimation” mode. In fact parameter bounds, transformations and linkages must be the same for a predictive analysis run as they were for the preceding parameter estimation run in which min was determined, for the value supplied to PEST for 0 must be consistent with the previously determined value of min.
Just as in “estimation” mode, a Marquardt lambda is used to assist PEST in coping with model nonlinearities when it is run in “predictive analysis” mode; this lambda is adjusted by PEST as the optimisation process progresses. The same user-supplied control variables affect PEST’s lambda adjustment procedure as when it is used in “estimation” mode (plus a couple more – see below). However, if desired, a line search procedure along the direction of the parameter upgrade vector can be used to improve calculation of the maximum or minimum model prediction for any value of the Marquardt lambda. This, in fact, is the recommended procedure.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.
- **Next Summary:** In "predictive analysis" mode, PEST maximizes/minimizes a prediction (in the "predict" group) while keeping the objective function ≤ Φ0 (requires a prior "estimation" run).  It uses the same parameters, transformations, and observations as the estimation run.  Restarting uses `/r`, `/j`, `/d`, or `/s` (parallel runs).  Change limits remain important.  Screen output shows prediction values per iteration.  Results include the optimal prediction and parameter values.

### Metadata
- **Keywords:** 
- **Chunk ID:** d8284352aeb8
- **Chunk Index:** 1
- **Previous Chunk ID:** c55285164f60
- **Next Chunk ID:** b94b8e2d6ccd

---

## Context

### Summary
**GENLINPRED selects between two predictive uncertainty equations (Doherty 2015, Equations 7.4.1 and 7.4.2) based on the number of parameters and observations in the PEST control file.  High parameter/observation numbers may cause slow runtimes or numerical errors; contact the author if errors such as negative uncertainties or parameter contributions occur.**

### Header
**10.17.11 PREDUNC Uncertainty Formulation**

### Content
As documented in descriptions of PREDUNC1, PREDUNC4 and PREDUNC5, these programs provide two different options for computation of predictive uncertainty and of quantities which depend on this. One of these options is better used where parameter numbers
are small while the other is more efficient where observation numbers are small. GENLINPRED chooses the “efficient if low parameter numbers” option if the number of adjustable parameters in the PEST control file is less than the number of adjustable observations, and chooses the “efficient if low observation numbers” option otherwise. Nevertheless where both observation and parameter numbers are high, the run times associated with PREDUNC‑suite programs, and hence with GENLINPRED, may be high. Furthermore, there may be some occasions where use of one of these equations (particularly the low observation number option) can induce numerical errors due to the large number of matrix operations involved. Contact me if GENLINPRED computes obviously erroneous quantities such as negative uncertainties and negative parameter contributions to predictive uncertainty and I will alter GENLINPRED’s internal settings to alter its choice of equation.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 10. Linear Error and Uncertainty – Part I
- **Subsection:** 10.17 GENLINPRED

### Additional Summaries
- **Higher-Level Summary:** SVD-assist optimizes inversions by estimating "super parameters" instead of native parameters, reducing computational cost. Use standard procedures, PEST, and SVDAPREP for optimal results. Create a base PEST control file, run PEST to generate a Jacobian matrix, and use PARCALC and PICALC for parameter translation and prior information calculation.
- **Detailed Summary:** GENLINPRED automates parameter and prediction uncertainty analyses using various programs. It simplifies the process for users, compiling results into a single output file. It calculates parameter group contributions to prediction error and uncertainty, selecting predictive uncertainty equations based on parameters and observations in the PEST control file. The tool offers prompts for input and analysis options, with the ability to customize settings for improved performance and accuracy.

### Related Context
- **Previous Summary:** GENLINPRED calculates parameter group contributions to prediction error/uncertainty (using PREDVAR4/PREDUNC4).  Bar charts show pre- and post-calibration contributions. Post-calibration contributions may exceed pre-calibration contributions due to calibration-induced parameter correlation;  this is further discussed below.
- **Next Summary:** For additional analyses or to correct numerical errors, run PREDVAR and PREDUNC suite programs individually; GENLINPRED's automation may be less efficient computationally but simpler for the user.  Running SCALEPAR before PREDUNC programs is unnecessary.

### Metadata
- **Keywords:** 
- **Chunk ID:** f79f5df3f074
- **Chunk Index:** 1
- **Previous Chunk ID:** d2684bb2d53b
- **Next Chunk ID:** 321b4ef6ab4c

---

## Context

### Summary
**PESTPP-OPT solves constrained optimization problems considering uncertainties in model outputs (chance constraints).  Constraints are applied to predictive values adjusted for uncertainty (often pessimistically), using a calibrated model (minimized error variance, Doherty 2015) where model outputs are near the center of their posterior distributions.  Model parameter uncertainty stems from prior uncertainty and calibration data.**

### Header
**8.1.2 Overview**

### Content
Sustainable management of a natural system often requires that an optimization problem be solved. Something must be maximized or minimized through adjustment of so-called “decision variables”, subject to certain constraints. For example, it may be desirable to maximize the amount of water extracted from a number of wells (where pumping rates are the decision variables), subject to the constraints that flow in an adjacent stream does not fall below a specified rate, and that groundwater levels in certain observation wells are maintained above certain levels. Design of a contaminant remediation system may attempt to ensure that the cost of water extraction and treatment is minimized subject to the constraint that the contaminant is captured; pumping and injection rates, and the locations of pumping and injection wells, comprise the decision variables in this example.
Models are used to predict the response of a natural system to natural and management-imposed stresses. Where management is optimized, some of the quantities which the model calculates comprise system behaviour on which constraints must be imposed. These outputs are normally uncertain, reflecting the fact that the model’s parameters are uncertain. (Model outputs to which constraints are applied have this in common with any other predictions made by a model.) The question then arises as to whether imposition of constraints should take account of these uncertainties. Where violation of a constraint can result in an unacceptable cost, the answer to that question is obvious: respect for valuable societal and/or environmental assets requires that model-calculated quantities to which constraints are applied be adjusted to include the range of possibilities that are compatible with the range of reasonable parameters that a model can employ. For example, in the stream flow example discussed above, exercise of the precautionary principle may dictate that the constraint be applied to the lowest streamflow that would be calculated by the model if it were parameterized with the most pessimistic set of parameters (with respect to that particular model output) that are compatible with expert knowledge on the one hand, and the necessity to fit the model calibration dataset on the other hand.
In most environmental modelling contexts, a model is calibrated before it is deployed. As is described by Doherty (2015), if properly undertaken, the calibration process yields a parameter field of minimized error variance. This is its “passport to uniqueness”. The parameter field is not correct; its potential for wrongness (which may be large) is merely minimized. Any prediction that the model makes inherits this status. That is, the prediction is not correct; however, its potential for wrongness has been minimized. Hence a prediction made by a calibrated model lies somewhere near the centre of the posterior probability distribution of that prediction. The same concept can be extended to model outputs that describe environmental behaviour to which constraints must be applied.
If uncertainty is to be taken into account in imposition of an optimization constraint, the width of the probability distribution associated with the model output to which the constraint is applied must be calculated so that the constraint can be applied to a predictive value that is adjusted in order to accommodate its uncertainty. Often (but not always – see below) it will be adjusted towards the pessimistic end of its probability range.
PESTPP-OPT not only solves a constrained optimization problem. It solves a constrained optimization problem that accommodates uncertainties in model outputs to which constraints are applied. These are often referred to as “chance constraints”. In applying chance constraints, PESTPP-OPT assumes that model predictive uncertainty is an outcome of model parameter uncertainty. The latter is, in turn, an outcome of prior parameter uncertainty (i.e., the uncertainty range that emerges from the stochastic nature of expert knowledge), and the extent to which this uncertainty is reduced through the model calibration process. Parameter uncertainty reduction is a function of the information content of the calibration dataset, and the extent to which flow of this information is hampered by the presence of noise within that dataset.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.

### Related Context
- **Previous Summary:** PESTPP-OPT (described by White et al. 2018, and Wagner and Gorelick 1987) performs decision optimization under uncertainty using sequential linear programming.  Examples of its use are provided in White et al. (2018).
- **Next Summary:** PESTPP-OPT handles chance constraints via weights (as standard deviations, *opt_std_weights(true)*), linear methods (FOSM, using Jacobian matrices and prior parameter/measurement uncertainties), or stack-based methods.  FOSM uses Equations 8.1a or 8.1b (Doherty 2015) to calculate prediction variance;  Equations 8.2a or 8.2b calculate the posterior parameter covariance matrix; Equation 8.3 calculates output uncertainty variance.  The Jacobian matrix can be user-supplied or calculated by PESTPP-OPT.

### Metadata
- **Keywords:** 
- **Chunk ID:** e05099b5052d
- **Chunk Index:** 1
- **Previous Chunk ID:** 9eb7ce055068
- **Next Chunk ID:** 0a9e459f4e6c

---

```

# System Prompt
```

You are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:

1. **Direct Answer First:**  
   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.
   - Use the following structure:

     **1) Definition**  
     - Provide a concise definition.  
     - Cite source(s) using the format "File: [filename], Section: [header]".

     **2) Possible Values**  
     - Describe valid or recognized values (including defaults if specified).  
     - Cite source(s).

     **3) Implications**  
     - Explain usage considerations or consequences for each value.  
     - If the documentation does not provide this information, state: "Information not available in the provided content. "

     **4) Practical Usage Notes**  
     - Include usage notes or examples only if explicitly provided in the documentation.  
     - Otherwise, state: "No usage notes found in the provided content."

     **5) Keywords**  
     - List any associated keywords as found in the documentation.  
     - If none are provided, state: "No keywords found in the provided content"

     **6) Follow-up References**  
     - Point out additional references or relevant sections from the documentation, if applicable.

2. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.
   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.
   - Each question should reference specific sections from the documentation if available.

3. **Important Instructions:**  
   - **Do not mention internal processes, "chunks," or retrieval steps.**  
   - **Do not include any self-commentary or extra explanations beyond the structure above.**  
   - Use only the documentation provided in `{context}`.

Answer strictly following the structure and rules above.

```

# Full User Message
```

Question: How does uncertain analysis work?

Please provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:

1. **Cite Sources:**  
   - Use the format "File: [filename], Section: [header]" whenever you reference specific details.

2. **Include Examples:**  
   - Provide relevant examples from the documentation if available.

3. **Note Limitations:**  
   - If the documentation is incomplete or ambiguous, explicitly state: "Information not available in the provided content. I don't know."

4. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.
   - **Do not provide answers to these follow-up questions.**
   - Each question should reference specific sections from the documentation if applicable.

5. **Keywords Section:**  
   - Include a "Keywords" section if applicable, listing any associated keywords as found in the documentation.
   - If none are provided, state: "No keywords found in the provided content. I don't know."

6. **Avoid Internal Details:**  
   - Do not mention internal processes, such as "chunks" or retrieval steps.
   - Do not include any self-commentary or extra explanations beyond what is requested.

7. **Be Concise and Accurate:**  
   - Do not invent details or assumptions. If information is missing, state: "Information not available in the provided content. I don't know."

**Available Documentation with Metadata:**
# Search Results for: How does uncertain analysis work?

Keywords: None


## Context

### Summary
**In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.**

### Header
**8.1 Introduction**

### Content
When run in “predictive analysis” mode, PEST solves the constrained predictive maximisation/minimisation problem described in section 8.4 of Doherty (2015). In solving this problem PEST evaluates the maximum or minimum value that a model prediction can take while other model outputs are such that the calibration objective function is maintained at or below a user-specified value. In doing so it evaluates the post-calibration uncertainty range of the prediction. Optionally, the prediction can be accompanied by “predictive noise”. Of course, there is no reason why the prediction cannot actually be a model parameter; the post-calibration uncertainty of any parameter can thereby be explored.
The constrained maximisation/minimisation process undertaken by PEST when it is run in “predictive analysis” mode must be undertaken following a calibration process wherein an objective function is minimised. The objective function constraint imposed during the predictive maximisation/minimisation process will be somewhat greater than the minimised objective function. Theoretically, the value of the constraining objective function can be related to a predictive confidence limit using equations provided in Doherty (2015) and derived by Cooley and Vecchia (1987), Vecchia and Cooley (1987) and Christensen and Cooley (1999). In practice, however, the constraining objective function will probably be determined subjectively, as the statistics of model-to-measurement misfit will rarely be known, given the fact that in most modelling contexts it is model imperfections, rather than measurement noise, which dictates the level of fit that can be achieved between field measurements and their model-generated counterparts.
In practical terms, predictive maximisation/minimisation as a means of exploring post-calibration predictive uncertainty works well where parameters are relatively few in number and where estimation of those parameters constitutes a well-posed inverse problem. If the inverse problem of model calibration is not well-posed, then prior information which encapsulates pre-calibration expected parameter values (or linear/nonlinear relationships between expected parameter values) must form a component of the calibration dataset to make it so; such prior information may need to be accompanied by a prior covariance matrix if full expression is to be given to expert knowledge. Given the manual regularisation required for formulation of a well-posed, or almost well-posed, inverse problem, determination of the relative weighting between expert-knowledge-based prior information on the one hand and measurements of system state on the other hand then becomes a problem.
Experience demonstrates that the numerical performance of the constrained maximisation/minimisation process can be delicate. The integrity of finite-difference derivatives must be high for the process to work well – higher than it needs to be for successful minimisation of an objective function. Model numerical performance must therefore be good. While some protection against poor numerical performance can be gained through undertaking a line search in conjunction with Marquardt-lambda-based parameter upgrade testing (see below), the line search procedure is inherently serial, and hence cannot be parallelised. This limits the run times of models with which PEST can be used when undertaking predictive uncertainty analysis in this way.
The PEST suite provides other options for undertaking post-calibration predictive uncertainty.
analysis, these including linear analysis, calibration-constrained Monte Carlo analysis (of which null space Monte Carlo is an example), and its Pareto functionality. All of these can work well in highly parameterized contexts where the constrained maximisation/minimisation process which PEST undertakes when run in “predictive analysis” mode may fail. Nevertheless, this mode of operation has proven itself useful in many real-world modelling contexts, and will continue to do so in the future, provided its strengths and weaknesses are properly understood.
This chapter describes how to use PEST in “predictive analysis” mode. Concepts and theory are fully described in section 8.4 of Doherty (2015).

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** An optional "sensitivity reuse" section (Figure 7.1, before "parameter groups," after SVD/LSQR sections) controls sensitivity reuse (activated by DOSENREUSE="senreuse").  SENRELTHRESH sets the relative sensitivity threshold for reuse. SENMAXREUSE sets the maximum number of parameters for reuse. SENALLCALCINT sets the interval for recalculating all sensitivities. SENPREDWEIGHT weights prediction sensitivities in "predictive analysis" mode. SENPIEXCLUDE excludes prior information from sensitivity calculations.
- **Next Summary:** In "predictive analysis" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior "estimation" run (Φmin). The prediction is in the "predict" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding "estimation" run.

### Metadata
- **Keywords:** 
- **Chunk ID:** c55285164f60
- **Chunk Index:** 1
- **Previous Chunk ID:** 17462e455db6
- **Next Chunk ID:** d8284352aeb8

---

## Context

### Summary
**In "predictive analysis" mode (see Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while keeping the objective function below a threshold (Φ0, slightly above minimum Φmin). This method is suitable for well-behaved models with few parameters; otherwise, other methods are recommended.**

### Header
**3.3.4 Predictive Analysis Mode**

### Content
When PEST is run in “predictive analysis” mode it solves a constrained maximisation/minimisation problem in which a prediction of interest is maximised or minimised subject to the constraint that the objective function rises no higher than a user-specified level. Theory on which this mode of PEST’s operation is based was derived by Cooley and Vecchia (1987) and Vecchia and Cooley (1987), and is described in detail in section 8.4 of Doherty (2015).
Use of PEST in “predictive analysis” mode should follow solution of a well posed, or only slightly ill-posed, inverse problem in which a model has been calibrated through reduction of an appropriate objective function to its minimum. Let us denote this minimised objective function as Φmin. Let Φ0 denote an objective function that is slightly higher than Φmin at which the model is deemed to be “uncalibrated” at a certain level of confidence. Let model output read by PEST that is actually a prediction, and is hence unused by the calibration process. The range of post-calibration uncertainty of this prediction can be determined through solution of two constrained optimisation problems in which the prediction is maximised, and then minimized, subject to the constraint that the objective.
This means of assessing predictive uncertainty can work well where a model does not have too many parameters, and where it is numerically well-behaved so that finite-difference-based derivatives of model outputs with respect to parameters have a high degree of integrity. If these conditions are not met then other methods of predictive uncertainty assessment should be pursued; these can include linear methods, null space Monte Carlo, and PEST’s “pareto” mode.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 3. What PEST Does
- **Subsection:** 3.3 Modes of Operation

### Additional Summaries
- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.
- **Detailed Summary:** PEST is a tool that iteratively solves inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses Jacobian matrices and Marquardt lambda for parameter estimation. Different methods are employed based on problem types, with options for uncertainty analysis and parallel processing to reduce computational costs.

### Related Context
- **Previous Summary:** PEST's "regularisation" mode uses Tikhonov regularization (see Doherty 2015), employing measurement and regularization objective functions.  A parameter covariance matrix is not recorded; however, posterior uncertainties are investigated using utilities like PREDUNC7.
- **Next Summary:** In "pareto" mode, PEST explores the trade-off between objective functions (e.g., measurement vs. regularization, or data fit vs. prediction proximity).  This allows assessment of fit quality and hypothesis testing regarding predictions (see Doherty 2015, section 8.5).  Parallel processing and SVD-assist mitigate computational costs.  Linear uncertainty analysis is possible using PEST utilities.

### Metadata
- **Keywords:** 
- **Chunk ID:** 2e473251b7f2
- **Chunk Index:** 1
- **Previous Chunk ID:** 2c26d6d34bff
- **Next Chunk ID:** 753954871395

---

## Context

### Summary
**In "predictive analysis" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior "estimation" run (Φmin). The prediction is in the "predict" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding "estimation" run.**

### Header
**8.2 Predictive Analysis Mode**

### Content
As was discussed earlier in this manual, PEST can run in four different modes – “estimation”, “regularisation”, “pareto” and “predictive analysis” modes. A PEST run in “predictive analysis” mode is designed to follow a run in “estimation” mode wherein PEST minimises an objective function.
Let Φmin designate the value of the minimised objective function as calculated during its previous “estimation” run. PEST’s task when run in “predictive analysis” mode is to find the point identified in figure 8.2 of Doherty (2015). This is a point lying on a contour along which the objective function is Φ0 and at which a prediction of interest has its maximum or minimum value along that contour. This point is referred to as the “critical point” in the discussion that follows. PEST finds the parameters which correspond to this point, and the value of the prediction which corresponds to this point. Φ, of course, must be greater than 0 Φmin. Often it is not much greater than Φmin and can thus be designated as being equal to Φmin + δ where δ is a small number. The means through which a suitable value can be assigned to Φ0 has been mentioned above and will be discussed in greater detail below.
If PEST runs in “predictive analysis” mode, then a particular model output must be identified as “the prediction” of interest. Of course, all model outputs (and parameters) that were employed in the previous “estimation” run must also be included in the PEST dataset for the “predictive analysis” run, as the objective function must be calculable just as before. However the model may need to be expanded to include the predictive output of interest. Also, it may need to be run into the future. Perhaps two versions of the model will need to be encapsulated in a single batch or script file which PEST runs through a system call; one of these may pertain to calibration conditions while the other may be run into the future to calculate the model output which must be maximised or minimised subject to an objective function constraint of Φ0.
The predictive model output must be read like any other model output which is of interest to PEST. An instruction must be provided in an instruction file. The model output must be classified as an “observation”. However it must be assigned to an observation group named “predict”. Furthermore it must be the sole member of that observation group. This is how PEST recognizes the model output that it must maximise or minimise subject to calibration constraints. It is important to note that PEST takes no notice of the “observed value” of this observation; depending on the setting of control variables discussed below, it may or may not take notice of the weight assigned to this observation. PEST’s job is to maximise or minimise the model output corresponding to this observation, while maintaining the objective function at or below Φmin + δ, i.e. at or below Φ0.
Though ostensibly different, PEST’s operation in “predictive analysis” mode has much in
common with its operation in “estimation” mode. In fact, the underlying mathematics is very similar; see Doherty (2015). Like parameter estimation, the process required to determine the critical point is an iterative one, beginning at some user-supplied initial parameter set. Initial parameters can be either inside the 0 preceding parameter estimation process. If they are initial values that were used for the contour or outside of it; in fact they can be the same outside of the 0 contour, PEST automatically works in “estimation” mode until it is “within reach” of 0, at which stage it modifies its operations to search for the critical point. It is normally good practice, however, for “predictive analysis” mode initial values to be the same as those determined through the previous “estimation” mode PEST run, and hence correspond to min.
When run in “predictive analysis” mode PEST still needs to calculate a Jacobian matrix, so derivatives of model outcomes with respect to adjustable parameters are still required. Derivatives can be calculated using two, three or five points; PEST can switch from one to the other as the solution process progresses. Parameters must still be assigned to groups for the purpose of assigning variables which govern derivatives calculation. Parameters can be bounded, log-transformed, linked to one another, or fixed in “predictive analysis” mode just as in “estimation” mode. In fact parameter bounds, transformations and linkages must be the same for a predictive analysis run as they were for the preceding parameter estimation run in which min was determined, for the value supplied to PEST for 0 must be consistent with the previously determined value of min.
Just as in “estimation” mode, a Marquardt lambda is used to assist PEST in coping with model nonlinearities when it is run in “predictive analysis” mode; this lambda is adjusted by PEST as the optimisation process progresses. The same user-supplied control variables affect PEST’s lambda adjustment procedure as when it is used in “estimation” mode (plus a couple more – see below). However, if desired, a line search procedure along the direction of the parameter upgrade vector can be used to improve calculation of the maximum or minimum model prediction for any value of the Marquardt lambda. This, in fact, is the recommended procedure.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.
- **Next Summary:** In "predictive analysis" mode, PEST maximizes/minimizes a prediction (in the "predict" group) while keeping the objective function ≤ Φ0 (requires a prior "estimation" run).  It uses the same parameters, transformations, and observations as the estimation run.  Restarting uses `/r`, `/j`, `/d`, or `/s` (parallel runs).  Change limits remain important.  Screen output shows prediction values per iteration.  Results include the optimal prediction and parameter values.

### Metadata
- **Keywords:** 
- **Chunk ID:** d8284352aeb8
- **Chunk Index:** 1
- **Previous Chunk ID:** c55285164f60
- **Next Chunk ID:** b94b8e2d6ccd

---

## Context

### Summary
**GENLINPRED selects between two predictive uncertainty equations (Doherty 2015, Equations 7.4.1 and 7.4.2) based on the number of parameters and observations in the PEST control file.  High parameter/observation numbers may cause slow runtimes or numerical errors; contact the author if errors such as negative uncertainties or parameter contributions occur.**

### Header
**10.17.11 PREDUNC Uncertainty Formulation**

### Content
As documented in descriptions of PREDUNC1, PREDUNC4 and PREDUNC5, these programs provide two different options for computation of predictive uncertainty and of quantities which depend on this. One of these options is better used where parameter numbers
are small while the other is more efficient where observation numbers are small. GENLINPRED chooses the “efficient if low parameter numbers” option if the number of adjustable parameters in the PEST control file is less than the number of adjustable observations, and chooses the “efficient if low observation numbers” option otherwise. Nevertheless where both observation and parameter numbers are high, the run times associated with PREDUNC‑suite programs, and hence with GENLINPRED, may be high. Furthermore, there may be some occasions where use of one of these equations (particularly the low observation number option) can induce numerical errors due to the large number of matrix operations involved. Contact me if GENLINPRED computes obviously erroneous quantities such as negative uncertainties and negative parameter contributions to predictive uncertainty and I will alter GENLINPRED’s internal settings to alter its choice of equation.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 10. Linear Error and Uncertainty – Part I
- **Subsection:** 10.17 GENLINPRED

### Additional Summaries
- **Higher-Level Summary:** SVD-assist optimizes inversions by estimating "super parameters" instead of native parameters, reducing computational cost. Use standard procedures, PEST, and SVDAPREP for optimal results. Create a base PEST control file, run PEST to generate a Jacobian matrix, and use PARCALC and PICALC for parameter translation and prior information calculation.
- **Detailed Summary:** GENLINPRED automates parameter and prediction uncertainty analyses using various programs. It simplifies the process for users, compiling results into a single output file. It calculates parameter group contributions to prediction error and uncertainty, selecting predictive uncertainty equations based on parameters and observations in the PEST control file. The tool offers prompts for input and analysis options, with the ability to customize settings for improved performance and accuracy.

### Related Context
- **Previous Summary:** GENLINPRED calculates parameter group contributions to prediction error/uncertainty (using PREDVAR4/PREDUNC4).  Bar charts show pre- and post-calibration contributions. Post-calibration contributions may exceed pre-calibration contributions due to calibration-induced parameter correlation;  this is further discussed below.
- **Next Summary:** For additional analyses or to correct numerical errors, run PREDVAR and PREDUNC suite programs individually; GENLINPRED's automation may be less efficient computationally but simpler for the user.  Running SCALEPAR before PREDUNC programs is unnecessary.

### Metadata
- **Keywords:** 
- **Chunk ID:** f79f5df3f074
- **Chunk Index:** 1
- **Previous Chunk ID:** d2684bb2d53b
- **Next Chunk ID:** 321b4ef6ab4c

---

## Context

### Summary
**PESTPP-OPT solves constrained optimization problems considering uncertainties in model outputs (chance constraints).  Constraints are applied to predictive values adjusted for uncertainty (often pessimistically), using a calibrated model (minimized error variance, Doherty 2015) where model outputs are near the center of their posterior distributions.  Model parameter uncertainty stems from prior uncertainty and calibration data.**

### Header
**8.1.2 Overview**

### Content
Sustainable management of a natural system often requires that an optimization problem be solved. Something must be maximized or minimized through adjustment of so-called “decision variables”, subject to certain constraints. For example, it may be desirable to maximize the amount of water extracted from a number of wells (where pumping rates are the decision variables), subject to the constraints that flow in an adjacent stream does not fall below a specified rate, and that groundwater levels in certain observation wells are maintained above certain levels. Design of a contaminant remediation system may attempt to ensure that the cost of water extraction and treatment is minimized subject to the constraint that the contaminant is captured; pumping and injection rates, and the locations of pumping and injection wells, comprise the decision variables in this example.
Models are used to predict the response of a natural system to natural and management-imposed stresses. Where management is optimized, some of the quantities which the model calculates comprise system behaviour on which constraints must be imposed. These outputs are normally uncertain, reflecting the fact that the model’s parameters are uncertain. (Model outputs to which constraints are applied have this in common with any other predictions made by a model.) The question then arises as to whether imposition of constraints should take account of these uncertainties. Where violation of a constraint can result in an unacceptable cost, the answer to that question is obvious: respect for valuable societal and/or environmental assets requires that model-calculated quantities to which constraints are applied be adjusted to include the range of possibilities that are compatible with the range of reasonable parameters that a model can employ. For example, in the stream flow example discussed above, exercise of the precautionary principle may dictate that the constraint be applied to the lowest streamflow that would be calculated by the model if it were parameterized with the most pessimistic set of parameters (with respect to that particular model output) that are compatible with expert knowledge on the one hand, and the necessity to fit the model calibration dataset on the other hand.
In most environmental modelling contexts, a model is calibrated before it is deployed. As is described by Doherty (2015), if properly undertaken, the calibration process yields a parameter field of minimized error variance. This is its “passport to uniqueness”. The parameter field is not correct; its potential for wrongness (which may be large) is merely minimized. Any prediction that the model makes inherits this status. That is, the prediction is not correct; however, its potential for wrongness has been minimized. Hence a prediction made by a calibrated model lies somewhere near the centre of the posterior probability distribution of that prediction. The same concept can be extended to model outputs that describe environmental behaviour to which constraints must be applied.
If uncertainty is to be taken into account in imposition of an optimization constraint, the width of the probability distribution associated with the model output to which the constraint is applied must be calculated so that the constraint can be applied to a predictive value that is adjusted in order to accommodate its uncertainty. Often (but not always – see below) it will be adjusted towards the pessimistic end of its probability range.
PESTPP-OPT not only solves a constrained optimization problem. It solves a constrained optimization problem that accommodates uncertainties in model outputs to which constraints are applied. These are often referred to as “chance constraints”. In applying chance constraints, PESTPP-OPT assumes that model predictive uncertainty is an outcome of model parameter uncertainty. The latter is, in turn, an outcome of prior parameter uncertainty (i.e., the uncertainty range that emerges from the stochastic nature of expert knowledge), and the extent to which this uncertainty is reduced through the model calibration process. Parameter uncertainty reduction is a function of the information content of the calibration dataset, and the extent to which flow of this information is hampered by the presence of noise within that dataset.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.

### Related Context
- **Previous Summary:** PESTPP-OPT (described by White et al. 2018, and Wagner and Gorelick 1987) performs decision optimization under uncertainty using sequential linear programming.  Examples of its use are provided in White et al. (2018).
- **Next Summary:** PESTPP-OPT handles chance constraints via weights (as standard deviations, *opt_std_weights(true)*), linear methods (FOSM, using Jacobian matrices and prior parameter/measurement uncertainties), or stack-based methods.  FOSM uses Equations 8.1a or 8.1b (Doherty 2015) to calculate prediction variance;  Equations 8.2a or 8.2b calculate the posterior parameter covariance matrix; Equation 8.3 calculates output uncertainty variance.  The Jacobian matrix can be user-supplied or calculated by PESTPP-OPT.

### Metadata
- **Keywords:** 
- **Chunk ID:** e05099b5052d
- **Chunk Index:** 1
- **Previous Chunk ID:** 9eb7ce055068
- **Next Chunk ID:** 0a9e459f4e6c

---


Answer strictly following the above instructions.

```

# Complete Messages Array
```json
[
  {
    "role": "system",
    "content": "\nYou are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:\n\n1. **Direct Answer First:**  \n   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.\n   - Use the following structure:\n\n     **1) Definition**  \n     - Provide a concise definition.  \n     - Cite source(s) using the format \"File: [filename], Section: [header]\".\n\n     **2) Possible Values**  \n     - Describe valid or recognized values (including defaults if specified).  \n     - Cite source(s).\n\n     **3) Implications**  \n     - Explain usage considerations or consequences for each value.  \n     - If the documentation does not provide this information, state: \"Information not available in the provided content. \"\n\n     **4) Practical Usage Notes**  \n     - Include usage notes or examples only if explicitly provided in the documentation.  \n     - Otherwise, state: \"No usage notes found in the provided content.\"\n\n     **5) Keywords**  \n     - List any associated keywords as found in the documentation.  \n     - If none are provided, state: \"No keywords found in the provided content\"\n\n     **6) Follow-up References**  \n     - Point out additional references or relevant sections from the documentation, if applicable.\n\n2. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.\n   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.\n   - Each question should reference specific sections from the documentation if available.\n\n3. **Important Instructions:**  \n   - **Do not mention internal processes, \"chunks,\" or retrieval steps.**  \n   - **Do not include any self-commentary or extra explanations beyond the structure above.**  \n   - Use only the documentation provided in `{context}`.\n\nAnswer strictly following the structure and rules above.\n"
  },
  {
    "role": "user",
    "content": "\nQuestion: How does uncertain analysis work?\n\nPlease provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:\n\n1. **Cite Sources:**  \n   - Use the format \"File: [filename], Section: [header]\" whenever you reference specific details.\n\n2. **Include Examples:**  \n   - Provide relevant examples from the documentation if available.\n\n3. **Note Limitations:**  \n   - If the documentation is incomplete or ambiguous, explicitly state: \"Information not available in the provided content. I don't know.\"\n\n4. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.\n   - **Do not provide answers to these follow-up questions.**\n   - Each question should reference specific sections from the documentation if applicable.\n\n5. **Keywords Section:**  \n   - Include a \"Keywords\" section if applicable, listing any associated keywords as found in the documentation.\n   - If none are provided, state: \"No keywords found in the provided content. I don't know.\"\n\n6. **Avoid Internal Details:**  \n   - Do not mention internal processes, such as \"chunks\" or retrieval steps.\n   - Do not include any self-commentary or extra explanations beyond what is requested.\n\n7. **Be Concise and Accurate:**  \n   - Do not invent details or assumptions. If information is missing, state: \"Information not available in the provided content. I don't know.\"\n\n**Available Documentation with Metadata:**\n# Search Results for: How does uncertain analysis work?\n\nKeywords: None\n\n\n## Context\n\n### Summary\n**In \"predictive analysis\" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.**\n\n### Header\n**8.1 Introduction**\n\n### Content\nWhen run in “predictive analysis” mode, PEST solves the constrained predictive maximisation/minimisation problem described in section 8.4 of Doherty (2015). In solving this problem PEST evaluates the maximum or minimum value that a model prediction can take while other model outputs are such that the calibration objective function is maintained at or below a user-specified value. In doing so it evaluates the post-calibration uncertainty range of the prediction. Optionally, the prediction can be accompanied by “predictive noise”. Of course, there is no reason why the prediction cannot actually be a model parameter; the post-calibration uncertainty of any parameter can thereby be explored.\nThe constrained maximisation/minimisation process undertaken by PEST when it is run in “predictive analysis” mode must be undertaken following a calibration process wherein an objective function is minimised. The objective function constraint imposed during the predictive maximisation/minimisation process will be somewhat greater than the minimised objective function. Theoretically, the value of the constraining objective function can be related to a predictive confidence limit using equations provided in Doherty (2015) and derived by Cooley and Vecchia (1987), Vecchia and Cooley (1987) and Christensen and Cooley (1999). In practice, however, the constraining objective function will probably be determined subjectively, as the statistics of model-to-measurement misfit will rarely be known, given the fact that in most modelling contexts it is model imperfections, rather than measurement noise, which dictates the level of fit that can be achieved between field measurements and their model-generated counterparts.\nIn practical terms, predictive maximisation/minimisation as a means of exploring post-calibration predictive uncertainty works well where parameters are relatively few in number and where estimation of those parameters constitutes a well-posed inverse problem. If the inverse problem of model calibration is not well-posed, then prior information which encapsulates pre-calibration expected parameter values (or linear/nonlinear relationships between expected parameter values) must form a component of the calibration dataset to make it so; such prior information may need to be accompanied by a prior covariance matrix if full expression is to be given to expert knowledge. Given the manual regularisation required for formulation of a well-posed, or almost well-posed, inverse problem, determination of the relative weighting between expert-knowledge-based prior information on the one hand and measurements of system state on the other hand then becomes a problem.\nExperience demonstrates that the numerical performance of the constrained maximisation/minimisation process can be delicate. The integrity of finite-difference derivatives must be high for the process to work well – higher than it needs to be for successful minimisation of an objective function. Model numerical performance must therefore be good. While some protection against poor numerical performance can be gained through undertaking a line search in conjunction with Marquardt-lambda-based parameter upgrade testing (see below), the line search procedure is inherently serial, and hence cannot be parallelised. This limits the run times of models with which PEST can be used when undertaking predictive uncertainty analysis in this way.\nThe PEST suite provides other options for undertaking post-calibration predictive uncertainty.\nanalysis, these including linear analysis, calibration-constrained Monte Carlo analysis (of which null space Monte Carlo is an example), and its Pareto functionality. All of these can work well in highly parameterized contexts where the constrained maximisation/minimisation process which PEST undertakes when run in “predictive analysis” mode may fail. Nevertheless, this mode of operation has proven itself useful in many real-world modelling contexts, and will continue to do so in the future, provided its strengths and weaknesses are properly understood.\nThis chapter describes how to use PEST in “predictive analysis” mode. Concepts and theory are fully described in section 8.4 of Doherty (2015).\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 8. Predictive Analysis\n- **Subsection:** \n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** \n\n### Related Context\n- **Previous Summary:** An optional \"sensitivity reuse\" section (Figure 7.1, before \"parameter groups,\" after SVD/LSQR sections) controls sensitivity reuse (activated by DOSENREUSE=\"senreuse\").  SENRELTHRESH sets the relative sensitivity threshold for reuse. SENMAXREUSE sets the maximum number of parameters for reuse. SENALLCALCINT sets the interval for recalculating all sensitivities. SENPREDWEIGHT weights prediction sensitivities in \"predictive analysis\" mode. SENPIEXCLUDE excludes prior information from sensitivity calculations.\n- **Next Summary:** In \"predictive analysis\" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior \"estimation\" run (Φmin). The prediction is in the \"predict\" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding \"estimation\" run.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** c55285164f60\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 17462e455db6\n- **Next Chunk ID:** d8284352aeb8\n\n---\n\n## Context\n\n### Summary\n**In \"predictive analysis\" mode (see Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while keeping the objective function below a threshold (Φ0, slightly above minimum Φmin). This method is suitable for well-behaved models with few parameters; otherwise, other methods are recommended.**\n\n### Header\n**3.3.4 Predictive Analysis Mode**\n\n### Content\nWhen PEST is run in “predictive analysis” mode it solves a constrained maximisation/minimisation problem in which a prediction of interest is maximised or minimised subject to the constraint that the objective function rises no higher than a user-specified level. Theory on which this mode of PEST’s operation is based was derived by Cooley and Vecchia (1987) and Vecchia and Cooley (1987), and is described in detail in section 8.4 of Doherty (2015).\nUse of PEST in “predictive analysis” mode should follow solution of a well posed, or only slightly ill-posed, inverse problem in which a model has been calibrated through reduction of an appropriate objective function to its minimum. Let us denote this minimised objective function as Φmin. Let Φ0 denote an objective function that is slightly higher than Φmin at which the model is deemed to be “uncalibrated” at a certain level of confidence. Let model output read by PEST that is actually a prediction, and is hence unused by the calibration process. The range of post-calibration uncertainty of this prediction can be determined through solution of two constrained optimisation problems in which the prediction is maximised, and then minimized, subject to the constraint that the objective.\nThis means of assessing predictive uncertainty can work well where a model does not have too many parameters, and where it is numerically well-behaved so that finite-difference-based derivatives of model outputs with respect to parameters have a high degree of integrity. If these conditions are not met then other methods of predictive uncertainty assessment should be pursued; these can include linear methods, null space Monte Carlo, and PEST’s “pareto” mode.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 3. What PEST Does\n- **Subsection:** 3.3 Modes of Operation\n\n### Additional Summaries\n- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: \"estimation\", \"predictive analysis\", \"regularisation\", and \"pareto\". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.\n- **Detailed Summary:** PEST is a tool that iteratively solves inverse problems in four modes: \"estimation\", \"predictive analysis\", \"regularisation\", and \"pareto\". It uses Jacobian matrices and Marquardt lambda for parameter estimation. Different methods are employed based on problem types, with options for uncertainty analysis and parallel processing to reduce computational costs.\n\n### Related Context\n- **Previous Summary:** PEST's \"regularisation\" mode uses Tikhonov regularization (see Doherty 2015), employing measurement and regularization objective functions.  A parameter covariance matrix is not recorded; however, posterior uncertainties are investigated using utilities like PREDUNC7.\n- **Next Summary:** In \"pareto\" mode, PEST explores the trade-off between objective functions (e.g., measurement vs. regularization, or data fit vs. prediction proximity).  This allows assessment of fit quality and hypothesis testing regarding predictions (see Doherty 2015, section 8.5).  Parallel processing and SVD-assist mitigate computational costs.  Linear uncertainty analysis is possible using PEST utilities.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 2e473251b7f2\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 2c26d6d34bff\n- **Next Chunk ID:** 753954871395\n\n---\n\n## Context\n\n### Summary\n**In \"predictive analysis\" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior \"estimation\" run (Φmin). The prediction is in the \"predict\" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding \"estimation\" run.**\n\n### Header\n**8.2 Predictive Analysis Mode**\n\n### Content\nAs was discussed earlier in this manual, PEST can run in four different modes – “estimation”, “regularisation”, “pareto” and “predictive analysis” modes. A PEST run in “predictive analysis” mode is designed to follow a run in “estimation” mode wherein PEST minimises an objective function.\nLet Φmin designate the value of the minimised objective function as calculated during its previous “estimation” run. PEST’s task when run in “predictive analysis” mode is to find the point identified in figure 8.2 of Doherty (2015). This is a point lying on a contour along which the objective function is Φ0 and at which a prediction of interest has its maximum or minimum value along that contour. This point is referred to as the “critical point” in the discussion that follows. PEST finds the parameters which correspond to this point, and the value of the prediction which corresponds to this point. Φ, of course, must be greater than 0 Φmin. Often it is not much greater than Φmin and can thus be designated as being equal to Φmin + δ where δ is a small number. The means through which a suitable value can be assigned to Φ0 has been mentioned above and will be discussed in greater detail below.\nIf PEST runs in “predictive analysis” mode, then a particular model output must be identified as “the prediction” of interest. Of course, all model outputs (and parameters) that were employed in the previous “estimation” run must also be included in the PEST dataset for the “predictive analysis” run, as the objective function must be calculable just as before. However the model may need to be expanded to include the predictive output of interest. Also, it may need to be run into the future. Perhaps two versions of the model will need to be encapsulated in a single batch or script file which PEST runs through a system call; one of these may pertain to calibration conditions while the other may be run into the future to calculate the model output which must be maximised or minimised subject to an objective function constraint of Φ0.\nThe predictive model output must be read like any other model output which is of interest to PEST. An instruction must be provided in an instruction file. The model output must be classified as an “observation”. However it must be assigned to an observation group named “predict”. Furthermore it must be the sole member of that observation group. This is how PEST recognizes the model output that it must maximise or minimise subject to calibration constraints. It is important to note that PEST takes no notice of the “observed value” of this observation; depending on the setting of control variables discussed below, it may or may not take notice of the weight assigned to this observation. PEST’s job is to maximise or minimise the model output corresponding to this observation, while maintaining the objective function at or below Φmin + δ, i.e. at or below Φ0.\nThough ostensibly different, PEST’s operation in “predictive analysis” mode has much in\ncommon with its operation in “estimation” mode. In fact, the underlying mathematics is very similar; see Doherty (2015). Like parameter estimation, the process required to determine the critical point is an iterative one, beginning at some user-supplied initial parameter set. Initial parameters can be either inside the 0 preceding parameter estimation process. If they are initial values that were used for the contour or outside of it; in fact they can be the same outside of the 0 contour, PEST automatically works in “estimation” mode until it is “within reach” of 0, at which stage it modifies its operations to search for the critical point. It is normally good practice, however, for “predictive analysis” mode initial values to be the same as those determined through the previous “estimation” mode PEST run, and hence correspond to min.\nWhen run in “predictive analysis” mode PEST still needs to calculate a Jacobian matrix, so derivatives of model outcomes with respect to adjustable parameters are still required. Derivatives can be calculated using two, three or five points; PEST can switch from one to the other as the solution process progresses. Parameters must still be assigned to groups for the purpose of assigning variables which govern derivatives calculation. Parameters can be bounded, log-transformed, linked to one another, or fixed in “predictive analysis” mode just as in “estimation” mode. In fact parameter bounds, transformations and linkages must be the same for a predictive analysis run as they were for the preceding parameter estimation run in which min was determined, for the value supplied to PEST for 0 must be consistent with the previously determined value of min.\nJust as in “estimation” mode, a Marquardt lambda is used to assist PEST in coping with model nonlinearities when it is run in “predictive analysis” mode; this lambda is adjusted by PEST as the optimisation process progresses. The same user-supplied control variables affect PEST’s lambda adjustment procedure as when it is used in “estimation” mode (plus a couple more – see below). However, if desired, a line search procedure along the direction of the parameter upgrade vector can be used to improve calculation of the maximum or minimum model prediction for any value of the Marquardt lambda. This, in fact, is the recommended procedure.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 8. Predictive Analysis\n- **Subsection:** \n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** \n\n### Related Context\n- **Previous Summary:** In \"predictive analysis\" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.\n- **Next Summary:** In \"predictive analysis\" mode, PEST maximizes/minimizes a prediction (in the \"predict\" group) while keeping the objective function ≤ Φ0 (requires a prior \"estimation\" run).  It uses the same parameters, transformations, and observations as the estimation run.  Restarting uses `/r`, `/j`, `/d`, or `/s` (parallel runs).  Change limits remain important.  Screen output shows prediction values per iteration.  Results include the optimal prediction and parameter values.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** d8284352aeb8\n- **Chunk Index:** 1\n- **Previous Chunk ID:** c55285164f60\n- **Next Chunk ID:** b94b8e2d6ccd\n\n---\n\n## Context\n\n### Summary\n**GENLINPRED selects between two predictive uncertainty equations (Doherty 2015, Equations 7.4.1 and 7.4.2) based on the number of parameters and observations in the PEST control file.  High parameter/observation numbers may cause slow runtimes or numerical errors; contact the author if errors such as negative uncertainties or parameter contributions occur.**\n\n### Header\n**10.17.11 PREDUNC Uncertainty Formulation**\n\n### Content\nAs documented in descriptions of PREDUNC1, PREDUNC4 and PREDUNC5, these programs provide two different options for computation of predictive uncertainty and of quantities which depend on this. One of these options is better used where parameter numbers\nare small while the other is more efficient where observation numbers are small. GENLINPRED chooses the “efficient if low parameter numbers” option if the number of adjustable parameters in the PEST control file is less than the number of adjustable observations, and chooses the “efficient if low observation numbers” option otherwise. Nevertheless where both observation and parameter numbers are high, the run times associated with PREDUNC‑suite programs, and hence with GENLINPRED, may be high. Furthermore, there may be some occasions where use of one of these equations (particularly the low observation number option) can induce numerical errors due to the large number of matrix operations involved. Contact me if GENLINPRED computes obviously erroneous quantities such as negative uncertainties and negative parameter contributions to predictive uncertainty and I will alter GENLINPRED’s internal settings to alter its choice of equation.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software\n- **Main Section:** 10. Linear Error and Uncertainty – Part I\n- **Subsection:** 10.17 GENLINPRED\n\n### Additional Summaries\n- **Higher-Level Summary:** SVD-assist optimizes inversions by estimating \"super parameters\" instead of native parameters, reducing computational cost. Use standard procedures, PEST, and SVDAPREP for optimal results. Create a base PEST control file, run PEST to generate a Jacobian matrix, and use PARCALC and PICALC for parameter translation and prior information calculation.\n- **Detailed Summary:** GENLINPRED automates parameter and prediction uncertainty analyses using various programs. It simplifies the process for users, compiling results into a single output file. It calculates parameter group contributions to prediction error and uncertainty, selecting predictive uncertainty equations based on parameters and observations in the PEST control file. The tool offers prompts for input and analysis options, with the ability to customize settings for improved performance and accuracy.\n\n### Related Context\n- **Previous Summary:** GENLINPRED calculates parameter group contributions to prediction error/uncertainty (using PREDVAR4/PREDUNC4).  Bar charts show pre- and post-calibration contributions. Post-calibration contributions may exceed pre-calibration contributions due to calibration-induced parameter correlation;  this is further discussed below.\n- **Next Summary:** For additional analyses or to correct numerical errors, run PREDVAR and PREDUNC suite programs individually; GENLINPRED's automation may be less efficient computationally but simpler for the user.  Running SCALEPAR before PREDUNC programs is unnecessary.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** f79f5df3f074\n- **Chunk Index:** 1\n- **Previous Chunk ID:** d2684bb2d53b\n- **Next Chunk ID:** 321b4ef6ab4c\n\n---\n\n## Context\n\n### Summary\n**PESTPP-OPT solves constrained optimization problems considering uncertainties in model outputs (chance constraints).  Constraints are applied to predictive values adjusted for uncertainty (often pessimistically), using a calibrated model (minimized error variance, Doherty 2015) where model outputs are near the center of their posterior distributions.  Model parameter uncertainty stems from prior uncertainty and calibration data.**\n\n### Header\n**8.1.2 Overview**\n\n### Content\nSustainable management of a natural system often requires that an optimization problem be solved. Something must be maximized or minimized through adjustment of so-called “decision variables”, subject to certain constraints. For example, it may be desirable to maximize the amount of water extracted from a number of wells (where pumping rates are the decision variables), subject to the constraints that flow in an adjacent stream does not fall below a specified rate, and that groundwater levels in certain observation wells are maintained above certain levels. Design of a contaminant remediation system may attempt to ensure that the cost of water extraction and treatment is minimized subject to the constraint that the contaminant is captured; pumping and injection rates, and the locations of pumping and injection wells, comprise the decision variables in this example.\nModels are used to predict the response of a natural system to natural and management-imposed stresses. Where management is optimized, some of the quantities which the model calculates comprise system behaviour on which constraints must be imposed. These outputs are normally uncertain, reflecting the fact that the model’s parameters are uncertain. (Model outputs to which constraints are applied have this in common with any other predictions made by a model.) The question then arises as to whether imposition of constraints should take account of these uncertainties. Where violation of a constraint can result in an unacceptable cost, the answer to that question is obvious: respect for valuable societal and/or environmental assets requires that model-calculated quantities to which constraints are applied be adjusted to include the range of possibilities that are compatible with the range of reasonable parameters that a model can employ. For example, in the stream flow example discussed above, exercise of the precautionary principle may dictate that the constraint be applied to the lowest streamflow that would be calculated by the model if it were parameterized with the most pessimistic set of parameters (with respect to that particular model output) that are compatible with expert knowledge on the one hand, and the necessity to fit the model calibration dataset on the other hand.\nIn most environmental modelling contexts, a model is calibrated before it is deployed. As is described by Doherty (2015), if properly undertaken, the calibration process yields a parameter field of minimized error variance. This is its “passport to uniqueness”. The parameter field is not correct; its potential for wrongness (which may be large) is merely minimized. Any prediction that the model makes inherits this status. That is, the prediction is not correct; however, its potential for wrongness has been minimized. Hence a prediction made by a calibrated model lies somewhere near the centre of the posterior probability distribution of that prediction. The same concept can be extended to model outputs that describe environmental behaviour to which constraints must be applied.\nIf uncertainty is to be taken into account in imposition of an optimization constraint, the width of the probability distribution associated with the model output to which the constraint is applied must be calculated so that the constraint can be applied to a predictive value that is adjusted in order to accommodate its uncertainty. Often (but not always – see below) it will be adjusted towards the pessimistic end of its probability range.\nPESTPP-OPT not only solves a constrained optimization problem. It solves a constrained optimization problem that accommodates uncertainties in model outputs to which constraints are applied. These are often referred to as “chance constraints”. In applying chance constraints, PESTPP-OPT assumes that model predictive uncertainty is an outcome of model parameter uncertainty. The latter is, in turn, an outcome of prior parameter uncertainty (i.e., the uncertainty range that emerges from the stochastic nature of expert knowledge), and the extent to which this uncertainty is reduced through the model calibration process. Parameter uncertainty reduction is a function of the information content of the calibration dataset, and the extent to which flow of this information is hampered by the presence of noise within that dataset.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis\n- **Main Section:** 8. PESTPP-OPT\n- **Subsection:** 8.1 Introduction\n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** In \"predictive analysis\" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.\n\n### Related Context\n- **Previous Summary:** PESTPP-OPT (described by White et al. 2018, and Wagner and Gorelick 1987) performs decision optimization under uncertainty using sequential linear programming.  Examples of its use are provided in White et al. (2018).\n- **Next Summary:** PESTPP-OPT handles chance constraints via weights (as standard deviations, *opt_std_weights(true)*), linear methods (FOSM, using Jacobian matrices and prior parameter/measurement uncertainties), or stack-based methods.  FOSM uses Equations 8.1a or 8.1b (Doherty 2015) to calculate prediction variance;  Equations 8.2a or 8.2b calculate the posterior parameter covariance matrix; Equation 8.3 calculates output uncertainty variance.  The Jacobian matrix can be user-supplied or calculated by PESTPP-OPT.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** e05099b5052d\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 9eb7ce055068\n- **Next Chunk ID:** 0a9e459f4e6c\n\n---\n\n\nAnswer strictly following the above instructions.\n"
  }
]
```