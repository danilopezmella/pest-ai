# Stream Debug - 20250206_015224

# Original Question
```
How does PEST handle uncertainty?
```

# Context Content
```markdown
# Search Results for: How does PEST handle uncertainty?

Keywords: None


## Context

### Summary
**PEST is advanced software for environmental model calibration and uncertainty analysis.  It acknowledges model parameter and prediction uncertainties, supporting decisions by identifying unlikely future events rather than predicting certain outcomes.  Used with other software, PEST quantifies uncertainties and helps decision-making by embracing real-world complexity.  Doherty (2015) provides theoretical background.**

### Header
**1.4 Philosophy**

### Content
At the time of writing, the PEST suite is by far the most advanced software available for environmental model calibration, and for post-calibration uncertainty analysis. As such, it holds a unique place in the environmental industry – not just for what it can do, but for what it can teach us about environmental modelling.
PEST, and its ancillary software, embraces the fact that environmental systems are complex, and that a model’s parameters and predictions are uncertain. Its use supports the critical notion that a model can never tell us what will happen in the future following adoption of a certain environmental management practice; this is an outcome of the uncertainties associated with most model predictions of environmental interest. However a model may tell us, with a high degree of confidence, what will NOT happen in the future. In order to accomplish this, it cannot be deployed on its own; instead it must be deployed in conjunction with high-end inversion software such as PEST. Under these circumstances models may then provide invaluable support to the decision-making process by allowing rejection of hypotheses that unwanted events will occur if certain courses of management action are taken. (These courses of management action will often include installation of monitoring systems which trigger responses to the crossing of pre-defined measurement thresholds.)
It follows that a model, as a simulator, does not constitute a decision-support tool. In contrast, the model, as a simulator, should constitute one of a number of software packages, which are used in partnership to
- quantify the uncertainties associated with predictions of management interest, and
- reduce those uncertainties to a level that is commensurate with information available from expert knowledge on the one hand and the historical behaviour of a system on the other hand.
Software packages used in concert to achieve these ends collectively constitute an indispensable tool for decision-support – a tool which embraces the complexity of the real world at the same time as it provides decision-makers with an understanding of the ramifications of that complexity for the decisions that they must make.
For a full discussion of the role of models in decision-making see Doherty and Simmons (2013) and Doherty and Vogwill (2016).
1.5 PEST- The Book
The following book can be downloaded from the PEST web site:
Doherty, J., 2015. Calibration and uncertainty analysis for complex environmental models. Published by Watermark Numerical Computing, Brisbane, Australia. 227pp, ISBN: 978-0-9943786-0-6
The numerous references to Doherty (2015) throughout this manual are to this text.
Doherty (2015) covers in details all of the theory embodied in PEST and its utility support software. It also discusses the ramifications of this theory for how models should be used in real-world environmental decision-making. It provides an extensive discussion on the theory and practice of regularisation – whether this is done manually through parameter simplification, or mathematically using subspace or Tikhonov methods. It also provides a critique of manual regularisation, and provides an in-depth discussion on why it is important to reflect environmental system complexity in model parameterisation complexity if models are to play a useful role in support of environmental decision-making. It shows how parameter nonuniqueness is not something to run away from, but something to embrace; after all, it is the parameters that cannot be estimated that contribute most to predictive uncertainty - generally much more than those which can be estimated. It demonstrates that the use of many parameters in an inversion problem does not necessarily lead to over-fitting; nor does it promulgate numerical instability, or result in solutions to the inverse problem which are unnecessarily complex. The book shows that parameter simplification is fundamental to achievement of a unique solution to an inverse problem, and that achievement of parameter simplification through mathematical means leads to reduction of potential for model predictive error at the same time as it allows quantification of this potential for error.
Parts I and II of this manual refer to the above book extensively. They do not repeat the theory presented in the book; nor do they discuss the ramifications of that theory for model deployment in the decision-making context. This enables these manuals to be somewhat shorter than they would otherwise be; it also enables them to concentrate on implementation details. As a PEST user, you are strongly advised to read the book, for this will provide you with the theoretical basis that you need to get the most out of PEST.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 1. Introduction
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** To install PEST, copy its executables to a folder in the PATH variable for access from any directory. The suite includes PEST, Parallel PEST, BEOPEST, SENSAN, global optimizers, and utilities. PEST calibrates models by matching outputs to measurements, handling non-uniqueness through regularization. It quantifies uncertainties and supports decision-making by identifying unlikely events.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** PEST, a model-independent parameter estimation program, calibrates models by matching outputs to measurements.  It handles model calibration's inherent non-uniqueness through regularization.  The suite also assesses parameter and predictive uncertainty using linear and nonlinear methods, including null space Monte Carlo, and analyzes model defects' effects on predictions.
- **Next Summary:** PEST runs models via system calls, requiring command-line accessibility; ideally, the model's directory should be in the PATH variable.  PEST can handle models run via batch files or scripts, including pre- and post-processors and multiple simulators.  To prevent errors, batch files should delete intermediate files.  The "start /w" command (Windows) prevents premature PEST output file checks, and keyboard input can be redirected from a text file.

### Metadata
- **Keywords:** 
- **Chunk ID:** 98ea592f521d
- **Chunk Index:** 1
- **Previous Chunk ID:** 8d302ce6af24
- **Next Chunk ID:** 6ad562368195

---

## Context

### Summary
**PESTPP-OPT solves constrained optimization problems considering uncertainties in model outputs (chance constraints).  Constraints are applied to predictive values adjusted for uncertainty (often pessimistically), using a calibrated model (minimized error variance, Doherty 2015) where model outputs are near the center of their posterior distributions.  Model parameter uncertainty stems from prior uncertainty and calibration data.**

### Header
**8.1.2 Overview**

### Content
Sustainable management of a natural system often requires that an optimization problem be solved. Something must be maximized or minimized through adjustment of so-called “decision variables”, subject to certain constraints. For example, it may be desirable to maximize the amount of water extracted from a number of wells (where pumping rates are the decision variables), subject to the constraints that flow in an adjacent stream does not fall below a specified rate, and that groundwater levels in certain observation wells are maintained above certain levels. Design of a contaminant remediation system may attempt to ensure that the cost of water extraction and treatment is minimized subject to the constraint that the contaminant is captured; pumping and injection rates, and the locations of pumping and injection wells, comprise the decision variables in this example.
Models are used to predict the response of a natural system to natural and management-imposed stresses. Where management is optimized, some of the quantities which the model calculates comprise system behaviour on which constraints must be imposed. These outputs are normally uncertain, reflecting the fact that the model’s parameters are uncertain. (Model outputs to which constraints are applied have this in common with any other predictions made by a model.) The question then arises as to whether imposition of constraints should take account of these uncertainties. Where violation of a constraint can result in an unacceptable cost, the answer to that question is obvious: respect for valuable societal and/or environmental assets requires that model-calculated quantities to which constraints are applied be adjusted to include the range of possibilities that are compatible with the range of reasonable parameters that a model can employ. For example, in the stream flow example discussed above, exercise of the precautionary principle may dictate that the constraint be applied to the lowest streamflow that would be calculated by the model if it were parameterized with the most pessimistic set of parameters (with respect to that particular model output) that are compatible with expert knowledge on the one hand, and the necessity to fit the model calibration dataset on the other hand.
In most environmental modelling contexts, a model is calibrated before it is deployed. As is described by Doherty (2015), if properly undertaken, the calibration process yields a parameter field of minimized error variance. This is its “passport to uniqueness”. The parameter field is not correct; its potential for wrongness (which may be large) is merely minimized. Any prediction that the model makes inherits this status. That is, the prediction is not correct; however, its potential for wrongness has been minimized. Hence a prediction made by a calibrated model lies somewhere near the centre of the posterior probability distribution of that prediction. The same concept can be extended to model outputs that describe environmental behaviour to which constraints must be applied.
If uncertainty is to be taken into account in imposition of an optimization constraint, the width of the probability distribution associated with the model output to which the constraint is applied must be calculated so that the constraint can be applied to a predictive value that is adjusted in order to accommodate its uncertainty. Often (but not always – see below) it will be adjusted towards the pessimistic end of its probability range.
PESTPP-OPT not only solves a constrained optimization problem. It solves a constrained optimization problem that accommodates uncertainties in model outputs to which constraints are applied. These are often referred to as “chance constraints”. In applying chance constraints, PESTPP-OPT assumes that model predictive uncertainty is an outcome of model parameter uncertainty. The latter is, in turn, an outcome of prior parameter uncertainty (i.e., the uncertainty range that emerges from the stochastic nature of expert knowledge), and the extent to which this uncertainty is reduced through the model calibration process. Parameter uncertainty reduction is a function of the information content of the calibration dataset, and the extent to which flow of this information is hampered by the presence of noise within that dataset.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.

### Related Context
- **Previous Summary:** PESTPP-OPT (described by White et al. 2018, and Wagner and Gorelick 1987) performs decision optimization under uncertainty using sequential linear programming.  Examples of its use are provided in White et al. (2018).
- **Next Summary:** PESTPP-OPT handles chance constraints via weights (as standard deviations, *opt_std_weights(true)*), linear methods (FOSM, using Jacobian matrices and prior parameter/measurement uncertainties), or stack-based methods.  FOSM uses Equations 8.1a or 8.1b (Doherty 2015) to calculate prediction variance;  Equations 8.2a or 8.2b calculate the posterior parameter covariance matrix; Equation 8.3 calculates output uncertainty variance.  The Jacobian matrix can be user-supplied or calculated by PESTPP-OPT.

### Metadata
- **Keywords:** 
- **Chunk ID:** e05099b5052d
- **Chunk Index:** 1
- **Previous Chunk ID:** 9eb7ce055068
- **Next Chunk ID:** 0a9e459f4e6c

---

## Context

### Summary
**In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.**

### Header
**8.1 Introduction**

### Content
When run in “predictive analysis” mode, PEST solves the constrained predictive maximisation/minimisation problem described in section 8.4 of Doherty (2015). In solving this problem PEST evaluates the maximum or minimum value that a model prediction can take while other model outputs are such that the calibration objective function is maintained at or below a user-specified value. In doing so it evaluates the post-calibration uncertainty range of the prediction. Optionally, the prediction can be accompanied by “predictive noise”. Of course, there is no reason why the prediction cannot actually be a model parameter; the post-calibration uncertainty of any parameter can thereby be explored.
The constrained maximisation/minimisation process undertaken by PEST when it is run in “predictive analysis” mode must be undertaken following a calibration process wherein an objective function is minimised. The objective function constraint imposed during the predictive maximisation/minimisation process will be somewhat greater than the minimised objective function. Theoretically, the value of the constraining objective function can be related to a predictive confidence limit using equations provided in Doherty (2015) and derived by Cooley and Vecchia (1987), Vecchia and Cooley (1987) and Christensen and Cooley (1999). In practice, however, the constraining objective function will probably be determined subjectively, as the statistics of model-to-measurement misfit will rarely be known, given the fact that in most modelling contexts it is model imperfections, rather than measurement noise, which dictates the level of fit that can be achieved between field measurements and their model-generated counterparts.
In practical terms, predictive maximisation/minimisation as a means of exploring post-calibration predictive uncertainty works well where parameters are relatively few in number and where estimation of those parameters constitutes a well-posed inverse problem. If the inverse problem of model calibration is not well-posed, then prior information which encapsulates pre-calibration expected parameter values (or linear/nonlinear relationships between expected parameter values) must form a component of the calibration dataset to make it so; such prior information may need to be accompanied by a prior covariance matrix if full expression is to be given to expert knowledge. Given the manual regularisation required for formulation of a well-posed, or almost well-posed, inverse problem, determination of the relative weighting between expert-knowledge-based prior information on the one hand and measurements of system state on the other hand then becomes a problem.
Experience demonstrates that the numerical performance of the constrained maximisation/minimisation process can be delicate. The integrity of finite-difference derivatives must be high for the process to work well – higher than it needs to be for successful minimisation of an objective function. Model numerical performance must therefore be good. While some protection against poor numerical performance can be gained through undertaking a line search in conjunction with Marquardt-lambda-based parameter upgrade testing (see below), the line search procedure is inherently serial, and hence cannot be parallelised. This limits the run times of models with which PEST can be used when undertaking predictive uncertainty analysis in this way.
The PEST suite provides other options for undertaking post-calibration predictive uncertainty.
analysis, these including linear analysis, calibration-constrained Monte Carlo analysis (of which null space Monte Carlo is an example), and its Pareto functionality. All of these can work well in highly parameterized contexts where the constrained maximisation/minimisation process which PEST undertakes when run in “predictive analysis” mode may fail. Nevertheless, this mode of operation has proven itself useful in many real-world modelling contexts, and will continue to do so in the future, provided its strengths and weaknesses are properly understood.
This chapter describes how to use PEST in “predictive analysis” mode. Concepts and theory are fully described in section 8.4 of Doherty (2015).

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** An optional "sensitivity reuse" section (Figure 7.1, before "parameter groups," after SVD/LSQR sections) controls sensitivity reuse (activated by DOSENREUSE="senreuse").  SENRELTHRESH sets the relative sensitivity threshold for reuse. SENMAXREUSE sets the maximum number of parameters for reuse. SENALLCALCINT sets the interval for recalculating all sensitivities. SENPREDWEIGHT weights prediction sensitivities in "predictive analysis" mode. SENPIEXCLUDE excludes prior information from sensitivity calculations.
- **Next Summary:** In "predictive analysis" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior "estimation" run (Φmin). The prediction is in the "predict" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding "estimation" run.

### Metadata
- **Keywords:** 
- **Chunk ID:** c55285164f60
- **Chunk Index:** 1
- **Previous Chunk ID:** 17462e455db6
- **Next Chunk ID:** d8284352aeb8

---

## Context

### Summary
**PESTPP-OPT handles chance constraints (risk neutral, averse, or tolerant) by shifting constraint values based on a user-specified risk value (0.0-1.0) and the model output's standard deviation (σo).  A value of 0.5 ignores uncertainty; 0.95 applies constraints to the upper 95% confidence level.  This is based on chance-constraint programming (Charnes and Cooper 1959, etc.).**

### Header
**8.1.5 Chance Constraints**

### Content
A user of PESTPP-OPT can inform it whether he/she would like the optimization process which it implements to be risk neutral, risk averse, or risk tolerant. In the latter two cases he/she can specify the degree of aversion or tolerance that should characterize that process. Tolerance or aversion is introduced through the way in which model output uncertainty affects the imposition of optimization constraints.
Suppose that a user specifies that a model output *o* shall have a value no greater than *b*. Suppose also that the standard deviation of post-calibration uncertainty associated with model output *o* is *σ*o (*σ*o is calculated by PESTPP-OPT using equations 8.1 to 8.3). PESTPP-OPT assumes that model output uncertainties are characterized by a normal distribution. A user can specify, in recognition of the uncertainty associated with *o*, that he/she must be 95% sure that the constraint is not violated. In this case PESTPP-OPT applies the constraint to the model output *o* plus an amount δ*o* calculated to ensure that, according to the normal probability distribution, the chances of *o* being smaller than *o*+ δ*o* are 95%. Alternatively, a user may adopt a risk tolerant strategy by specifying that he/she will be happy as long as there is a 5% chance that the constraint is respected. In that case PESTPP-OPT applies the constraint to *o* minus this same δ*o*. A risk neutral approach results in the constraint being applied to *o*. This technique of shifting model-simulated values to which constraints are applied up or down in accordance with risk tolerance or risk aversion is referred to as chance-constraint programming (Charnes and Cooper, 1959; Miller and Wagner, 1965; Tung, 1986; Wagner and Gorelick, 1987; Hantush and Marino, 1989; Chan, 1994).
A PESTPP-OPT user must provide one number to characterize his/her approach to risk. This number must be between zero and one. A model-output-specific number, representing the uncertainty of that output, is then added or subtracted from it prior to imposition of optimization constraints on that output. Provision of a value of 0.5 for this variable (signifying risk neutrality) is equivalent to ignoring parameter, and hence predictive, uncertainty. Under these circumstances, PESTPP-OPT does not calculate model output uncertainties at all. This reduces input requirements, at the same time as it accelerates the optimization process by foregoing the need to (re)calculate the J matrix and/or y vectors of equations 8.1 to 8.3. On the other hand, a value of 0.95 specifies that constraints are applied to model outputs which are corrected to represent the upper end of the 95% one-sided confidence level of that prediction.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.

### Related Context
- **Previous Summary:** PESTPP-OPT minimizes a linear objective function (φ=cᵀx, Equation 8.4a) subject to linear constraints (Ax≤b, Equation 8.5).  The  c vector contains constants (often costs); x contains decision variables.  A (response matrix) is calculated using finite differences or user-supplied values.  It uses sequential linear programming (SLP, Forrest et al. 2016, Lougee-Heimer 2003, Ahlfield and Mulligan 2000) for efficient optimization, recomputing A iteratively.  The model is assumed to be calibrated.
- **Next Summary:** PESTPP-OPT uses a PEST control file (Chapter 5) defining parameters, calibration data (with noise), decision variables, constraints, objective function, and optimization control variables (keyword-value pairs, "++" prefix).  It requires a calibrated model.  The details of each of these are discussed below.

### Metadata
- **Keywords:** 
- **Chunk ID:** 135c3f141f17
- **Chunk Index:** 1
- **Previous Chunk ID:** 1af4c91b72e5
- **Next Chunk ID:** 1eb4698ae37e

---

## Context

### Summary
**In "predictive analysis" mode (see Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while keeping the objective function below a threshold (Φ0, slightly above minimum Φmin). This method is suitable for well-behaved models with few parameters; otherwise, other methods are recommended.**

### Header
**3.3.4 Predictive Analysis Mode**

### Content
When PEST is run in “predictive analysis” mode it solves a constrained maximisation/minimisation problem in which a prediction of interest is maximised or minimised subject to the constraint that the objective function rises no higher than a user-specified level. Theory on which this mode of PEST’s operation is based was derived by Cooley and Vecchia (1987) and Vecchia and Cooley (1987), and is described in detail in section 8.4 of Doherty (2015).
Use of PEST in “predictive analysis” mode should follow solution of a well posed, or only slightly ill-posed, inverse problem in which a model has been calibrated through reduction of an appropriate objective function to its minimum. Let us denote this minimised objective function as Φmin. Let Φ0 denote an objective function that is slightly higher than Φmin at which the model is deemed to be “uncalibrated” at a certain level of confidence. Let model output read by PEST that is actually a prediction, and is hence unused by the calibration process. The range of post-calibration uncertainty of this prediction can be determined through solution of two constrained optimisation problems in which the prediction is maximised, and then minimized, subject to the constraint that the objective.
This means of assessing predictive uncertainty can work well where a model does not have too many parameters, and where it is numerically well-behaved so that finite-difference-based derivatives of model outputs with respect to parameters have a high degree of integrity. If these conditions are not met then other methods of predictive uncertainty assessment should be pursued; these can include linear methods, null space Monte Carlo, and PEST’s “pareto” mode.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 3. What PEST Does
- **Subsection:** 3.3 Modes of Operation

### Additional Summaries
- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.
- **Detailed Summary:** PEST is a tool that iteratively solves inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses Jacobian matrices and Marquardt lambda for parameter estimation. Different methods are employed based on problem types, with options for uncertainty analysis and parallel processing to reduce computational costs.

### Related Context
- **Previous Summary:** PEST's "regularisation" mode uses Tikhonov regularization (see Doherty 2015), employing measurement and regularization objective functions.  A parameter covariance matrix is not recorded; however, posterior uncertainties are investigated using utilities like PREDUNC7.
- **Next Summary:** In "pareto" mode, PEST explores the trade-off between objective functions (e.g., measurement vs. regularization, or data fit vs. prediction proximity).  This allows assessment of fit quality and hypothesis testing regarding predictions (see Doherty 2015, section 8.5).  Parallel processing and SVD-assist mitigate computational costs.  Linear uncertainty analysis is possible using PEST utilities.

### Metadata
- **Keywords:** 
- **Chunk ID:** 2e473251b7f2
- **Chunk Index:** 1
- **Previous Chunk ID:** 2c26d6d34bff
- **Next Chunk ID:** 753954871395

---

```

# System Prompt
```

You are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:

1. **Direct Answer First:**  
   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.
   - Use the following structure:

     **1) Definition**  
     - Provide a concise definition.  
     - Cite source(s) using the format "File: [filename], Section: [header]".

     **2) Possible Values**  
     - Describe valid or recognized values (including defaults if specified).  
     - Cite source(s).

     **3) Implications**  
     - Explain usage considerations or consequences for each value.  
     - If the documentation does not provide this information, state: "Information not available in the provided content. "

     **4) Practical Usage Notes**  
     - Include usage notes or examples only if explicitly provided in the documentation.  
     - Otherwise, state: "No usage notes found in the provided content."

     **5) Keywords**  
     - List any associated keywords as found in the documentation.  
     - If none are provided, state: "No keywords found in the provided content"

     **6) Follow-up References**  
     - Point out additional references or relevant sections from the documentation, if applicable.

2. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.
   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.
   - Each question should reference specific sections from the documentation if available.

3. **Important Instructions:**  
   - **Do not mention internal processes, "chunks," or retrieval steps.**  
   - **Do not include any self-commentary or extra explanations beyond the structure above.**  
   - Use only the documentation provided in `{context}`.

Answer strictly following the structure and rules above.

```

# Full User Message
```

Question: How does PEST handle uncertainty?

Please provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:

1. **Cite Sources:**  
   - Use the format "File: [filename], Section: [header]" whenever you reference specific details.

2. **Include Examples:**  
   - Provide relevant examples from the documentation if available.

3. **Note Limitations:**  
   - If the documentation is incomplete or ambiguous, explicitly state: "Information not available in the provided content. I don't know."

4. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.
   - **Do not provide answers to these follow-up questions.**
   - Each question should reference specific sections from the documentation if applicable.

5. **Keywords Section:**  
   - Include a "Keywords" section if applicable, listing any associated keywords as found in the documentation.
   - If none are provided, state: "No keywords found in the provided content. I don't know."

6. **Avoid Internal Details:**  
   - Do not mention internal processes, such as "chunks" or retrieval steps.
   - Do not include any self-commentary or extra explanations beyond what is requested.

7. **Be Concise and Accurate:**  
   - Do not invent details or assumptions. If information is missing, state: "Information not available in the provided content. I don't know."

**Available Documentation with Metadata:**
# Search Results for: How does PEST handle uncertainty?

Keywords: None


## Context

### Summary
**PEST is advanced software for environmental model calibration and uncertainty analysis.  It acknowledges model parameter and prediction uncertainties, supporting decisions by identifying unlikely future events rather than predicting certain outcomes.  Used with other software, PEST quantifies uncertainties and helps decision-making by embracing real-world complexity.  Doherty (2015) provides theoretical background.**

### Header
**1.4 Philosophy**

### Content
At the time of writing, the PEST suite is by far the most advanced software available for environmental model calibration, and for post-calibration uncertainty analysis. As such, it holds a unique place in the environmental industry – not just for what it can do, but for what it can teach us about environmental modelling.
PEST, and its ancillary software, embraces the fact that environmental systems are complex, and that a model’s parameters and predictions are uncertain. Its use supports the critical notion that a model can never tell us what will happen in the future following adoption of a certain environmental management practice; this is an outcome of the uncertainties associated with most model predictions of environmental interest. However a model may tell us, with a high degree of confidence, what will NOT happen in the future. In order to accomplish this, it cannot be deployed on its own; instead it must be deployed in conjunction with high-end inversion software such as PEST. Under these circumstances models may then provide invaluable support to the decision-making process by allowing rejection of hypotheses that unwanted events will occur if certain courses of management action are taken. (These courses of management action will often include installation of monitoring systems which trigger responses to the crossing of pre-defined measurement thresholds.)
It follows that a model, as a simulator, does not constitute a decision-support tool. In contrast, the model, as a simulator, should constitute one of a number of software packages, which are used in partnership to
- quantify the uncertainties associated with predictions of management interest, and
- reduce those uncertainties to a level that is commensurate with information available from expert knowledge on the one hand and the historical behaviour of a system on the other hand.
Software packages used in concert to achieve these ends collectively constitute an indispensable tool for decision-support – a tool which embraces the complexity of the real world at the same time as it provides decision-makers with an understanding of the ramifications of that complexity for the decisions that they must make.
For a full discussion of the role of models in decision-making see Doherty and Simmons (2013) and Doherty and Vogwill (2016).
1.5 PEST- The Book
The following book can be downloaded from the PEST web site:
Doherty, J., 2015. Calibration and uncertainty analysis for complex environmental models. Published by Watermark Numerical Computing, Brisbane, Australia. 227pp, ISBN: 978-0-9943786-0-6
The numerous references to Doherty (2015) throughout this manual are to this text.
Doherty (2015) covers in details all of the theory embodied in PEST and its utility support software. It also discusses the ramifications of this theory for how models should be used in real-world environmental decision-making. It provides an extensive discussion on the theory and practice of regularisation – whether this is done manually through parameter simplification, or mathematically using subspace or Tikhonov methods. It also provides a critique of manual regularisation, and provides an in-depth discussion on why it is important to reflect environmental system complexity in model parameterisation complexity if models are to play a useful role in support of environmental decision-making. It shows how parameter nonuniqueness is not something to run away from, but something to embrace; after all, it is the parameters that cannot be estimated that contribute most to predictive uncertainty - generally much more than those which can be estimated. It demonstrates that the use of many parameters in an inversion problem does not necessarily lead to over-fitting; nor does it promulgate numerical instability, or result in solutions to the inverse problem which are unnecessarily complex. The book shows that parameter simplification is fundamental to achievement of a unique solution to an inverse problem, and that achievement of parameter simplification through mathematical means leads to reduction of potential for model predictive error at the same time as it allows quantification of this potential for error.
Parts I and II of this manual refer to the above book extensively. They do not repeat the theory presented in the book; nor do they discuss the ramifications of that theory for model deployment in the decision-making context. This enables these manuals to be somewhat shorter than they would otherwise be; it also enables them to concentrate on implementation details. As a PEST user, you are strongly advised to read the book, for this will provide you with the theoretical basis that you need to get the most out of PEST.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 1. Introduction
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** To install PEST, copy its executables to a folder in the PATH variable for access from any directory. The suite includes PEST, Parallel PEST, BEOPEST, SENSAN, global optimizers, and utilities. PEST calibrates models by matching outputs to measurements, handling non-uniqueness through regularization. It quantifies uncertainties and supports decision-making by identifying unlikely events.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** PEST, a model-independent parameter estimation program, calibrates models by matching outputs to measurements.  It handles model calibration's inherent non-uniqueness through regularization.  The suite also assesses parameter and predictive uncertainty using linear and nonlinear methods, including null space Monte Carlo, and analyzes model defects' effects on predictions.
- **Next Summary:** PEST runs models via system calls, requiring command-line accessibility; ideally, the model's directory should be in the PATH variable.  PEST can handle models run via batch files or scripts, including pre- and post-processors and multiple simulators.  To prevent errors, batch files should delete intermediate files.  The "start /w" command (Windows) prevents premature PEST output file checks, and keyboard input can be redirected from a text file.

### Metadata
- **Keywords:** 
- **Chunk ID:** 98ea592f521d
- **Chunk Index:** 1
- **Previous Chunk ID:** 8d302ce6af24
- **Next Chunk ID:** 6ad562368195

---

## Context

### Summary
**PESTPP-OPT solves constrained optimization problems considering uncertainties in model outputs (chance constraints).  Constraints are applied to predictive values adjusted for uncertainty (often pessimistically), using a calibrated model (minimized error variance, Doherty 2015) where model outputs are near the center of their posterior distributions.  Model parameter uncertainty stems from prior uncertainty and calibration data.**

### Header
**8.1.2 Overview**

### Content
Sustainable management of a natural system often requires that an optimization problem be solved. Something must be maximized or minimized through adjustment of so-called “decision variables”, subject to certain constraints. For example, it may be desirable to maximize the amount of water extracted from a number of wells (where pumping rates are the decision variables), subject to the constraints that flow in an adjacent stream does not fall below a specified rate, and that groundwater levels in certain observation wells are maintained above certain levels. Design of a contaminant remediation system may attempt to ensure that the cost of water extraction and treatment is minimized subject to the constraint that the contaminant is captured; pumping and injection rates, and the locations of pumping and injection wells, comprise the decision variables in this example.
Models are used to predict the response of a natural system to natural and management-imposed stresses. Where management is optimized, some of the quantities which the model calculates comprise system behaviour on which constraints must be imposed. These outputs are normally uncertain, reflecting the fact that the model’s parameters are uncertain. (Model outputs to which constraints are applied have this in common with any other predictions made by a model.) The question then arises as to whether imposition of constraints should take account of these uncertainties. Where violation of a constraint can result in an unacceptable cost, the answer to that question is obvious: respect for valuable societal and/or environmental assets requires that model-calculated quantities to which constraints are applied be adjusted to include the range of possibilities that are compatible with the range of reasonable parameters that a model can employ. For example, in the stream flow example discussed above, exercise of the precautionary principle may dictate that the constraint be applied to the lowest streamflow that would be calculated by the model if it were parameterized with the most pessimistic set of parameters (with respect to that particular model output) that are compatible with expert knowledge on the one hand, and the necessity to fit the model calibration dataset on the other hand.
In most environmental modelling contexts, a model is calibrated before it is deployed. As is described by Doherty (2015), if properly undertaken, the calibration process yields a parameter field of minimized error variance. This is its “passport to uniqueness”. The parameter field is not correct; its potential for wrongness (which may be large) is merely minimized. Any prediction that the model makes inherits this status. That is, the prediction is not correct; however, its potential for wrongness has been minimized. Hence a prediction made by a calibrated model lies somewhere near the centre of the posterior probability distribution of that prediction. The same concept can be extended to model outputs that describe environmental behaviour to which constraints must be applied.
If uncertainty is to be taken into account in imposition of an optimization constraint, the width of the probability distribution associated with the model output to which the constraint is applied must be calculated so that the constraint can be applied to a predictive value that is adjusted in order to accommodate its uncertainty. Often (but not always – see below) it will be adjusted towards the pessimistic end of its probability range.
PESTPP-OPT not only solves a constrained optimization problem. It solves a constrained optimization problem that accommodates uncertainties in model outputs to which constraints are applied. These are often referred to as “chance constraints”. In applying chance constraints, PESTPP-OPT assumes that model predictive uncertainty is an outcome of model parameter uncertainty. The latter is, in turn, an outcome of prior parameter uncertainty (i.e., the uncertainty range that emerges from the stochastic nature of expert knowledge), and the extent to which this uncertainty is reduced through the model calibration process. Parameter uncertainty reduction is a function of the information content of the calibration dataset, and the extent to which flow of this information is hampered by the presence of noise within that dataset.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.

### Related Context
- **Previous Summary:** PESTPP-OPT (described by White et al. 2018, and Wagner and Gorelick 1987) performs decision optimization under uncertainty using sequential linear programming.  Examples of its use are provided in White et al. (2018).
- **Next Summary:** PESTPP-OPT handles chance constraints via weights (as standard deviations, *opt_std_weights(true)*), linear methods (FOSM, using Jacobian matrices and prior parameter/measurement uncertainties), or stack-based methods.  FOSM uses Equations 8.1a or 8.1b (Doherty 2015) to calculate prediction variance;  Equations 8.2a or 8.2b calculate the posterior parameter covariance matrix; Equation 8.3 calculates output uncertainty variance.  The Jacobian matrix can be user-supplied or calculated by PESTPP-OPT.

### Metadata
- **Keywords:** 
- **Chunk ID:** e05099b5052d
- **Chunk Index:** 1
- **Previous Chunk ID:** 9eb7ce055068
- **Next Chunk ID:** 0a9e459f4e6c

---

## Context

### Summary
**In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.**

### Header
**8.1 Introduction**

### Content
When run in “predictive analysis” mode, PEST solves the constrained predictive maximisation/minimisation problem described in section 8.4 of Doherty (2015). In solving this problem PEST evaluates the maximum or minimum value that a model prediction can take while other model outputs are such that the calibration objective function is maintained at or below a user-specified value. In doing so it evaluates the post-calibration uncertainty range of the prediction. Optionally, the prediction can be accompanied by “predictive noise”. Of course, there is no reason why the prediction cannot actually be a model parameter; the post-calibration uncertainty of any parameter can thereby be explored.
The constrained maximisation/minimisation process undertaken by PEST when it is run in “predictive analysis” mode must be undertaken following a calibration process wherein an objective function is minimised. The objective function constraint imposed during the predictive maximisation/minimisation process will be somewhat greater than the minimised objective function. Theoretically, the value of the constraining objective function can be related to a predictive confidence limit using equations provided in Doherty (2015) and derived by Cooley and Vecchia (1987), Vecchia and Cooley (1987) and Christensen and Cooley (1999). In practice, however, the constraining objective function will probably be determined subjectively, as the statistics of model-to-measurement misfit will rarely be known, given the fact that in most modelling contexts it is model imperfections, rather than measurement noise, which dictates the level of fit that can be achieved between field measurements and their model-generated counterparts.
In practical terms, predictive maximisation/minimisation as a means of exploring post-calibration predictive uncertainty works well where parameters are relatively few in number and where estimation of those parameters constitutes a well-posed inverse problem. If the inverse problem of model calibration is not well-posed, then prior information which encapsulates pre-calibration expected parameter values (or linear/nonlinear relationships between expected parameter values) must form a component of the calibration dataset to make it so; such prior information may need to be accompanied by a prior covariance matrix if full expression is to be given to expert knowledge. Given the manual regularisation required for formulation of a well-posed, or almost well-posed, inverse problem, determination of the relative weighting between expert-knowledge-based prior information on the one hand and measurements of system state on the other hand then becomes a problem.
Experience demonstrates that the numerical performance of the constrained maximisation/minimisation process can be delicate. The integrity of finite-difference derivatives must be high for the process to work well – higher than it needs to be for successful minimisation of an objective function. Model numerical performance must therefore be good. While some protection against poor numerical performance can be gained through undertaking a line search in conjunction with Marquardt-lambda-based parameter upgrade testing (see below), the line search procedure is inherently serial, and hence cannot be parallelised. This limits the run times of models with which PEST can be used when undertaking predictive uncertainty analysis in this way.
The PEST suite provides other options for undertaking post-calibration predictive uncertainty.
analysis, these including linear analysis, calibration-constrained Monte Carlo analysis (of which null space Monte Carlo is an example), and its Pareto functionality. All of these can work well in highly parameterized contexts where the constrained maximisation/minimisation process which PEST undertakes when run in “predictive analysis” mode may fail. Nevertheless, this mode of operation has proven itself useful in many real-world modelling contexts, and will continue to do so in the future, provided its strengths and weaknesses are properly understood.
This chapter describes how to use PEST in “predictive analysis” mode. Concepts and theory are fully described in section 8.4 of Doherty (2015).

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** An optional "sensitivity reuse" section (Figure 7.1, before "parameter groups," after SVD/LSQR sections) controls sensitivity reuse (activated by DOSENREUSE="senreuse").  SENRELTHRESH sets the relative sensitivity threshold for reuse. SENMAXREUSE sets the maximum number of parameters for reuse. SENALLCALCINT sets the interval for recalculating all sensitivities. SENPREDWEIGHT weights prediction sensitivities in "predictive analysis" mode. SENPIEXCLUDE excludes prior information from sensitivity calculations.
- **Next Summary:** In "predictive analysis" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior "estimation" run (Φmin). The prediction is in the "predict" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding "estimation" run.

### Metadata
- **Keywords:** 
- **Chunk ID:** c55285164f60
- **Chunk Index:** 1
- **Previous Chunk ID:** 17462e455db6
- **Next Chunk ID:** d8284352aeb8

---

## Context

### Summary
**PESTPP-OPT handles chance constraints (risk neutral, averse, or tolerant) by shifting constraint values based on a user-specified risk value (0.0-1.0) and the model output's standard deviation (σo).  A value of 0.5 ignores uncertainty; 0.95 applies constraints to the upper 95% confidence level.  This is based on chance-constraint programming (Charnes and Cooper 1959, etc.).**

### Header
**8.1.5 Chance Constraints**

### Content
A user of PESTPP-OPT can inform it whether he/she would like the optimization process which it implements to be risk neutral, risk averse, or risk tolerant. In the latter two cases he/she can specify the degree of aversion or tolerance that should characterize that process. Tolerance or aversion is introduced through the way in which model output uncertainty affects the imposition of optimization constraints.
Suppose that a user specifies that a model output *o* shall have a value no greater than *b*. Suppose also that the standard deviation of post-calibration uncertainty associated with model output *o* is *σ*o (*σ*o is calculated by PESTPP-OPT using equations 8.1 to 8.3). PESTPP-OPT assumes that model output uncertainties are characterized by a normal distribution. A user can specify, in recognition of the uncertainty associated with *o*, that he/she must be 95% sure that the constraint is not violated. In this case PESTPP-OPT applies the constraint to the model output *o* plus an amount δ*o* calculated to ensure that, according to the normal probability distribution, the chances of *o* being smaller than *o*+ δ*o* are 95%. Alternatively, a user may adopt a risk tolerant strategy by specifying that he/she will be happy as long as there is a 5% chance that the constraint is respected. In that case PESTPP-OPT applies the constraint to *o* minus this same δ*o*. A risk neutral approach results in the constraint being applied to *o*. This technique of shifting model-simulated values to which constraints are applied up or down in accordance with risk tolerance or risk aversion is referred to as chance-constraint programming (Charnes and Cooper, 1959; Miller and Wagner, 1965; Tung, 1986; Wagner and Gorelick, 1987; Hantush and Marino, 1989; Chan, 1994).
A PESTPP-OPT user must provide one number to characterize his/her approach to risk. This number must be between zero and one. A model-output-specific number, representing the uncertainty of that output, is then added or subtracted from it prior to imposition of optimization constraints on that output. Provision of a value of 0.5 for this variable (signifying risk neutrality) is equivalent to ignoring parameter, and hence predictive, uncertainty. Under these circumstances, PESTPP-OPT does not calculate model output uncertainties at all. This reduces input requirements, at the same time as it accelerates the optimization process by foregoing the need to (re)calculate the J matrix and/or y vectors of equations 8.1 to 8.3. On the other hand, a value of 0.95 specifies that constraints are applied to model outputs which are corrected to represent the upper end of the 95% one-sided confidence level of that prediction.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.

### Related Context
- **Previous Summary:** PESTPP-OPT minimizes a linear objective function (φ=cᵀx, Equation 8.4a) subject to linear constraints (Ax≤b, Equation 8.5).  The  c vector contains constants (often costs); x contains decision variables.  A (response matrix) is calculated using finite differences or user-supplied values.  It uses sequential linear programming (SLP, Forrest et al. 2016, Lougee-Heimer 2003, Ahlfield and Mulligan 2000) for efficient optimization, recomputing A iteratively.  The model is assumed to be calibrated.
- **Next Summary:** PESTPP-OPT uses a PEST control file (Chapter 5) defining parameters, calibration data (with noise), decision variables, constraints, objective function, and optimization control variables (keyword-value pairs, "++" prefix).  It requires a calibrated model.  The details of each of these are discussed below.

### Metadata
- **Keywords:** 
- **Chunk ID:** 135c3f141f17
- **Chunk Index:** 1
- **Previous Chunk ID:** 1af4c91b72e5
- **Next Chunk ID:** 1eb4698ae37e

---

## Context

### Summary
**In "predictive analysis" mode (see Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while keeping the objective function below a threshold (Φ0, slightly above minimum Φmin). This method is suitable for well-behaved models with few parameters; otherwise, other methods are recommended.**

### Header
**3.3.4 Predictive Analysis Mode**

### Content
When PEST is run in “predictive analysis” mode it solves a constrained maximisation/minimisation problem in which a prediction of interest is maximised or minimised subject to the constraint that the objective function rises no higher than a user-specified level. Theory on which this mode of PEST’s operation is based was derived by Cooley and Vecchia (1987) and Vecchia and Cooley (1987), and is described in detail in section 8.4 of Doherty (2015).
Use of PEST in “predictive analysis” mode should follow solution of a well posed, or only slightly ill-posed, inverse problem in which a model has been calibrated through reduction of an appropriate objective function to its minimum. Let us denote this minimised objective function as Φmin. Let Φ0 denote an objective function that is slightly higher than Φmin at which the model is deemed to be “uncalibrated” at a certain level of confidence. Let model output read by PEST that is actually a prediction, and is hence unused by the calibration process. The range of post-calibration uncertainty of this prediction can be determined through solution of two constrained optimisation problems in which the prediction is maximised, and then minimized, subject to the constraint that the objective.
This means of assessing predictive uncertainty can work well where a model does not have too many parameters, and where it is numerically well-behaved so that finite-difference-based derivatives of model outputs with respect to parameters have a high degree of integrity. If these conditions are not met then other methods of predictive uncertainty assessment should be pursued; these can include linear methods, null space Monte Carlo, and PEST’s “pareto” mode.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 3. What PEST Does
- **Subsection:** 3.3 Modes of Operation

### Additional Summaries
- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.
- **Detailed Summary:** PEST is a tool that iteratively solves inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses Jacobian matrices and Marquardt lambda for parameter estimation. Different methods are employed based on problem types, with options for uncertainty analysis and parallel processing to reduce computational costs.

### Related Context
- **Previous Summary:** PEST's "regularisation" mode uses Tikhonov regularization (see Doherty 2015), employing measurement and regularization objective functions.  A parameter covariance matrix is not recorded; however, posterior uncertainties are investigated using utilities like PREDUNC7.
- **Next Summary:** In "pareto" mode, PEST explores the trade-off between objective functions (e.g., measurement vs. regularization, or data fit vs. prediction proximity).  This allows assessment of fit quality and hypothesis testing regarding predictions (see Doherty 2015, section 8.5).  Parallel processing and SVD-assist mitigate computational costs.  Linear uncertainty analysis is possible using PEST utilities.

### Metadata
- **Keywords:** 
- **Chunk ID:** 2e473251b7f2
- **Chunk Index:** 1
- **Previous Chunk ID:** 2c26d6d34bff
- **Next Chunk ID:** 753954871395

---


Answer strictly following the above instructions.

```

# Complete Messages Array
```json
[
  {
    "role": "system",
    "content": "\nYou are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:\n\n1. **Direct Answer First:**  \n   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.\n   - Use the following structure:\n\n     **1) Definition**  \n     - Provide a concise definition.  \n     - Cite source(s) using the format \"File: [filename], Section: [header]\".\n\n     **2) Possible Values**  \n     - Describe valid or recognized values (including defaults if specified).  \n     - Cite source(s).\n\n     **3) Implications**  \n     - Explain usage considerations or consequences for each value.  \n     - If the documentation does not provide this information, state: \"Information not available in the provided content. \"\n\n     **4) Practical Usage Notes**  \n     - Include usage notes or examples only if explicitly provided in the documentation.  \n     - Otherwise, state: \"No usage notes found in the provided content.\"\n\n     **5) Keywords**  \n     - List any associated keywords as found in the documentation.  \n     - If none are provided, state: \"No keywords found in the provided content\"\n\n     **6) Follow-up References**  \n     - Point out additional references or relevant sections from the documentation, if applicable.\n\n2. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.\n   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.\n   - Each question should reference specific sections from the documentation if available.\n\n3. **Important Instructions:**  \n   - **Do not mention internal processes, \"chunks,\" or retrieval steps.**  \n   - **Do not include any self-commentary or extra explanations beyond the structure above.**  \n   - Use only the documentation provided in `{context}`.\n\nAnswer strictly following the structure and rules above.\n"
  },
  {
    "role": "user",
    "content": "\nQuestion: How does PEST handle uncertainty?\n\nPlease provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:\n\n1. **Cite Sources:**  \n   - Use the format \"File: [filename], Section: [header]\" whenever you reference specific details.\n\n2. **Include Examples:**  \n   - Provide relevant examples from the documentation if available.\n\n3. **Note Limitations:**  \n   - If the documentation is incomplete or ambiguous, explicitly state: \"Information not available in the provided content. I don't know.\"\n\n4. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.\n   - **Do not provide answers to these follow-up questions.**\n   - Each question should reference specific sections from the documentation if applicable.\n\n5. **Keywords Section:**  \n   - Include a \"Keywords\" section if applicable, listing any associated keywords as found in the documentation.\n   - If none are provided, state: \"No keywords found in the provided content. I don't know.\"\n\n6. **Avoid Internal Details:**  \n   - Do not mention internal processes, such as \"chunks\" or retrieval steps.\n   - Do not include any self-commentary or extra explanations beyond what is requested.\n\n7. **Be Concise and Accurate:**  \n   - Do not invent details or assumptions. If information is missing, state: \"Information not available in the provided content. I don't know.\"\n\n**Available Documentation with Metadata:**\n# Search Results for: How does PEST handle uncertainty?\n\nKeywords: None\n\n\n## Context\n\n### Summary\n**PEST is advanced software for environmental model calibration and uncertainty analysis.  It acknowledges model parameter and prediction uncertainties, supporting decisions by identifying unlikely future events rather than predicting certain outcomes.  Used with other software, PEST quantifies uncertainties and helps decision-making by embracing real-world complexity.  Doherty (2015) provides theoretical background.**\n\n### Header\n**1.4 Philosophy**\n\n### Content\nAt the time of writing, the PEST suite is by far the most advanced software available for environmental model calibration, and for post-calibration uncertainty analysis. As such, it holds a unique place in the environmental industry – not just for what it can do, but for what it can teach us about environmental modelling.\nPEST, and its ancillary software, embraces the fact that environmental systems are complex, and that a model’s parameters and predictions are uncertain. Its use supports the critical notion that a model can never tell us what will happen in the future following adoption of a certain environmental management practice; this is an outcome of the uncertainties associated with most model predictions of environmental interest. However a model may tell us, with a high degree of confidence, what will NOT happen in the future. In order to accomplish this, it cannot be deployed on its own; instead it must be deployed in conjunction with high-end inversion software such as PEST. Under these circumstances models may then provide invaluable support to the decision-making process by allowing rejection of hypotheses that unwanted events will occur if certain courses of management action are taken. (These courses of management action will often include installation of monitoring systems which trigger responses to the crossing of pre-defined measurement thresholds.)\nIt follows that a model, as a simulator, does not constitute a decision-support tool. In contrast, the model, as a simulator, should constitute one of a number of software packages, which are used in partnership to\n- quantify the uncertainties associated with predictions of management interest, and\n- reduce those uncertainties to a level that is commensurate with information available from expert knowledge on the one hand and the historical behaviour of a system on the other hand.\nSoftware packages used in concert to achieve these ends collectively constitute an indispensable tool for decision-support – a tool which embraces the complexity of the real world at the same time as it provides decision-makers with an understanding of the ramifications of that complexity for the decisions that they must make.\nFor a full discussion of the role of models in decision-making see Doherty and Simmons (2013) and Doherty and Vogwill (2016).\n1.5 PEST- The Book\nThe following book can be downloaded from the PEST web site:\nDoherty, J., 2015. Calibration and uncertainty analysis for complex environmental models. Published by Watermark Numerical Computing, Brisbane, Australia. 227pp, ISBN: 978-0-9943786-0-6\nThe numerous references to Doherty (2015) throughout this manual are to this text.\nDoherty (2015) covers in details all of the theory embodied in PEST and its utility support software. It also discusses the ramifications of this theory for how models should be used in real-world environmental decision-making. It provides an extensive discussion on the theory and practice of regularisation – whether this is done manually through parameter simplification, or mathematically using subspace or Tikhonov methods. It also provides a critique of manual regularisation, and provides an in-depth discussion on why it is important to reflect environmental system complexity in model parameterisation complexity if models are to play a useful role in support of environmental decision-making. It shows how parameter nonuniqueness is not something to run away from, but something to embrace; after all, it is the parameters that cannot be estimated that contribute most to predictive uncertainty - generally much more than those which can be estimated. It demonstrates that the use of many parameters in an inversion problem does not necessarily lead to over-fitting; nor does it promulgate numerical instability, or result in solutions to the inverse problem which are unnecessarily complex. The book shows that parameter simplification is fundamental to achievement of a unique solution to an inverse problem, and that achievement of parameter simplification through mathematical means leads to reduction of potential for model predictive error at the same time as it allows quantification of this potential for error.\nParts I and II of this manual refer to the above book extensively. They do not repeat the theory presented in the book; nor do they discuss the ramifications of that theory for model deployment in the decision-making context. This enables these manuals to be somewhat shorter than they would otherwise be; it also enables them to concentrate on implementation details. As a PEST user, you are strongly advised to read the book, for this will provide you with the theoretical basis that you need to get the most out of PEST.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 1. Introduction\n- **Subsection:** \n\n### Additional Summaries\n- **Higher-Level Summary:** To install PEST, copy its executables to a folder in the PATH variable for access from any directory. The suite includes PEST, Parallel PEST, BEOPEST, SENSAN, global optimizers, and utilities. PEST calibrates models by matching outputs to measurements, handling non-uniqueness through regularization. It quantifies uncertainties and supports decision-making by identifying unlikely events.\n- **Detailed Summary:** \n\n### Related Context\n- **Previous Summary:** PEST, a model-independent parameter estimation program, calibrates models by matching outputs to measurements.  It handles model calibration's inherent non-uniqueness through regularization.  The suite also assesses parameter and predictive uncertainty using linear and nonlinear methods, including null space Monte Carlo, and analyzes model defects' effects on predictions.\n- **Next Summary:** PEST runs models via system calls, requiring command-line accessibility; ideally, the model's directory should be in the PATH variable.  PEST can handle models run via batch files or scripts, including pre- and post-processors and multiple simulators.  To prevent errors, batch files should delete intermediate files.  The \"start /w\" command (Windows) prevents premature PEST output file checks, and keyboard input can be redirected from a text file.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 98ea592f521d\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 8d302ce6af24\n- **Next Chunk ID:** 6ad562368195\n\n---\n\n## Context\n\n### Summary\n**PESTPP-OPT solves constrained optimization problems considering uncertainties in model outputs (chance constraints).  Constraints are applied to predictive values adjusted for uncertainty (often pessimistically), using a calibrated model (minimized error variance, Doherty 2015) where model outputs are near the center of their posterior distributions.  Model parameter uncertainty stems from prior uncertainty and calibration data.**\n\n### Header\n**8.1.2 Overview**\n\n### Content\nSustainable management of a natural system often requires that an optimization problem be solved. Something must be maximized or minimized through adjustment of so-called “decision variables”, subject to certain constraints. For example, it may be desirable to maximize the amount of water extracted from a number of wells (where pumping rates are the decision variables), subject to the constraints that flow in an adjacent stream does not fall below a specified rate, and that groundwater levels in certain observation wells are maintained above certain levels. Design of a contaminant remediation system may attempt to ensure that the cost of water extraction and treatment is minimized subject to the constraint that the contaminant is captured; pumping and injection rates, and the locations of pumping and injection wells, comprise the decision variables in this example.\nModels are used to predict the response of a natural system to natural and management-imposed stresses. Where management is optimized, some of the quantities which the model calculates comprise system behaviour on which constraints must be imposed. These outputs are normally uncertain, reflecting the fact that the model’s parameters are uncertain. (Model outputs to which constraints are applied have this in common with any other predictions made by a model.) The question then arises as to whether imposition of constraints should take account of these uncertainties. Where violation of a constraint can result in an unacceptable cost, the answer to that question is obvious: respect for valuable societal and/or environmental assets requires that model-calculated quantities to which constraints are applied be adjusted to include the range of possibilities that are compatible with the range of reasonable parameters that a model can employ. For example, in the stream flow example discussed above, exercise of the precautionary principle may dictate that the constraint be applied to the lowest streamflow that would be calculated by the model if it were parameterized with the most pessimistic set of parameters (with respect to that particular model output) that are compatible with expert knowledge on the one hand, and the necessity to fit the model calibration dataset on the other hand.\nIn most environmental modelling contexts, a model is calibrated before it is deployed. As is described by Doherty (2015), if properly undertaken, the calibration process yields a parameter field of minimized error variance. This is its “passport to uniqueness”. The parameter field is not correct; its potential for wrongness (which may be large) is merely minimized. Any prediction that the model makes inherits this status. That is, the prediction is not correct; however, its potential for wrongness has been minimized. Hence a prediction made by a calibrated model lies somewhere near the centre of the posterior probability distribution of that prediction. The same concept can be extended to model outputs that describe environmental behaviour to which constraints must be applied.\nIf uncertainty is to be taken into account in imposition of an optimization constraint, the width of the probability distribution associated with the model output to which the constraint is applied must be calculated so that the constraint can be applied to a predictive value that is adjusted in order to accommodate its uncertainty. Often (but not always – see below) it will be adjusted towards the pessimistic end of its probability range.\nPESTPP-OPT not only solves a constrained optimization problem. It solves a constrained optimization problem that accommodates uncertainties in model outputs to which constraints are applied. These are often referred to as “chance constraints”. In applying chance constraints, PESTPP-OPT assumes that model predictive uncertainty is an outcome of model parameter uncertainty. The latter is, in turn, an outcome of prior parameter uncertainty (i.e., the uncertainty range that emerges from the stochastic nature of expert knowledge), and the extent to which this uncertainty is reduced through the model calibration process. Parameter uncertainty reduction is a function of the information content of the calibration dataset, and the extent to which flow of this information is hampered by the presence of noise within that dataset.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis\n- **Main Section:** 8. PESTPP-OPT\n- **Subsection:** 8.1 Introduction\n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** In \"predictive analysis\" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.\n\n### Related Context\n- **Previous Summary:** PESTPP-OPT (described by White et al. 2018, and Wagner and Gorelick 1987) performs decision optimization under uncertainty using sequential linear programming.  Examples of its use are provided in White et al. (2018).\n- **Next Summary:** PESTPP-OPT handles chance constraints via weights (as standard deviations, *opt_std_weights(true)*), linear methods (FOSM, using Jacobian matrices and prior parameter/measurement uncertainties), or stack-based methods.  FOSM uses Equations 8.1a or 8.1b (Doherty 2015) to calculate prediction variance;  Equations 8.2a or 8.2b calculate the posterior parameter covariance matrix; Equation 8.3 calculates output uncertainty variance.  The Jacobian matrix can be user-supplied or calculated by PESTPP-OPT.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** e05099b5052d\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 9eb7ce055068\n- **Next Chunk ID:** 0a9e459f4e6c\n\n---\n\n## Context\n\n### Summary\n**In \"predictive analysis\" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.**\n\n### Header\n**8.1 Introduction**\n\n### Content\nWhen run in “predictive analysis” mode, PEST solves the constrained predictive maximisation/minimisation problem described in section 8.4 of Doherty (2015). In solving this problem PEST evaluates the maximum or minimum value that a model prediction can take while other model outputs are such that the calibration objective function is maintained at or below a user-specified value. In doing so it evaluates the post-calibration uncertainty range of the prediction. Optionally, the prediction can be accompanied by “predictive noise”. Of course, there is no reason why the prediction cannot actually be a model parameter; the post-calibration uncertainty of any parameter can thereby be explored.\nThe constrained maximisation/minimisation process undertaken by PEST when it is run in “predictive analysis” mode must be undertaken following a calibration process wherein an objective function is minimised. The objective function constraint imposed during the predictive maximisation/minimisation process will be somewhat greater than the minimised objective function. Theoretically, the value of the constraining objective function can be related to a predictive confidence limit using equations provided in Doherty (2015) and derived by Cooley and Vecchia (1987), Vecchia and Cooley (1987) and Christensen and Cooley (1999). In practice, however, the constraining objective function will probably be determined subjectively, as the statistics of model-to-measurement misfit will rarely be known, given the fact that in most modelling contexts it is model imperfections, rather than measurement noise, which dictates the level of fit that can be achieved between field measurements and their model-generated counterparts.\nIn practical terms, predictive maximisation/minimisation as a means of exploring post-calibration predictive uncertainty works well where parameters are relatively few in number and where estimation of those parameters constitutes a well-posed inverse problem. If the inverse problem of model calibration is not well-posed, then prior information which encapsulates pre-calibration expected parameter values (or linear/nonlinear relationships between expected parameter values) must form a component of the calibration dataset to make it so; such prior information may need to be accompanied by a prior covariance matrix if full expression is to be given to expert knowledge. Given the manual regularisation required for formulation of a well-posed, or almost well-posed, inverse problem, determination of the relative weighting between expert-knowledge-based prior information on the one hand and measurements of system state on the other hand then becomes a problem.\nExperience demonstrates that the numerical performance of the constrained maximisation/minimisation process can be delicate. The integrity of finite-difference derivatives must be high for the process to work well – higher than it needs to be for successful minimisation of an objective function. Model numerical performance must therefore be good. While some protection against poor numerical performance can be gained through undertaking a line search in conjunction with Marquardt-lambda-based parameter upgrade testing (see below), the line search procedure is inherently serial, and hence cannot be parallelised. This limits the run times of models with which PEST can be used when undertaking predictive uncertainty analysis in this way.\nThe PEST suite provides other options for undertaking post-calibration predictive uncertainty.\nanalysis, these including linear analysis, calibration-constrained Monte Carlo analysis (of which null space Monte Carlo is an example), and its Pareto functionality. All of these can work well in highly parameterized contexts where the constrained maximisation/minimisation process which PEST undertakes when run in “predictive analysis” mode may fail. Nevertheless, this mode of operation has proven itself useful in many real-world modelling contexts, and will continue to do so in the future, provided its strengths and weaknesses are properly understood.\nThis chapter describes how to use PEST in “predictive analysis” mode. Concepts and theory are fully described in section 8.4 of Doherty (2015).\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 8. Predictive Analysis\n- **Subsection:** \n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** \n\n### Related Context\n- **Previous Summary:** An optional \"sensitivity reuse\" section (Figure 7.1, before \"parameter groups,\" after SVD/LSQR sections) controls sensitivity reuse (activated by DOSENREUSE=\"senreuse\").  SENRELTHRESH sets the relative sensitivity threshold for reuse. SENMAXREUSE sets the maximum number of parameters for reuse. SENALLCALCINT sets the interval for recalculating all sensitivities. SENPREDWEIGHT weights prediction sensitivities in \"predictive analysis\" mode. SENPIEXCLUDE excludes prior information from sensitivity calculations.\n- **Next Summary:** In \"predictive analysis\" mode, PEST finds the maximum/minimum prediction value (Figure 8.2 of Doherty 2015) where the objective function (Φ0, >Φmin) is met.  It requires a prior \"estimation\" run (Φmin). The prediction is in the \"predict\" group.  The process is iterative, using a Jacobian matrix and Marquardt lambda, optionally with a line search.  Parameter settings must match the preceding \"estimation\" run.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** c55285164f60\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 17462e455db6\n- **Next Chunk ID:** d8284352aeb8\n\n---\n\n## Context\n\n### Summary\n**PESTPP-OPT handles chance constraints (risk neutral, averse, or tolerant) by shifting constraint values based on a user-specified risk value (0.0-1.0) and the model output's standard deviation (σo).  A value of 0.5 ignores uncertainty; 0.95 applies constraints to the upper 95% confidence level.  This is based on chance-constraint programming (Charnes and Cooper 1959, etc.).**\n\n### Header\n**8.1.5 Chance Constraints**\n\n### Content\nA user of PESTPP-OPT can inform it whether he/she would like the optimization process which it implements to be risk neutral, risk averse, or risk tolerant. In the latter two cases he/she can specify the degree of aversion or tolerance that should characterize that process. Tolerance or aversion is introduced through the way in which model output uncertainty affects the imposition of optimization constraints.\nSuppose that a user specifies that a model output *o* shall have a value no greater than *b*. Suppose also that the standard deviation of post-calibration uncertainty associated with model output *o* is *σ*o (*σ*o is calculated by PESTPP-OPT using equations 8.1 to 8.3). PESTPP-OPT assumes that model output uncertainties are characterized by a normal distribution. A user can specify, in recognition of the uncertainty associated with *o*, that he/she must be 95% sure that the constraint is not violated. In this case PESTPP-OPT applies the constraint to the model output *o* plus an amount δ*o* calculated to ensure that, according to the normal probability distribution, the chances of *o* being smaller than *o*+ δ*o* are 95%. Alternatively, a user may adopt a risk tolerant strategy by specifying that he/she will be happy as long as there is a 5% chance that the constraint is respected. In that case PESTPP-OPT applies the constraint to *o* minus this same δ*o*. A risk neutral approach results in the constraint being applied to *o*. This technique of shifting model-simulated values to which constraints are applied up or down in accordance with risk tolerance or risk aversion is referred to as chance-constraint programming (Charnes and Cooper, 1959; Miller and Wagner, 1965; Tung, 1986; Wagner and Gorelick, 1987; Hantush and Marino, 1989; Chan, 1994).\nA PESTPP-OPT user must provide one number to characterize his/her approach to risk. This number must be between zero and one. A model-output-specific number, representing the uncertainty of that output, is then added or subtracted from it prior to imposition of optimization constraints on that output. Provision of a value of 0.5 for this variable (signifying risk neutrality) is equivalent to ignoring parameter, and hence predictive, uncertainty. Under these circumstances, PESTPP-OPT does not calculate model output uncertainties at all. This reduces input requirements, at the same time as it accelerates the optimization process by foregoing the need to (re)calculate the J matrix and/or y vectors of equations 8.1 to 8.3. On the other hand, a value of 0.95 specifies that constraints are applied to model outputs which are corrected to represent the upper end of the 95% one-sided confidence level of that prediction.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis\n- **Main Section:** 8. PESTPP-OPT\n- **Subsection:** 8.1 Introduction\n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** In \"predictive analysis\" mode (Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while maintaining the objective function below a threshold, assessing post-calibration uncertainty.  This works best with few parameters and a well-posed inverse problem; otherwise, use linear analysis, Monte Carlo, or Pareto methods.  The method requires high-integrity derivatives and a prior calibration process.\n\n### Related Context\n- **Previous Summary:** PESTPP-OPT minimizes a linear objective function (φ=cᵀx, Equation 8.4a) subject to linear constraints (Ax≤b, Equation 8.5).  The  c vector contains constants (often costs); x contains decision variables.  A (response matrix) is calculated using finite differences or user-supplied values.  It uses sequential linear programming (SLP, Forrest et al. 2016, Lougee-Heimer 2003, Ahlfield and Mulligan 2000) for efficient optimization, recomputing A iteratively.  The model is assumed to be calibrated.\n- **Next Summary:** PESTPP-OPT uses a PEST control file (Chapter 5) defining parameters, calibration data (with noise), decision variables, constraints, objective function, and optimization control variables (keyword-value pairs, \"++\" prefix).  It requires a calibrated model.  The details of each of these are discussed below.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 135c3f141f17\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 1af4c91b72e5\n- **Next Chunk ID:** 1eb4698ae37e\n\n---\n\n## Context\n\n### Summary\n**In \"predictive analysis\" mode (see Doherty 2015, section 8.4), PEST maximizes/minimizes a prediction while keeping the objective function below a threshold (Φ0, slightly above minimum Φmin). This method is suitable for well-behaved models with few parameters; otherwise, other methods are recommended.**\n\n### Header\n**3.3.4 Predictive Analysis Mode**\n\n### Content\nWhen PEST is run in “predictive analysis” mode it solves a constrained maximisation/minimisation problem in which a prediction of interest is maximised or minimised subject to the constraint that the objective function rises no higher than a user-specified level. Theory on which this mode of PEST’s operation is based was derived by Cooley and Vecchia (1987) and Vecchia and Cooley (1987), and is described in detail in section 8.4 of Doherty (2015).\nUse of PEST in “predictive analysis” mode should follow solution of a well posed, or only slightly ill-posed, inverse problem in which a model has been calibrated through reduction of an appropriate objective function to its minimum. Let us denote this minimised objective function as Φmin. Let Φ0 denote an objective function that is slightly higher than Φmin at which the model is deemed to be “uncalibrated” at a certain level of confidence. Let model output read by PEST that is actually a prediction, and is hence unused by the calibration process. The range of post-calibration uncertainty of this prediction can be determined through solution of two constrained optimisation problems in which the prediction is maximised, and then minimized, subject to the constraint that the objective.\nThis means of assessing predictive uncertainty can work well where a model does not have too many parameters, and where it is numerically well-behaved so that finite-difference-based derivatives of model outputs with respect to parameters have a high degree of integrity. If these conditions are not met then other methods of predictive uncertainty assessment should be pursued; these can include linear methods, null space Monte Carlo, and PEST’s “pareto” mode.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 3. What PEST Does\n- **Subsection:** 3.3 Modes of Operation\n\n### Additional Summaries\n- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: \"estimation\", \"predictive analysis\", \"regularisation\", and \"pareto\". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.\n- **Detailed Summary:** PEST is a tool that iteratively solves inverse problems in four modes: \"estimation\", \"predictive analysis\", \"regularisation\", and \"pareto\". It uses Jacobian matrices and Marquardt lambda for parameter estimation. Different methods are employed based on problem types, with options for uncertainty analysis and parallel processing to reduce computational costs.\n\n### Related Context\n- **Previous Summary:** PEST's \"regularisation\" mode uses Tikhonov regularization (see Doherty 2015), employing measurement and regularization objective functions.  A parameter covariance matrix is not recorded; however, posterior uncertainties are investigated using utilities like PREDUNC7.\n- **Next Summary:** In \"pareto\" mode, PEST explores the trade-off between objective functions (e.g., measurement vs. regularization, or data fit vs. prediction proximity).  This allows assessment of fit quality and hypothesis testing regarding predictions (see Doherty 2015, section 8.5).  Parallel processing and SVD-assist mitigate computational costs.  Linear uncertainty analysis is possible using PEST utilities.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 2e473251b7f2\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 2c26d6d34bff\n- **Next Chunk ID:** 753954871395\n\n---\n\n\nAnswer strictly following the above instructions.\n"
  }
]
```