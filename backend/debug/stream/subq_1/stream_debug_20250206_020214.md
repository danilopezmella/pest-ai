# Stream Debug - 20250206_020214

# Original Question
```
What is model calibration?
```

# Context Content
```markdown
# Search Results for: What is model calibration?

Keywords: None


## Context

### Summary
**For predictions differing from calibration measurements, predictive noise (mostly from model inadequacies) must be estimated subjectively.**

### Header
**8.3.2 Predictive Analysis Section of the PEST Control File**

### Content
Where a prediction is of an entirely different type to measurements employed in the calibration process, then the level of noise associated with that prediction (in most cases resulting from incapacity of the model to simulate all details of system behaviour which pertain to this prediction) must be guessed.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 8.3 Predictive Analysis Control Variables

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** To run PEST in "predictive analysis" mode, set PESTMODE to "prediction", define observation groups, and perform a prior "estimation" run. Adjust Marquardt lambda iteratively to maximize/minimize predictions while meeting objective function criteria. Use line search, adjust search parameters, and set termination conditions based on prediction improvement. User intervention can modify line search variables.

### Related Context
- **Previous Summary:** NPREDNORED (integer, ~4) iterations without prediction improvement triggers termination in "predictive analysis" mode.  ABSPREDSTP (real, context-dependent) and RELPREDSTP (real, ~0.005) define thresholds for prediction convergence (NPREDSTP highest/lowest predictions).  NOPTMAX sets the maximum number of iterations. User intervention (section 6.2) can adjust line search control variables.
- **Next Summary:** Adding a "predictive error" parameter (e) to the parameter set, with a prior information equation setting e=0, incorporates predictive noise into the analysis.  The weight for this equation is set based on the predictive noise standard deviation.  The model is modified to add e to the prediction before PEST processing.

### Metadata
- **Keywords:** 
- **Chunk ID:** 49cb420fc630
- **Chunk Index:** 5
- **Previous Chunk ID:** cbd30e177677
- **Next Chunk ID:** 7a418d66c68f

---

## Context

### Summary
**PARREDUCE compares simplification strategies by calculating residual covariance matrices: uncalibrated (Equation 14.2.5) and calibrated (Equation 14.2.9 for the complex model Z, Equation 14.2.16 for simplified model X, assuming C(k)=I, Equation 14.2.17).  Φx (Equation 14.2.18), the sum of Cx(r)'s diagonal elements, summarizes the impact of simplification on the objective function. Low Φx suggests sufficient parameters to achieve a good fit.**

### Header
**14.2.2 Theory**

### Content
C(r) can thus be very small. For the types of analyses that PARREDUCE is asked to perform this is fine. Its purpose is to provide a means of comparison of residuals that emerge from calibration of the Z model with those that emerge from calibration of various simplified X models.
Where an X model is calibrated in place of the Z model, equation 14.2.7 is replaced by equation 14.2.4; that is
rx = Zk – Xp (14.2.12) where p is calculated as p = Vx1Sx1-1Ux1ht (14.2.13)
Here the subscript “x” indicates that singular value decomposition is undertaken on X rather than on Z. Substitution of equation 14.2.13 and equation 14.2.1 (with ε assumed to be 0) into equation 14.2.12 yields
rx = Zk – XVx1S-1x1Utx1Zk (14.2.14) which (after a little matrix manipulation) becomes
rx = (I – Ux1Utx1)Zk = Ux2Utx2Zk (14.2.15)
The covariance matrix of residuals emerging from calibration of a simplified model is then calculated as
Cx(r) = Ux2Utx2ZC(k)ZtUx2Utx2 (14.2.16) which, if C(k) is equal to I, becomes
Cx(r) = Ux2Utx2ZZtUx2Utx2 (14.2.17)
Once again, the diagonal elements of Cx(r) represent the variances of individual elements of r; the square roots of these represent their standard deviations.
Different simplification strategies can be compared through comparing Cx(r) matrices calculated using equation 14.2.16 for different X matrices. A simple summary statistic is the sum of elements along the diagonal of Cx(r). This is denoted as Φx as it is an objective function. Thus
Φ = tr(Cx(r)) x (14.2.18)
where tr() is the matrix trace operator. Φ can be thought of as the contribution made to the overall calibration objective function by parameter simplification. If this number is low (or even zero), it indicates that the simplified model retains enough adjustable parameters to guarantee a fit with field data that is very little worse than that which would prevail through calibration of the original Z model. This does not mean that simplification is therefore “ideal”. It is possible that the simplified parameters play roles that compensate for model defects in achieving this level of fit. Nevertheless it does indicate that enough parameters exist for a good fit between model outputs and field data to be attained, and that these parameters therefore span the solution space of the Z model.
In the subsurface reservoir modelling context, different simplification strategies (embodied in different X matrices) may result from alternative representations of the presence, locations and geometries of zones of piecewise constancy reflecting rock types of contrasting, but relatively homogeneous, hydraulic properties. Lower values for Φx arising from some of these tested dispositions may indicate better representation of subsurface features in the model domain.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 14. Miscellaneous Utilities
- **Subsection:** 14.2 PARREDUCE

### Additional Summaries
- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.
- **Detailed Summary:** Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.

### Related Context
- **Previous Summary:** PARREDUCE assesses parameter simplification's impact on model-data misfit using a complex and simplified model (Equation 14.2.4: r=Zk-Xp). It calculates uncalibrated (Equation 14.2.5: C<sub>u</sub>(r)=ZC(k)Z<sup>T</sup>) and calibrated (Equation 14.2.9: C<sub>z</sub>(r)=U₂S₂²U₂<sup>T</sup>, assuming C(k)=I, Equation 14.2.11) residual covariance matrices (using SVD of Z).  It uses two PEST control files (complex and simplified) and assumes zero measurement noise and a perfect model.
- **Next Summary:** PARREDUCE compares parameter simplification strategies using two PEST control files (complex: pestfile1 with JCO file; simplified: pestfile2) and an eigenvalue threshold (eigthresh, 0.0-1.0). It calculates residual standard deviations for uncalibrated, calibrated complex, and calibrated simplified models.  The optional `/b` switch uses bounds to estimate C(k); otherwise C(k)=I.  Output (Figure 14.1) includes traces of the residual covariance matrices.  Use `parreduce pestfile1 pestfile2 eigthresh outfile [/b]`.

### Metadata
- **Keywords:** 
- **Chunk ID:** 23bc4ed1ec29
- **Chunk Index:** 2
- **Previous Chunk ID:** 6ad64ffdaa14
- **Next Chunk ID:** 9ca209c76eb4

---

## Context

### Summary
**Post-calibration parameter/prediction error variance is calculated using Equation 11.1.5 (Doherty 2015, Equation 5.5.10):  σ<sub>s-s</sub>² = y<sup>T</sup>(I-R)C(k)(I-R)<sup>T</sup>y + y<sup>T</sup>GC(ε)G<sup>T</sup>y.  R=GZ (Equation 11.1.2), where G is the parameter solution matrix and Z is the Jacobian matrix.  R and G calculations depend on the solution method and Marquardt lambda;  keep Marquardt lambda low.  The text defines variables: Z, X, T, S, λ, h, ε, Q, V, E.**

### Header
**11.1.2 Concepts**

### Content
Post-Calibration Parameter and Predictive Error
Let k represent parameters employed by a model. Let k represent the parameter set achieved through model calibration. From equation 5.5.10 of Doherty (2015) the covariance matrix of post‑calibration parameter error is calculated as
C(k ‑ k) = (I ‑ R)C(k)(I ‑ R)t + GC(Æ)Gt (11.1.1)
where
- k represents “true” model parameters (which are unknown);
- k represents calibrated model parameters;
- C(k) represents the prior parameter covariance matrix, this describing the innate variability of real‑world parameters;
- C(Æ) represents the covariance matrix of measurement/structural noise, mostly assumed to be diagonal;
- R is the so‑called “resolution matrix”; and
- G is the matrix through which estimated parameter values (i.e. the elements of k) are calculated from measurements (which are denoted as h in Doherty, 2015); G is referred to herein as the “parameter solution matrix”, or more simply as the “G matrix”.
R is related to G through the equation
R = GZ (11.1.2)
where Z specifies the relationship between model parameters and model outputs used in the calibration process (see equation 10.3.6).
Let s be a model prediction whose sensitivities to model parameters are encapsulated in the vector y. For a linear model, the “true” value of a model prediction is given by
s = ytk (11.1.3a)
while its counterpart as calculated by the calibrated model is
s = ytk (11.1.3b)
Model predictive error is then obtained as
s – s = yt(k ‑ k) = -yt(I – R)k + ytGÆ (11.1.4)
while model predictive error variance (i.e. the “variance of potential wrongness” of a prediction made by a calibrated model) is given by
2s‑s = yt(I – R)C(k)(I – R)ty + ytGC(ε)Gty (11.1.5)
Note that while derivation of these equations rests on an assumption of model linearity, they are nevertheless approximately correct when applied to many nonlinear models. With some modifications, they can also be used as a basis for nonlinear analysis; PEST’s null space Monte Carlo methodology rests on equation 11.1.1.
Calculation of the R and G Matrices
Formulas for R and G featured in the above equations depend on the method used by PEST to solve the inverse problem. For an overdetermined system, for which the regularisation opportunities offered by truncated singular value decomposition and Tikhonov schemes are not required, the resolution matrix R is simply I, the identity matrix. However in many real world cases, barely overdetermined problems are rescued from numerical instability through PEST’s use of a high‑valued Marquardt lambda (which is a de‑facto Tikhonov regularisation device). Even where mathematical regularisation is formally introduced to a real world problem, it is often insufficient to guarantee unequivocal numerical stability of solution of that problem; hence PEST will often respond by raising the value of the Marquardt lambda, this allow progress in solution of an inverse problem to be made when it may otherwise founder.
The role of the Marquardt lambda in calculation of the R and G matrices is recognised in the utility software described in the present chapter. It must be noted, however, that the Marquardt lambda is not a very good regularisation device; in many cases it can lead to inverse problem solutions which are not of minimised error variance, at the same time as it can lead to distortion of the resolution matrix. Hence, whether using one of the specialist regularisation devices offered by PEST to assist in solution of an inverse problem, or whether using manual regularisation to promulgate inverse‑problem well‑posedness, attempts should be made to keep the Marquardt lambda low.
Formulas used for calculation of R and G
Variables appearing in these formulas are as follows.
- Z This is the Jacobian matrix, which is a linearization of the relationship between model parameters and model outputs used in the calibration process. Each row of the Jacobian matrix provides derivatives of a particular model outcome for which there is a complementary field measurement with respect to all adjustable parameters. If a parameter is log‑transformed, pertinent elements of Z pertain to the log of that parameter. Note that for SVD‑assisted inversion the Z matrix refers to base parameters, not super parameters in the equations below.
- X This is the super‑parameter Jacobian matrix whose elements are derivatives of model outcomes with respect to super parameters estimated through SVD‑assisted inversion.
- The PEST‑calculated Marquardt lambda.
159
Definitions
- T The matrix of Tikhonov regularisation constraints. These constraints are assumed to be of the form Tk = 0.
- S The relative regularisation weight matrix (calculated from user-supplied regularisation weights and/or user-supplied regularisation covariance matrices).
- 2 The PEST-calculated regularisation weight factor.
- h The set of observations which constitute the calibration dataset. Æ featured in equations 11.1.1, 11.1.4 and 11.1.5 is the “noise” or “measurement error” associated with these observations.
- Q The observation weight matrix (calculated from user-supplied weights and measurement covariance matrices).
- V The matrix whose columns are orthogonal unit eigenvectors of ZtQZ (and hence of Q1/2Z) as calculated through singular value decomposition undertaken either during every iteration of the parameter estimation process (when this is achieved through truncated singular value decomposition), or at the beginning of the inversion process for determination of super parameters (if using SVD-assisted parameter estimation).
- E A diagonal matrix whose elements are the eigenvalues of ZtQZ (arranged in decreasing order) determined through singular value decomposition. The singular values of Q1/2Z are the square roots of these.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 11. Linear Error and Uncertainty – Part II
- **Subsection:** 11.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** Parallel PEST and BEOPEST parallelize model runs to reduce run time. Parallel PEST needs a run management file, while BEOPEST's is optional. Both distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Parallel PEST uses PAGENT agents, requires separate folders for agents, and shared signal files for communication. BEOPEST offers ease of use, faster communication, flexibility, and support for multiple command lines and surrogate models.
- **Detailed Summary:** Parallel PEST and BEOPEST parallelize model runs, reducing PEST run time. Parallel PEST requires a run management file, while BEOPEST's is optional. They distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Both store data in binary files for reduced memory needs.

### Related Context
- **Previous Summary:** This chapter documents older PEST utilities (largely superseded by those in the previous chapter) for parameter and predictive error analysis (not uncertainty). They require a prior model calibration run and are less general than the previous chapter's utilities.  Some users may find them useful.
- **Next Summary:** This chapter details utilities calculating R (resolution matrix) and G (parameter solution matrix) using case.jco (updated per improved parameter set, except for SVD-assist).  Equations for R and G are given for overdetermined systems (Equations 11.1.6a, 11.1.6b), Tikhonov regularization (Equations 11.1.7a, 11.1.7b), SVD (Equations 11.1.8a, 11.1.8b), and SVD-assist (Equations 11.1.9a, 11.1.9b).  Results apply to base (not super) parameters and their logs (for log-transformed parameters).  LSQR is not accommodated.

### Metadata
- **Keywords:** 
- **Chunk ID:** 8588789b5326
- **Chunk Index:** 1
- **Previous Chunk ID:** 4a5dda9e0a37
- **Next Chunk ID:** ab1abc08f45b

---

## Context

### Summary
**A missing model output file indicates model failure. A zero gradient indicates incorrect model input file names. Erratic objective function behavior suggests poor derivatives (check using JACTEST), potentially caused by insufficient precision, low increments, model numerical issues, or loose solver criteria.  Mitigation strategies include adjusting increments, using DERINCLB, tightening solver criteria, disabling adaptive time-stepping, split slope analysis, five-point stencils, or automatic user intervention.  Nonlinearity can be addressed using parameter change limits (FACPARMAX, RELPARMAX, ABSOLUTE(N)), log transformation, SCALE, or BOUNDSCALE.**

### Header
**4.19.2 Format of a Covariance Matrix File**

### Content
Before it runs the model, PEST deletes the model output files listed in the “model input/output” section of the PEST control file. These are the model output files which corresponding instruction files must read. If, for some reason, the model fails to run, these model output files will not be present. PEST will then issue an error message such as that depicted in figure 5.6. This error message is nearly always a sign that the model did not run, or did not run to completion.
5.5.3 Objective Function Gradient Zero
If the sensitivities of all model outputs to all parameters are zero, PEST issues the following error message:
Phi gradient zero in non-frozen parameter space.
This situation can arise if there is only one model input file to which there is a corresponding template file, and the name provided for this model input file is incorrect. PEST then writes parameter values to one file while the model reads another. (The PESTCHEK program can detect many errors, but it cannot detect this one.) This problem is, of course, easily rectified. It simply requires that the name of the wrong model input file be replaced by the name of the correct model input file.
If there is more than one model input file cited in the “model input/output” section of the PEST control file, and if only one of these is named incorrectly, then the problem of input file misnaming is more difficult to detect. It may be revealed through zero-valued composite sensitivities of parameters which are only written to this model input file (though this will be hidden if regularisation is employed, as the very purpose of regularisation is create sensitivity where it would otherwise not exist). It may also be revealed through the fact that parameters that are only represented in this model input file are not adjusted through the inversion process.
5.5.4 Erratic Objective Function Behaviour caused by Bad Derivatives
If PEST is working well, the objective function falls rapidly at first, then falls more slowly, and then falls no further. The transition from rapid downward movement to no movement at all is usually gradational.
Sometimes, however, the objective function falls rapidly during one iteration, and then does not fall at all during the next iteration. Sometimes it rises rapidly and then falls rapidly again. This is often a sign of problematical finite-difference derivatives.
Problematical finite-difference derivatives can have any of the following causes.
- Parameter values are not written with sufficient precision to model input files;
- Numbers are passed with less than full precision between different executables cited in a batch or script file which PEST runs as “the model”;
- Parameter increments are too low;
- The model is experiencing numerical difficulties;
- Model solver convergence criteria are not set tightly enough.
The integrity of finite-difference derivatives can be checked using the JACTEST utility described in part II of this manual. Steps which can be taken to mitigate the deleterious effects of model-corrupted derivatives include the following.
- Derivative increments can be increased;
- The DERINLB derivatives control variable can be used where low parameter increments are caused by low parameter values;
- Model solver convergence criteria can be tightened;
- If it is practical to do so, model numerical strategies such as adaptive time-stepping which may introduce a small amount of “numerical noise” to model outputs may be disabled;
- PEST’s “split slope analysis” functionality can be invoked to detect and defend against model numerical output granularity (see section 3.5.7);
- A five-point finite-difference stencil can be used (see section 3.5.2);
- PEST’s “automatic user intervention” functionality can be activated, with the DOAUI control variable set to “auid” (see section 6.4).
5.5.5 Other Factors Leading to Erratic Objective Function Behaviour
Where failure to lower the objective function, or erratic behaviour of the objective function, results from extreme problem nonlinearity rather than degraded finite-difference derivatives, this can be accommodated by placing limits on the amount that any parameter is allowed to change during any one iteration. Parameter change limits can be imposed using the FACPARMAX, RELPARMAX and ABSOLUTE(N) variables cited in the “control data” section of the PEST control file.
Log-transformation of parameters often makes a profound impact on PEST performance. As is discussed elsewhere in this manual, relationships between model outputs and model parameters are often more linear if the latter are log-transformed. Log-transformation of all parameters often accomplishes a similar outcome to normalizing parameters by their innate variabilities. This prevents super-sensitivity of those parameters whose values are expressed by numbers which are numerically small (as is often the case for recharge in a groundwater model). If log transformation is not possible because parameters may become zero or negative, then the SCALE control variable available in the “parameter data” section of the PEST control file can be used to reduce the sensitivities of individual super-sensitive parameters. The BOUNDSCALE variable that resides in the “control data” section of the PEST control file introduces global normalization of parameters with respect to their innate variabilities.
5.5.6 Excessive Number of Model Runs

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 4. The PEST Control File
- **Subsection:** 4.19 Covariance Matrix Files

### Additional Summaries
- **Higher-Level Summary:** Figure 4.2 in PEST software displays control data section variables. The text details options for writing matrices, files, and parameters, including settings for matrix and file saving, operational modes, precision, derivative handling, and convergence criteria. Optional features like sensitivity reuse and LSQR algorithm for solving inverse problems are discussed.
- **Detailed Summary:** COVFLE specifies covariance matrix files for observation groups, overriding individual weights. PEST supports various ASCII covariance matrix file formats. Different PEST versions may produce varied results for ill-posed problems. PEST run commands include switches for different functionalities and modes. Parameter estimation results include objective function, estimates, confidence limits, observations, and statistics.

### Related Context
- **Previous Summary:** PPAUSE, PUNPAUSE, PSTOP, and PSTOPST (Part II) control PEST execution via pest.stp.  <Ctrl-C> also stops PEST.  User termination is common due to poor fit, unrealistic parameters, or erratic objective function behavior. Ill-posed inverse problems are addressed using regularization, SVD, or LSQR, and RLAMFAC=-3.
- **Next Summary:** For highly parameterized models, excessive model runs for derivative calculations can be reduced by preventing premature higher-order derivative calculations (NOPTSWITCH), widening parameter bounds, using Tikhonov regularization, and setting an appropriate target objective function (Chapter 9).  Discontinuous model outputs may require global optimization methods (Chapter 16).  Parameter correlation/insensitivity (JtQJ non-invertible) is addressed by regularization, SVD, or LSQR.

### Metadata
- **Keywords:** BOUNDSCALE, DOAUI, FACPARMAX, RELPARMAX, SCALE
- **Chunk ID:** 53a1defef6a5
- **Chunk Index:** 20
- **Previous Chunk ID:** b4b75f923100
- **Next Chunk ID:** 993e9ef91c80

---

## Context

### Summary
**Tikhonov regularization provides a "fall-back" parameter condition (e.g., preferred values, homogeneity) and allows departures based on expert knowledge (covariance matrix, penalty functions).  In "regularisation" mode, PEST uses measurement (Φm) and regularization (Φr) objective functions.  Regularization constraints (assigned to "regul" groups) can be prior information equations or model-calculated observations.  A target measurement objective function can be set.**

### Header
**8.5 Model-Based Hypothesis Testing**

### Content
- Most natural systems are complex and heterogeneous. The use of many parameters allows better representation of system heterogeneity than parsimonious parameterisation. It is precisely because parameterisation detail is unlikely to be uniquely estimable that it must be represented when exploring predictive uncertainty; it is the parameters that cannot be estimated, rather than those which can, which are critical to this endeavour. Regularised inversion easily accommodates parameter nonuniqueness. Post-calibration predictive uncertainty analysis requires exploration of the effects of parameter nonuniqueness if it is to have integrity.
See Doherty (2015) for a full discussion of the advantages of highly parameterized inversion.
9.1.2 Tikhonov Regularisation
As explained in detail by Doherty (2015), appropriately formulated Tikhonov regularisation
provides a “fall-back position” for some or all model parameters. This describes a condition that, according to expert knowledge, they should satisfy unless there is information in the calibration dataset to the contrary. This fall-back condition can be formulated as preferred values for some or all parameters, homogeneity, piecewise homogeneity, minimum curvature of parameter fields, combinations of these, or other conditions altogether.
As well as expressing a preferred parameter condition, Tikhonov regularisation should explicitly or implicitly express the way in which departures from this condition can arise. This can be done through a covariance matrix. Alternatively, it can be done through mechanisms such as “sharpness filters” which penalize the emergence of heterogeneity unless it has sharp edges. Another possibility is to formulate linear and nonlinear “heterogeneity penalty functions” which reward the emergence of heterogeneity at certain locations and in certain directions, and penalise its emergence at other locations and in other directions. In short, Tikhonov regularisation should comprise a mathematical formulation of expert knowledge that allows the inversion process to “join the dots” between the limited parameterisation detail that can be estimated on the basis of the calibration dataset in such a way that the parameter field which emerges from the Tikhonov-regularised inversion process is as compatible with expert knowledge as possible, while allowing the model to replicate field measurements.
Ideally, all parameters involved in the inversion process should feature in Tikhonov regularisation. This ensures that they are all provided with both a fall-back position, and with an optimal means of departing from that fall-back position.
9.1.3 Measurement and Regularization Objective Functions
When PEST is run in “regularisation” mode it defines two objective functions instead of one. The first is the measurement objective function, designated as Φm. This is similar to the traditional objective function that PEST uses when run in “estimation” mode in that it constitutes a weighted least squares measure of the discrepancies between field measurements and their model-generated counterparts. The second is the regularisation objective function, designated as Φ. This constitutes a weighted least squares measure of the discrepancies between parameters and their preferred conditions.
As stated above, preferred parameter conditions can be simple or complex. The simplest form of regularisation is to assign every estimated parameter a preferred value (normally equal to its initial value). This is easily accomplished using the ADDREG1 utility described in part II of this manual. A series of prior information equations encapsulate this form of regularisation, with one prior information equation pertaining to each parameter. Each prior information equation is then of the following form.
pi1 1.0 * par1 = 10.0 1.0 regul1 or (if a parameter is log-transformed) pi1 1.0 * log(par1) = 1.0 1.0 regul1
To the extent that the “par1” parameter which features in the above equations differs from 10.0, a non-zero residual occurs, and the regularisation objective function itself becomes non-zero.
Prior information can be used to express differences between parameter values or, if parameters are log-transformed, quotients between parameter values. For example pi2 1.0 * par1 – 1.0 * par2 = 0.0 1.0 regul2
or (if “par1” and “par2” are log-transformed)
pi2 1.0 * log(par1) – 1.0 * log(par2) = 0.0 1.0 regul2
To the extent that “par1” differs in value from “par2”, these equations acquire a non-zero residual. The regularisation objective function is then non-zero.
It is not necessary that Tikhonov constraints be expressed as prior information equations. They can be calculated by the model rather than by PEST and thus be “observations”. Thus they do not need to be linear. Nor do they even need to be comprised of simple equality and difference relationships between parameters; however, of course, they must have some sensitivity to parameters and thus must all feature one or more parameters in some way.
In short, regularisation observations and prior information equations are just like other observations and prior information equations. They have an observed value and a model-calculated value. The difference between these constitutes a residual. Each is assigned a weight. Collectively a group of them can be assigned a covariance matrix. However the distinguishing feature of all of them is that they must be assigned to an observation group whose name begins with “regul”. The regularisation objective function is simply the component of the total objective function that is summed over all observations and prior information equations that belong to observation groups whose names begin with “regul”. In contrast, the measurement objective function is that component of the total objective function that is summed over all observations and prior information equations that belong to observation groups whose names do not begin with “regul”.
9.1.4 Target Measurement Objective Function

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** In "regularisation" mode, PEST balances prior information and measurement weights for predictive analysis (model-based hypothesis testing, section 8.5 of Doherty 2015). A "predict" group (one observation) helps identify parameter sets allowing an undesirable prediction while fitting historical data. Tikhonov regularization handles many parameters, minimizing error variance and ensuring numerical stability.  ASSESSPAR (Part II) assesses parameter reasonableness.
- **Next Summary:** To avoid overfitting with many parameters, PEST's Tikhonov regularization uses a target measurement objective function (Φtm, PHIMLIM).  PEST minimizes the regularization objective function (Φr), constrained by Φm = Φtm. A global multiplier (µ) is applied to regularization weights to achieve this;  it's adjusted per iteration.  Inter-regularisation group weight adjustment occurs beforehand (IREGADJ).

### Metadata
- **Keywords:** 
- **Chunk ID:** 9036138cc854
- **Chunk Index:** 2
- **Previous Chunk ID:** 28d98579ea1b
- **Next Chunk ID:** d46940ffa7a8

---

```

# System Prompt
```

You are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:

1. **Direct Answer First:**  
   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.
   - Use the following structure:

     **1) Definition**  
     - Provide a concise definition.  
     - Cite source(s) using the format "File: [filename], Section: [header]".

     **2) Possible Values**  
     - Describe valid or recognized values (including defaults if specified).  
     - Cite source(s).

     **3) Implications**  
     - Explain usage considerations or consequences for each value.  
     - If the documentation does not provide this information, state: "Information not available in the provided content. "

     **4) Practical Usage Notes**  
     - Include usage notes or examples only if explicitly provided in the documentation.  
     - Otherwise, state: "No usage notes found in the provided content."

     **5) Keywords**  
     - List any associated keywords as found in the documentation.  
     - If none are provided, state: "No keywords found in the provided content"

     **6) Follow-up References**  
     - Point out additional references or relevant sections from the documentation, if applicable.

2. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.
   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.
   - Each question should reference specific sections from the documentation if available.

3. **Important Instructions:**  
   - **Do not mention internal processes, "chunks," or retrieval steps.**  
   - **Do not include any self-commentary or extra explanations beyond the structure above.**  
   - Use only the documentation provided in `{context}`.

Answer strictly following the structure and rules above.

```

# Full User Message
```

Question: What is model calibration?

Please provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:

1. **Cite Sources:**  
   - Use the format "File: [filename], Section: [header]" whenever you reference specific details.

2. **Include Examples:**  
   - Provide relevant examples from the documentation if available.

3. **Note Limitations:**  
   - If the documentation is incomplete or ambiguous, explicitly state: "Information not available in the provided content. I don't know."

4. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.
   - **Do not provide answers to these follow-up questions.**
   - Each question should reference specific sections from the documentation if applicable.

5. **Keywords Section:**  
   - Include a "Keywords" section if applicable, listing any associated keywords as found in the documentation.
   - If none are provided, state: "No keywords found in the provided content. I don't know."

6. **Avoid Internal Details:**  
   - Do not mention internal processes, such as "chunks" or retrieval steps.
   - Do not include any self-commentary or extra explanations beyond what is requested.

7. **Be Concise and Accurate:**  
   - Do not invent details or assumptions. If information is missing, state: "Information not available in the provided content. I don't know."

**Available Documentation with Metadata:**
# Search Results for: What is model calibration?

Keywords: None


## Context

### Summary
**For predictions differing from calibration measurements, predictive noise (mostly from model inadequacies) must be estimated subjectively.**

### Header
**8.3.2 Predictive Analysis Section of the PEST Control File**

### Content
Where a prediction is of an entirely different type to measurements employed in the calibration process, then the level of noise associated with that prediction (in most cases resulting from incapacity of the model to simulate all details of system behaviour which pertain to this prediction) must be guessed.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 8.3 Predictive Analysis Control Variables

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** To run PEST in "predictive analysis" mode, set PESTMODE to "prediction", define observation groups, and perform a prior "estimation" run. Adjust Marquardt lambda iteratively to maximize/minimize predictions while meeting objective function criteria. Use line search, adjust search parameters, and set termination conditions based on prediction improvement. User intervention can modify line search variables.

### Related Context
- **Previous Summary:** NPREDNORED (integer, ~4) iterations without prediction improvement triggers termination in "predictive analysis" mode.  ABSPREDSTP (real, context-dependent) and RELPREDSTP (real, ~0.005) define thresholds for prediction convergence (NPREDSTP highest/lowest predictions).  NOPTMAX sets the maximum number of iterations. User intervention (section 6.2) can adjust line search control variables.
- **Next Summary:** Adding a "predictive error" parameter (e) to the parameter set, with a prior information equation setting e=0, incorporates predictive noise into the analysis.  The weight for this equation is set based on the predictive noise standard deviation.  The model is modified to add e to the prediction before PEST processing.

### Metadata
- **Keywords:** 
- **Chunk ID:** 49cb420fc630
- **Chunk Index:** 5
- **Previous Chunk ID:** cbd30e177677
- **Next Chunk ID:** 7a418d66c68f

---

## Context

### Summary
**PARREDUCE compares simplification strategies by calculating residual covariance matrices: uncalibrated (Equation 14.2.5) and calibrated (Equation 14.2.9 for the complex model Z, Equation 14.2.16 for simplified model X, assuming C(k)=I, Equation 14.2.17).  Φx (Equation 14.2.18), the sum of Cx(r)'s diagonal elements, summarizes the impact of simplification on the objective function. Low Φx suggests sufficient parameters to achieve a good fit.**

### Header
**14.2.2 Theory**

### Content
C(r) can thus be very small. For the types of analyses that PARREDUCE is asked to perform this is fine. Its purpose is to provide a means of comparison of residuals that emerge from calibration of the Z model with those that emerge from calibration of various simplified X models.
Where an X model is calibrated in place of the Z model, equation 14.2.7 is replaced by equation 14.2.4; that is
rx = Zk – Xp (14.2.12) where p is calculated as p = Vx1Sx1-1Ux1ht (14.2.13)
Here the subscript “x” indicates that singular value decomposition is undertaken on X rather than on Z. Substitution of equation 14.2.13 and equation 14.2.1 (with ε assumed to be 0) into equation 14.2.12 yields
rx = Zk – XVx1S-1x1Utx1Zk (14.2.14) which (after a little matrix manipulation) becomes
rx = (I – Ux1Utx1)Zk = Ux2Utx2Zk (14.2.15)
The covariance matrix of residuals emerging from calibration of a simplified model is then calculated as
Cx(r) = Ux2Utx2ZC(k)ZtUx2Utx2 (14.2.16) which, if C(k) is equal to I, becomes
Cx(r) = Ux2Utx2ZZtUx2Utx2 (14.2.17)
Once again, the diagonal elements of Cx(r) represent the variances of individual elements of r; the square roots of these represent their standard deviations.
Different simplification strategies can be compared through comparing Cx(r) matrices calculated using equation 14.2.16 for different X matrices. A simple summary statistic is the sum of elements along the diagonal of Cx(r). This is denoted as Φx as it is an objective function. Thus
Φ = tr(Cx(r)) x (14.2.18)
where tr() is the matrix trace operator. Φ can be thought of as the contribution made to the overall calibration objective function by parameter simplification. If this number is low (or even zero), it indicates that the simplified model retains enough adjustable parameters to guarantee a fit with field data that is very little worse than that which would prevail through calibration of the original Z model. This does not mean that simplification is therefore “ideal”. It is possible that the simplified parameters play roles that compensate for model defects in achieving this level of fit. Nevertheless it does indicate that enough parameters exist for a good fit between model outputs and field data to be attained, and that these parameters therefore span the solution space of the Z model.
In the subsurface reservoir modelling context, different simplification strategies (embodied in different X matrices) may result from alternative representations of the presence, locations and geometries of zones of piecewise constancy reflecting rock types of contrasting, but relatively homogeneous, hydraulic properties. Lower values for Φx arising from some of these tested dispositions may indicate better representation of subsurface features in the model domain.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 14. Miscellaneous Utilities
- **Subsection:** 14.2 PARREDUCE

### Additional Summaries
- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.
- **Detailed Summary:** Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.

### Related Context
- **Previous Summary:** PARREDUCE assesses parameter simplification's impact on model-data misfit using a complex and simplified model (Equation 14.2.4: r=Zk-Xp). It calculates uncalibrated (Equation 14.2.5: C<sub>u</sub>(r)=ZC(k)Z<sup>T</sup>) and calibrated (Equation 14.2.9: C<sub>z</sub>(r)=U₂S₂²U₂<sup>T</sup>, assuming C(k)=I, Equation 14.2.11) residual covariance matrices (using SVD of Z).  It uses two PEST control files (complex and simplified) and assumes zero measurement noise and a perfect model.
- **Next Summary:** PARREDUCE compares parameter simplification strategies using two PEST control files (complex: pestfile1 with JCO file; simplified: pestfile2) and an eigenvalue threshold (eigthresh, 0.0-1.0). It calculates residual standard deviations for uncalibrated, calibrated complex, and calibrated simplified models.  The optional `/b` switch uses bounds to estimate C(k); otherwise C(k)=I.  Output (Figure 14.1) includes traces of the residual covariance matrices.  Use `parreduce pestfile1 pestfile2 eigthresh outfile [/b]`.

### Metadata
- **Keywords:** 
- **Chunk ID:** 23bc4ed1ec29
- **Chunk Index:** 2
- **Previous Chunk ID:** 6ad64ffdaa14
- **Next Chunk ID:** 9ca209c76eb4

---

## Context

### Summary
**Post-calibration parameter/prediction error variance is calculated using Equation 11.1.5 (Doherty 2015, Equation 5.5.10):  σ<sub>s-s</sub>² = y<sup>T</sup>(I-R)C(k)(I-R)<sup>T</sup>y + y<sup>T</sup>GC(ε)G<sup>T</sup>y.  R=GZ (Equation 11.1.2), where G is the parameter solution matrix and Z is the Jacobian matrix.  R and G calculations depend on the solution method and Marquardt lambda;  keep Marquardt lambda low.  The text defines variables: Z, X, T, S, λ, h, ε, Q, V, E.**

### Header
**11.1.2 Concepts**

### Content
Post-Calibration Parameter and Predictive Error
Let k represent parameters employed by a model. Let k represent the parameter set achieved through model calibration. From equation 5.5.10 of Doherty (2015) the covariance matrix of post‑calibration parameter error is calculated as
C(k ‑ k) = (I ‑ R)C(k)(I ‑ R)t + GC(Æ)Gt (11.1.1)
where
- k represents “true” model parameters (which are unknown);
- k represents calibrated model parameters;
- C(k) represents the prior parameter covariance matrix, this describing the innate variability of real‑world parameters;
- C(Æ) represents the covariance matrix of measurement/structural noise, mostly assumed to be diagonal;
- R is the so‑called “resolution matrix”; and
- G is the matrix through which estimated parameter values (i.e. the elements of k) are calculated from measurements (which are denoted as h in Doherty, 2015); G is referred to herein as the “parameter solution matrix”, or more simply as the “G matrix”.
R is related to G through the equation
R = GZ (11.1.2)
where Z specifies the relationship between model parameters and model outputs used in the calibration process (see equation 10.3.6).
Let s be a model prediction whose sensitivities to model parameters are encapsulated in the vector y. For a linear model, the “true” value of a model prediction is given by
s = ytk (11.1.3a)
while its counterpart as calculated by the calibrated model is
s = ytk (11.1.3b)
Model predictive error is then obtained as
s – s = yt(k ‑ k) = -yt(I – R)k + ytGÆ (11.1.4)
while model predictive error variance (i.e. the “variance of potential wrongness” of a prediction made by a calibrated model) is given by
2s‑s = yt(I – R)C(k)(I – R)ty + ytGC(ε)Gty (11.1.5)
Note that while derivation of these equations rests on an assumption of model linearity, they are nevertheless approximately correct when applied to many nonlinear models. With some modifications, they can also be used as a basis for nonlinear analysis; PEST’s null space Monte Carlo methodology rests on equation 11.1.1.
Calculation of the R and G Matrices
Formulas for R and G featured in the above equations depend on the method used by PEST to solve the inverse problem. For an overdetermined system, for which the regularisation opportunities offered by truncated singular value decomposition and Tikhonov schemes are not required, the resolution matrix R is simply I, the identity matrix. However in many real world cases, barely overdetermined problems are rescued from numerical instability through PEST’s use of a high‑valued Marquardt lambda (which is a de‑facto Tikhonov regularisation device). Even where mathematical regularisation is formally introduced to a real world problem, it is often insufficient to guarantee unequivocal numerical stability of solution of that problem; hence PEST will often respond by raising the value of the Marquardt lambda, this allow progress in solution of an inverse problem to be made when it may otherwise founder.
The role of the Marquardt lambda in calculation of the R and G matrices is recognised in the utility software described in the present chapter. It must be noted, however, that the Marquardt lambda is not a very good regularisation device; in many cases it can lead to inverse problem solutions which are not of minimised error variance, at the same time as it can lead to distortion of the resolution matrix. Hence, whether using one of the specialist regularisation devices offered by PEST to assist in solution of an inverse problem, or whether using manual regularisation to promulgate inverse‑problem well‑posedness, attempts should be made to keep the Marquardt lambda low.
Formulas used for calculation of R and G
Variables appearing in these formulas are as follows.
- Z This is the Jacobian matrix, which is a linearization of the relationship between model parameters and model outputs used in the calibration process. Each row of the Jacobian matrix provides derivatives of a particular model outcome for which there is a complementary field measurement with respect to all adjustable parameters. If a parameter is log‑transformed, pertinent elements of Z pertain to the log of that parameter. Note that for SVD‑assisted inversion the Z matrix refers to base parameters, not super parameters in the equations below.
- X This is the super‑parameter Jacobian matrix whose elements are derivatives of model outcomes with respect to super parameters estimated through SVD‑assisted inversion.
- The PEST‑calculated Marquardt lambda.
159
Definitions
- T The matrix of Tikhonov regularisation constraints. These constraints are assumed to be of the form Tk = 0.
- S The relative regularisation weight matrix (calculated from user-supplied regularisation weights and/or user-supplied regularisation covariance matrices).
- 2 The PEST-calculated regularisation weight factor.
- h The set of observations which constitute the calibration dataset. Æ featured in equations 11.1.1, 11.1.4 and 11.1.5 is the “noise” or “measurement error” associated with these observations.
- Q The observation weight matrix (calculated from user-supplied weights and measurement covariance matrices).
- V The matrix whose columns are orthogonal unit eigenvectors of ZtQZ (and hence of Q1/2Z) as calculated through singular value decomposition undertaken either during every iteration of the parameter estimation process (when this is achieved through truncated singular value decomposition), or at the beginning of the inversion process for determination of super parameters (if using SVD-assisted parameter estimation).
- E A diagonal matrix whose elements are the eigenvalues of ZtQZ (arranged in decreasing order) determined through singular value decomposition. The singular values of Q1/2Z are the square roots of these.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 11. Linear Error and Uncertainty – Part II
- **Subsection:** 11.1 Introduction

### Additional Summaries
- **Higher-Level Summary:** Parallel PEST and BEOPEST parallelize model runs to reduce run time. Parallel PEST needs a run management file, while BEOPEST's is optional. Both distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Parallel PEST uses PAGENT agents, requires separate folders for agents, and shared signal files for communication. BEOPEST offers ease of use, faster communication, flexibility, and support for multiple command lines and surrogate models.
- **Detailed Summary:** Parallel PEST and BEOPEST parallelize model runs, reducing PEST run time. Parallel PEST requires a run management file, while BEOPEST's is optional. They distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Both store data in binary files for reduced memory needs.

### Related Context
- **Previous Summary:** This chapter documents older PEST utilities (largely superseded by those in the previous chapter) for parameter and predictive error analysis (not uncertainty). They require a prior model calibration run and are less general than the previous chapter's utilities.  Some users may find them useful.
- **Next Summary:** This chapter details utilities calculating R (resolution matrix) and G (parameter solution matrix) using case.jco (updated per improved parameter set, except for SVD-assist).  Equations for R and G are given for overdetermined systems (Equations 11.1.6a, 11.1.6b), Tikhonov regularization (Equations 11.1.7a, 11.1.7b), SVD (Equations 11.1.8a, 11.1.8b), and SVD-assist (Equations 11.1.9a, 11.1.9b).  Results apply to base (not super) parameters and their logs (for log-transformed parameters).  LSQR is not accommodated.

### Metadata
- **Keywords:** 
- **Chunk ID:** 8588789b5326
- **Chunk Index:** 1
- **Previous Chunk ID:** 4a5dda9e0a37
- **Next Chunk ID:** ab1abc08f45b

---

## Context

### Summary
**A missing model output file indicates model failure. A zero gradient indicates incorrect model input file names. Erratic objective function behavior suggests poor derivatives (check using JACTEST), potentially caused by insufficient precision, low increments, model numerical issues, or loose solver criteria.  Mitigation strategies include adjusting increments, using DERINCLB, tightening solver criteria, disabling adaptive time-stepping, split slope analysis, five-point stencils, or automatic user intervention.  Nonlinearity can be addressed using parameter change limits (FACPARMAX, RELPARMAX, ABSOLUTE(N)), log transformation, SCALE, or BOUNDSCALE.**

### Header
**4.19.2 Format of a Covariance Matrix File**

### Content
Before it runs the model, PEST deletes the model output files listed in the “model input/output” section of the PEST control file. These are the model output files which corresponding instruction files must read. If, for some reason, the model fails to run, these model output files will not be present. PEST will then issue an error message such as that depicted in figure 5.6. This error message is nearly always a sign that the model did not run, or did not run to completion.
5.5.3 Objective Function Gradient Zero
If the sensitivities of all model outputs to all parameters are zero, PEST issues the following error message:
Phi gradient zero in non-frozen parameter space.
This situation can arise if there is only one model input file to which there is a corresponding template file, and the name provided for this model input file is incorrect. PEST then writes parameter values to one file while the model reads another. (The PESTCHEK program can detect many errors, but it cannot detect this one.) This problem is, of course, easily rectified. It simply requires that the name of the wrong model input file be replaced by the name of the correct model input file.
If there is more than one model input file cited in the “model input/output” section of the PEST control file, and if only one of these is named incorrectly, then the problem of input file misnaming is more difficult to detect. It may be revealed through zero-valued composite sensitivities of parameters which are only written to this model input file (though this will be hidden if regularisation is employed, as the very purpose of regularisation is create sensitivity where it would otherwise not exist). It may also be revealed through the fact that parameters that are only represented in this model input file are not adjusted through the inversion process.
5.5.4 Erratic Objective Function Behaviour caused by Bad Derivatives
If PEST is working well, the objective function falls rapidly at first, then falls more slowly, and then falls no further. The transition from rapid downward movement to no movement at all is usually gradational.
Sometimes, however, the objective function falls rapidly during one iteration, and then does not fall at all during the next iteration. Sometimes it rises rapidly and then falls rapidly again. This is often a sign of problematical finite-difference derivatives.
Problematical finite-difference derivatives can have any of the following causes.
- Parameter values are not written with sufficient precision to model input files;
- Numbers are passed with less than full precision between different executables cited in a batch or script file which PEST runs as “the model”;
- Parameter increments are too low;
- The model is experiencing numerical difficulties;
- Model solver convergence criteria are not set tightly enough.
The integrity of finite-difference derivatives can be checked using the JACTEST utility described in part II of this manual. Steps which can be taken to mitigate the deleterious effects of model-corrupted derivatives include the following.
- Derivative increments can be increased;
- The DERINLB derivatives control variable can be used where low parameter increments are caused by low parameter values;
- Model solver convergence criteria can be tightened;
- If it is practical to do so, model numerical strategies such as adaptive time-stepping which may introduce a small amount of “numerical noise” to model outputs may be disabled;
- PEST’s “split slope analysis” functionality can be invoked to detect and defend against model numerical output granularity (see section 3.5.7);
- A five-point finite-difference stencil can be used (see section 3.5.2);
- PEST’s “automatic user intervention” functionality can be activated, with the DOAUI control variable set to “auid” (see section 6.4).
5.5.5 Other Factors Leading to Erratic Objective Function Behaviour
Where failure to lower the objective function, or erratic behaviour of the objective function, results from extreme problem nonlinearity rather than degraded finite-difference derivatives, this can be accommodated by placing limits on the amount that any parameter is allowed to change during any one iteration. Parameter change limits can be imposed using the FACPARMAX, RELPARMAX and ABSOLUTE(N) variables cited in the “control data” section of the PEST control file.
Log-transformation of parameters often makes a profound impact on PEST performance. As is discussed elsewhere in this manual, relationships between model outputs and model parameters are often more linear if the latter are log-transformed. Log-transformation of all parameters often accomplishes a similar outcome to normalizing parameters by their innate variabilities. This prevents super-sensitivity of those parameters whose values are expressed by numbers which are numerically small (as is often the case for recharge in a groundwater model). If log transformation is not possible because parameters may become zero or negative, then the SCALE control variable available in the “parameter data” section of the PEST control file can be used to reduce the sensitivities of individual super-sensitive parameters. The BOUNDSCALE variable that resides in the “control data” section of the PEST control file introduces global normalization of parameters with respect to their innate variabilities.
5.5.6 Excessive Number of Model Runs

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 4. The PEST Control File
- **Subsection:** 4.19 Covariance Matrix Files

### Additional Summaries
- **Higher-Level Summary:** Figure 4.2 in PEST software displays control data section variables. The text details options for writing matrices, files, and parameters, including settings for matrix and file saving, operational modes, precision, derivative handling, and convergence criteria. Optional features like sensitivity reuse and LSQR algorithm for solving inverse problems are discussed.
- **Detailed Summary:** COVFLE specifies covariance matrix files for observation groups, overriding individual weights. PEST supports various ASCII covariance matrix file formats. Different PEST versions may produce varied results for ill-posed problems. PEST run commands include switches for different functionalities and modes. Parameter estimation results include objective function, estimates, confidence limits, observations, and statistics.

### Related Context
- **Previous Summary:** PPAUSE, PUNPAUSE, PSTOP, and PSTOPST (Part II) control PEST execution via pest.stp.  <Ctrl-C> also stops PEST.  User termination is common due to poor fit, unrealistic parameters, or erratic objective function behavior. Ill-posed inverse problems are addressed using regularization, SVD, or LSQR, and RLAMFAC=-3.
- **Next Summary:** For highly parameterized models, excessive model runs for derivative calculations can be reduced by preventing premature higher-order derivative calculations (NOPTSWITCH), widening parameter bounds, using Tikhonov regularization, and setting an appropriate target objective function (Chapter 9).  Discontinuous model outputs may require global optimization methods (Chapter 16).  Parameter correlation/insensitivity (JtQJ non-invertible) is addressed by regularization, SVD, or LSQR.

### Metadata
- **Keywords:** BOUNDSCALE, DOAUI, FACPARMAX, RELPARMAX, SCALE
- **Chunk ID:** 53a1defef6a5
- **Chunk Index:** 20
- **Previous Chunk ID:** b4b75f923100
- **Next Chunk ID:** 993e9ef91c80

---

## Context

### Summary
**Tikhonov regularization provides a "fall-back" parameter condition (e.g., preferred values, homogeneity) and allows departures based on expert knowledge (covariance matrix, penalty functions).  In "regularisation" mode, PEST uses measurement (Φm) and regularization (Φr) objective functions.  Regularization constraints (assigned to "regul" groups) can be prior information equations or model-calculated observations.  A target measurement objective function can be set.**

### Header
**8.5 Model-Based Hypothesis Testing**

### Content
- Most natural systems are complex and heterogeneous. The use of many parameters allows better representation of system heterogeneity than parsimonious parameterisation. It is precisely because parameterisation detail is unlikely to be uniquely estimable that it must be represented when exploring predictive uncertainty; it is the parameters that cannot be estimated, rather than those which can, which are critical to this endeavour. Regularised inversion easily accommodates parameter nonuniqueness. Post-calibration predictive uncertainty analysis requires exploration of the effects of parameter nonuniqueness if it is to have integrity.
See Doherty (2015) for a full discussion of the advantages of highly parameterized inversion.
9.1.2 Tikhonov Regularisation
As explained in detail by Doherty (2015), appropriately formulated Tikhonov regularisation
provides a “fall-back position” for some or all model parameters. This describes a condition that, according to expert knowledge, they should satisfy unless there is information in the calibration dataset to the contrary. This fall-back condition can be formulated as preferred values for some or all parameters, homogeneity, piecewise homogeneity, minimum curvature of parameter fields, combinations of these, or other conditions altogether.
As well as expressing a preferred parameter condition, Tikhonov regularisation should explicitly or implicitly express the way in which departures from this condition can arise. This can be done through a covariance matrix. Alternatively, it can be done through mechanisms such as “sharpness filters” which penalize the emergence of heterogeneity unless it has sharp edges. Another possibility is to formulate linear and nonlinear “heterogeneity penalty functions” which reward the emergence of heterogeneity at certain locations and in certain directions, and penalise its emergence at other locations and in other directions. In short, Tikhonov regularisation should comprise a mathematical formulation of expert knowledge that allows the inversion process to “join the dots” between the limited parameterisation detail that can be estimated on the basis of the calibration dataset in such a way that the parameter field which emerges from the Tikhonov-regularised inversion process is as compatible with expert knowledge as possible, while allowing the model to replicate field measurements.
Ideally, all parameters involved in the inversion process should feature in Tikhonov regularisation. This ensures that they are all provided with both a fall-back position, and with an optimal means of departing from that fall-back position.
9.1.3 Measurement and Regularization Objective Functions
When PEST is run in “regularisation” mode it defines two objective functions instead of one. The first is the measurement objective function, designated as Φm. This is similar to the traditional objective function that PEST uses when run in “estimation” mode in that it constitutes a weighted least squares measure of the discrepancies between field measurements and their model-generated counterparts. The second is the regularisation objective function, designated as Φ. This constitutes a weighted least squares measure of the discrepancies between parameters and their preferred conditions.
As stated above, preferred parameter conditions can be simple or complex. The simplest form of regularisation is to assign every estimated parameter a preferred value (normally equal to its initial value). This is easily accomplished using the ADDREG1 utility described in part II of this manual. A series of prior information equations encapsulate this form of regularisation, with one prior information equation pertaining to each parameter. Each prior information equation is then of the following form.
pi1 1.0 * par1 = 10.0 1.0 regul1 or (if a parameter is log-transformed) pi1 1.0 * log(par1) = 1.0 1.0 regul1
To the extent that the “par1” parameter which features in the above equations differs from 10.0, a non-zero residual occurs, and the regularisation objective function itself becomes non-zero.
Prior information can be used to express differences between parameter values or, if parameters are log-transformed, quotients between parameter values. For example pi2 1.0 * par1 – 1.0 * par2 = 0.0 1.0 regul2
or (if “par1” and “par2” are log-transformed)
pi2 1.0 * log(par1) – 1.0 * log(par2) = 0.0 1.0 regul2
To the extent that “par1” differs in value from “par2”, these equations acquire a non-zero residual. The regularisation objective function is then non-zero.
It is not necessary that Tikhonov constraints be expressed as prior information equations. They can be calculated by the model rather than by PEST and thus be “observations”. Thus they do not need to be linear. Nor do they even need to be comprised of simple equality and difference relationships between parameters; however, of course, they must have some sensitivity to parameters and thus must all feature one or more parameters in some way.
In short, regularisation observations and prior information equations are just like other observations and prior information equations. They have an observed value and a model-calculated value. The difference between these constitutes a residual. Each is assigned a weight. Collectively a group of them can be assigned a covariance matrix. However the distinguishing feature of all of them is that they must be assigned to an observation group whose name begins with “regul”. The regularisation objective function is simply the component of the total objective function that is summed over all observations and prior information equations that belong to observation groups whose names begin with “regul”. In contrast, the measurement objective function is that component of the total objective function that is summed over all observations and prior information equations that belong to observation groups whose names do not begin with “regul”.
9.1.4 Target Measurement Objective Function

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 8. Predictive Analysis
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** In "regularisation" mode, PEST balances prior information and measurement weights for predictive analysis (model-based hypothesis testing, section 8.5 of Doherty 2015). A "predict" group (one observation) helps identify parameter sets allowing an undesirable prediction while fitting historical data. Tikhonov regularization handles many parameters, minimizing error variance and ensuring numerical stability.  ASSESSPAR (Part II) assesses parameter reasonableness.
- **Next Summary:** To avoid overfitting with many parameters, PEST's Tikhonov regularization uses a target measurement objective function (Φtm, PHIMLIM).  PEST minimizes the regularization objective function (Φr), constrained by Φm = Φtm. A global multiplier (µ) is applied to regularization weights to achieve this;  it's adjusted per iteration.  Inter-regularisation group weight adjustment occurs beforehand (IREGADJ).

### Metadata
- **Keywords:** 
- **Chunk ID:** 9036138cc854
- **Chunk Index:** 2
- **Previous Chunk ID:** 28d98579ea1b
- **Next Chunk ID:** d46940ffa7a8

---


Answer strictly following the above instructions.

```

# Complete Messages Array
```json
[
  {
    "role": "system",
    "content": "\nYou are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:\n\n1. **Direct Answer First:**  \n   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.\n   - Use the following structure:\n\n     **1) Definition**  \n     - Provide a concise definition.  \n     - Cite source(s) using the format \"File: [filename], Section: [header]\".\n\n     **2) Possible Values**  \n     - Describe valid or recognized values (including defaults if specified).  \n     - Cite source(s).\n\n     **3) Implications**  \n     - Explain usage considerations or consequences for each value.  \n     - If the documentation does not provide this information, state: \"Information not available in the provided content. \"\n\n     **4) Practical Usage Notes**  \n     - Include usage notes or examples only if explicitly provided in the documentation.  \n     - Otherwise, state: \"No usage notes found in the provided content.\"\n\n     **5) Keywords**  \n     - List any associated keywords as found in the documentation.  \n     - If none are provided, state: \"No keywords found in the provided content\"\n\n     **6) Follow-up References**  \n     - Point out additional references or relevant sections from the documentation, if applicable.\n\n2. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.\n   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.\n   - Each question should reference specific sections from the documentation if available.\n\n3. **Important Instructions:**  \n   - **Do not mention internal processes, \"chunks,\" or retrieval steps.**  \n   - **Do not include any self-commentary or extra explanations beyond the structure above.**  \n   - Use only the documentation provided in `{context}`.\n\nAnswer strictly following the structure and rules above.\n"
  },
  {
    "role": "user",
    "content": "\nQuestion: What is model calibration?\n\nPlease provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:\n\n1. **Cite Sources:**  \n   - Use the format \"File: [filename], Section: [header]\" whenever you reference specific details.\n\n2. **Include Examples:**  \n   - Provide relevant examples from the documentation if available.\n\n3. **Note Limitations:**  \n   - If the documentation is incomplete or ambiguous, explicitly state: \"Information not available in the provided content. I don't know.\"\n\n4. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.\n   - **Do not provide answers to these follow-up questions.**\n   - Each question should reference specific sections from the documentation if applicable.\n\n5. **Keywords Section:**  \n   - Include a \"Keywords\" section if applicable, listing any associated keywords as found in the documentation.\n   - If none are provided, state: \"No keywords found in the provided content. I don't know.\"\n\n6. **Avoid Internal Details:**  \n   - Do not mention internal processes, such as \"chunks\" or retrieval steps.\n   - Do not include any self-commentary or extra explanations beyond what is requested.\n\n7. **Be Concise and Accurate:**  \n   - Do not invent details or assumptions. If information is missing, state: \"Information not available in the provided content. I don't know.\"\n\n**Available Documentation with Metadata:**\n# Search Results for: What is model calibration?\n\nKeywords: None\n\n\n## Context\n\n### Summary\n**For predictions differing from calibration measurements, predictive noise (mostly from model inadequacies) must be estimated subjectively.**\n\n### Header\n**8.3.2 Predictive Analysis Section of the PEST Control File**\n\n### Content\nWhere a prediction is of an entirely different type to measurements employed in the calibration process, then the level of noise associated with that prediction (in most cases resulting from incapacity of the model to simulate all details of system behaviour which pertain to this prediction) must be guessed.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 8. Predictive Analysis\n- **Subsection:** 8.3 Predictive Analysis Control Variables\n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** To run PEST in \"predictive analysis\" mode, set PESTMODE to \"prediction\", define observation groups, and perform a prior \"estimation\" run. Adjust Marquardt lambda iteratively to maximize/minimize predictions while meeting objective function criteria. Use line search, adjust search parameters, and set termination conditions based on prediction improvement. User intervention can modify line search variables.\n\n### Related Context\n- **Previous Summary:** NPREDNORED (integer, ~4) iterations without prediction improvement triggers termination in \"predictive analysis\" mode.  ABSPREDSTP (real, context-dependent) and RELPREDSTP (real, ~0.005) define thresholds for prediction convergence (NPREDSTP highest/lowest predictions).  NOPTMAX sets the maximum number of iterations. User intervention (section 6.2) can adjust line search control variables.\n- **Next Summary:** Adding a \"predictive error\" parameter (e) to the parameter set, with a prior information equation setting e=0, incorporates predictive noise into the analysis.  The weight for this equation is set based on the predictive noise standard deviation.  The model is modified to add e to the prediction before PEST processing.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 49cb420fc630\n- **Chunk Index:** 5\n- **Previous Chunk ID:** cbd30e177677\n- **Next Chunk ID:** 7a418d66c68f\n\n---\n\n## Context\n\n### Summary\n**PARREDUCE compares simplification strategies by calculating residual covariance matrices: uncalibrated (Equation 14.2.5) and calibrated (Equation 14.2.9 for the complex model Z, Equation 14.2.16 for simplified model X, assuming C(k)=I, Equation 14.2.17).  Φx (Equation 14.2.18), the sum of Cx(r)'s diagonal elements, summarizes the impact of simplification on the objective function. Low Φx suggests sufficient parameters to achieve a good fit.**\n\n### Header\n**14.2.2 Theory**\n\n### Content\nC(r) can thus be very small. For the types of analyses that PARREDUCE is asked to perform this is fine. Its purpose is to provide a means of comparison of residuals that emerge from calibration of the Z model with those that emerge from calibration of various simplified X models.\nWhere an X model is calibrated in place of the Z model, equation 14.2.7 is replaced by equation 14.2.4; that is\nrx = Zk – Xp (14.2.12) where p is calculated as p = Vx1Sx1-1Ux1ht (14.2.13)\nHere the subscript “x” indicates that singular value decomposition is undertaken on X rather than on Z. Substitution of equation 14.2.13 and equation 14.2.1 (with ε assumed to be 0) into equation 14.2.12 yields\nrx = Zk – XVx1S-1x1Utx1Zk (14.2.14) which (after a little matrix manipulation) becomes\nrx = (I – Ux1Utx1)Zk = Ux2Utx2Zk (14.2.15)\nThe covariance matrix of residuals emerging from calibration of a simplified model is then calculated as\nCx(r) = Ux2Utx2ZC(k)ZtUx2Utx2 (14.2.16) which, if C(k) is equal to I, becomes\nCx(r) = Ux2Utx2ZZtUx2Utx2 (14.2.17)\nOnce again, the diagonal elements of Cx(r) represent the variances of individual elements of r; the square roots of these represent their standard deviations.\nDifferent simplification strategies can be compared through comparing Cx(r) matrices calculated using equation 14.2.16 for different X matrices. A simple summary statistic is the sum of elements along the diagonal of Cx(r). This is denoted as Φx as it is an objective function. Thus\nΦ = tr(Cx(r)) x (14.2.18)\nwhere tr() is the matrix trace operator. Φ can be thought of as the contribution made to the overall calibration objective function by parameter simplification. If this number is low (or even zero), it indicates that the simplified model retains enough adjustable parameters to guarantee a fit with field data that is very little worse than that which would prevail through calibration of the original Z model. This does not mean that simplification is therefore “ideal”. It is possible that the simplified parameters play roles that compensate for model defects in achieving this level of fit. Nevertheless it does indicate that enough parameters exist for a good fit between model outputs and field data to be attained, and that these parameters therefore span the solution space of the Z model.\nIn the subsurface reservoir modelling context, different simplification strategies (embodied in different X matrices) may result from alternative representations of the presence, locations and geometries of zones of piecewise constancy reflecting rock types of contrasting, but relatively homogeneous, hydraulic properties. Lower values for Φx arising from some of these tested dispositions may indicate better representation of subsurface features in the model domain.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software\n- **Main Section:** 14. Miscellaneous Utilities\n- **Subsection:** 14.2 PARREDUCE\n\n### Additional Summaries\n- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.\n- **Detailed Summary:** Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.\n\n### Related Context\n- **Previous Summary:** PARREDUCE assesses parameter simplification's impact on model-data misfit using a complex and simplified model (Equation 14.2.4: r=Zk-Xp). It calculates uncalibrated (Equation 14.2.5: C<sub>u</sub>(r)=ZC(k)Z<sup>T</sup>) and calibrated (Equation 14.2.9: C<sub>z</sub>(r)=U₂S₂²U₂<sup>T</sup>, assuming C(k)=I, Equation 14.2.11) residual covariance matrices (using SVD of Z).  It uses two PEST control files (complex and simplified) and assumes zero measurement noise and a perfect model.\n- **Next Summary:** PARREDUCE compares parameter simplification strategies using two PEST control files (complex: pestfile1 with JCO file; simplified: pestfile2) and an eigenvalue threshold (eigthresh, 0.0-1.0). It calculates residual standard deviations for uncalibrated, calibrated complex, and calibrated simplified models.  The optional `/b` switch uses bounds to estimate C(k); otherwise C(k)=I.  Output (Figure 14.1) includes traces of the residual covariance matrices.  Use `parreduce pestfile1 pestfile2 eigthresh outfile [/b]`.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 23bc4ed1ec29\n- **Chunk Index:** 2\n- **Previous Chunk ID:** 6ad64ffdaa14\n- **Next Chunk ID:** 9ca209c76eb4\n\n---\n\n## Context\n\n### Summary\n**Post-calibration parameter/prediction error variance is calculated using Equation 11.1.5 (Doherty 2015, Equation 5.5.10):  σ<sub>s-s</sub>² = y<sup>T</sup>(I-R)C(k)(I-R)<sup>T</sup>y + y<sup>T</sup>GC(ε)G<sup>T</sup>y.  R=GZ (Equation 11.1.2), where G is the parameter solution matrix and Z is the Jacobian matrix.  R and G calculations depend on the solution method and Marquardt lambda;  keep Marquardt lambda low.  The text defines variables: Z, X, T, S, λ, h, ε, Q, V, E.**\n\n### Header\n**11.1.2 Concepts**\n\n### Content\nPost-Calibration Parameter and Predictive Error\nLet k represent parameters employed by a model. Let k represent the parameter set achieved through model calibration. From equation 5.5.10 of Doherty (2015) the covariance matrix of post‑calibration parameter error is calculated as\nC(k ‑ k) = (I ‑ R)C(k)(I ‑ R)t + GC(Æ)Gt (11.1.1)\nwhere\n- k represents “true” model parameters (which are unknown);\n- k represents calibrated model parameters;\n- C(k) represents the prior parameter covariance matrix, this describing the innate variability of real‑world parameters;\n- C(Æ) represents the covariance matrix of measurement/structural noise, mostly assumed to be diagonal;\n- R is the so‑called “resolution matrix”; and\n- G is the matrix through which estimated parameter values (i.e. the elements of k) are calculated from measurements (which are denoted as h in Doherty, 2015); G is referred to herein as the “parameter solution matrix”, or more simply as the “G matrix”.\nR is related to G through the equation\nR = GZ (11.1.2)\nwhere Z specifies the relationship between model parameters and model outputs used in the calibration process (see equation 10.3.6).\nLet s be a model prediction whose sensitivities to model parameters are encapsulated in the vector y. For a linear model, the “true” value of a model prediction is given by\ns = ytk (11.1.3a)\nwhile its counterpart as calculated by the calibrated model is\ns = ytk (11.1.3b)\nModel predictive error is then obtained as\ns – s = yt(k ‑ k) = -yt(I – R)k + ytGÆ (11.1.4)\nwhile model predictive error variance (i.e. the “variance of potential wrongness” of a prediction made by a calibrated model) is given by\n2s‑s = yt(I – R)C(k)(I – R)ty + ytGC(ε)Gty (11.1.5)\nNote that while derivation of these equations rests on an assumption of model linearity, they are nevertheless approximately correct when applied to many nonlinear models. With some modifications, they can also be used as a basis for nonlinear analysis; PEST’s null space Monte Carlo methodology rests on equation 11.1.1.\nCalculation of the R and G Matrices\nFormulas for R and G featured in the above equations depend on the method used by PEST to solve the inverse problem. For an overdetermined system, for which the regularisation opportunities offered by truncated singular value decomposition and Tikhonov schemes are not required, the resolution matrix R is simply I, the identity matrix. However in many real world cases, barely overdetermined problems are rescued from numerical instability through PEST’s use of a high‑valued Marquardt lambda (which is a de‑facto Tikhonov regularisation device). Even where mathematical regularisation is formally introduced to a real world problem, it is often insufficient to guarantee unequivocal numerical stability of solution of that problem; hence PEST will often respond by raising the value of the Marquardt lambda, this allow progress in solution of an inverse problem to be made when it may otherwise founder.\nThe role of the Marquardt lambda in calculation of the R and G matrices is recognised in the utility software described in the present chapter. It must be noted, however, that the Marquardt lambda is not a very good regularisation device; in many cases it can lead to inverse problem solutions which are not of minimised error variance, at the same time as it can lead to distortion of the resolution matrix. Hence, whether using one of the specialist regularisation devices offered by PEST to assist in solution of an inverse problem, or whether using manual regularisation to promulgate inverse‑problem well‑posedness, attempts should be made to keep the Marquardt lambda low.\nFormulas used for calculation of R and G\nVariables appearing in these formulas are as follows.\n- Z This is the Jacobian matrix, which is a linearization of the relationship between model parameters and model outputs used in the calibration process. Each row of the Jacobian matrix provides derivatives of a particular model outcome for which there is a complementary field measurement with respect to all adjustable parameters. If a parameter is log‑transformed, pertinent elements of Z pertain to the log of that parameter. Note that for SVD‑assisted inversion the Z matrix refers to base parameters, not super parameters in the equations below.\n- X This is the super‑parameter Jacobian matrix whose elements are derivatives of model outcomes with respect to super parameters estimated through SVD‑assisted inversion.\n- The PEST‑calculated Marquardt lambda.\n159\nDefinitions\n- T The matrix of Tikhonov regularisation constraints. These constraints are assumed to be of the form Tk = 0.\n- S The relative regularisation weight matrix (calculated from user-supplied regularisation weights and/or user-supplied regularisation covariance matrices).\n- 2 The PEST-calculated regularisation weight factor.\n- h The set of observations which constitute the calibration dataset. Æ featured in equations 11.1.1, 11.1.4 and 11.1.5 is the “noise” or “measurement error” associated with these observations.\n- Q The observation weight matrix (calculated from user-supplied weights and measurement covariance matrices).\n- V The matrix whose columns are orthogonal unit eigenvectors of ZtQZ (and hence of Q1/2Z) as calculated through singular value decomposition undertaken either during every iteration of the parameter estimation process (when this is achieved through truncated singular value decomposition), or at the beginning of the inversion process for determination of super parameters (if using SVD-assisted parameter estimation).\n- E A diagonal matrix whose elements are the eigenvalues of ZtQZ (arranged in decreasing order) determined through singular value decomposition. The singular values of Q1/2Z are the square roots of these.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software\n- **Main Section:** 11. Linear Error and Uncertainty – Part II\n- **Subsection:** 11.1 Introduction\n\n### Additional Summaries\n- **Higher-Level Summary:** Parallel PEST and BEOPEST parallelize model runs to reduce run time. Parallel PEST needs a run management file, while BEOPEST's is optional. Both distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Parallel PEST uses PAGENT agents, requires separate folders for agents, and shared signal files for communication. BEOPEST offers ease of use, faster communication, flexibility, and support for multiple command lines and surrogate models.\n- **Detailed Summary:** Parallel PEST and BEOPEST parallelize model runs, reducing PEST run time. Parallel PEST requires a run management file, while BEOPEST's is optional. They distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Both store data in binary files for reduced memory needs.\n\n### Related Context\n- **Previous Summary:** This chapter documents older PEST utilities (largely superseded by those in the previous chapter) for parameter and predictive error analysis (not uncertainty). They require a prior model calibration run and are less general than the previous chapter's utilities.  Some users may find them useful.\n- **Next Summary:** This chapter details utilities calculating R (resolution matrix) and G (parameter solution matrix) using case.jco (updated per improved parameter set, except for SVD-assist).  Equations for R and G are given for overdetermined systems (Equations 11.1.6a, 11.1.6b), Tikhonov regularization (Equations 11.1.7a, 11.1.7b), SVD (Equations 11.1.8a, 11.1.8b), and SVD-assist (Equations 11.1.9a, 11.1.9b).  Results apply to base (not super) parameters and their logs (for log-transformed parameters).  LSQR is not accommodated.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 8588789b5326\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 4a5dda9e0a37\n- **Next Chunk ID:** ab1abc08f45b\n\n---\n\n## Context\n\n### Summary\n**A missing model output file indicates model failure. A zero gradient indicates incorrect model input file names. Erratic objective function behavior suggests poor derivatives (check using JACTEST), potentially caused by insufficient precision, low increments, model numerical issues, or loose solver criteria.  Mitigation strategies include adjusting increments, using DERINCLB, tightening solver criteria, disabling adaptive time-stepping, split slope analysis, five-point stencils, or automatic user intervention.  Nonlinearity can be addressed using parameter change limits (FACPARMAX, RELPARMAX, ABSOLUTE(N)), log transformation, SCALE, or BOUNDSCALE.**\n\n### Header\n**4.19.2 Format of a Covariance Matrix File**\n\n### Content\nBefore it runs the model, PEST deletes the model output files listed in the “model input/output” section of the PEST control file. These are the model output files which corresponding instruction files must read. If, for some reason, the model fails to run, these model output files will not be present. PEST will then issue an error message such as that depicted in figure 5.6. This error message is nearly always a sign that the model did not run, or did not run to completion.\n5.5.3 Objective Function Gradient Zero\nIf the sensitivities of all model outputs to all parameters are zero, PEST issues the following error message:\nPhi gradient zero in non-frozen parameter space.\nThis situation can arise if there is only one model input file to which there is a corresponding template file, and the name provided for this model input file is incorrect. PEST then writes parameter values to one file while the model reads another. (The PESTCHEK program can detect many errors, but it cannot detect this one.) This problem is, of course, easily rectified. It simply requires that the name of the wrong model input file be replaced by the name of the correct model input file.\nIf there is more than one model input file cited in the “model input/output” section of the PEST control file, and if only one of these is named incorrectly, then the problem of input file misnaming is more difficult to detect. It may be revealed through zero-valued composite sensitivities of parameters which are only written to this model input file (though this will be hidden if regularisation is employed, as the very purpose of regularisation is create sensitivity where it would otherwise not exist). It may also be revealed through the fact that parameters that are only represented in this model input file are not adjusted through the inversion process.\n5.5.4 Erratic Objective Function Behaviour caused by Bad Derivatives\nIf PEST is working well, the objective function falls rapidly at first, then falls more slowly, and then falls no further. The transition from rapid downward movement to no movement at all is usually gradational.\nSometimes, however, the objective function falls rapidly during one iteration, and then does not fall at all during the next iteration. Sometimes it rises rapidly and then falls rapidly again. This is often a sign of problematical finite-difference derivatives.\nProblematical finite-difference derivatives can have any of the following causes.\n- Parameter values are not written with sufficient precision to model input files;\n- Numbers are passed with less than full precision between different executables cited in a batch or script file which PEST runs as “the model”;\n- Parameter increments are too low;\n- The model is experiencing numerical difficulties;\n- Model solver convergence criteria are not set tightly enough.\nThe integrity of finite-difference derivatives can be checked using the JACTEST utility described in part II of this manual. Steps which can be taken to mitigate the deleterious effects of model-corrupted derivatives include the following.\n- Derivative increments can be increased;\n- The DERINLB derivatives control variable can be used where low parameter increments are caused by low parameter values;\n- Model solver convergence criteria can be tightened;\n- If it is practical to do so, model numerical strategies such as adaptive time-stepping which may introduce a small amount of “numerical noise” to model outputs may be disabled;\n- PEST’s “split slope analysis” functionality can be invoked to detect and defend against model numerical output granularity (see section 3.5.7);\n- A five-point finite-difference stencil can be used (see section 3.5.2);\n- PEST’s “automatic user intervention” functionality can be activated, with the DOAUI control variable set to “auid” (see section 6.4).\n5.5.5 Other Factors Leading to Erratic Objective Function Behaviour\nWhere failure to lower the objective function, or erratic behaviour of the objective function, results from extreme problem nonlinearity rather than degraded finite-difference derivatives, this can be accommodated by placing limits on the amount that any parameter is allowed to change during any one iteration. Parameter change limits can be imposed using the FACPARMAX, RELPARMAX and ABSOLUTE(N) variables cited in the “control data” section of the PEST control file.\nLog-transformation of parameters often makes a profound impact on PEST performance. As is discussed elsewhere in this manual, relationships between model outputs and model parameters are often more linear if the latter are log-transformed. Log-transformation of all parameters often accomplishes a similar outcome to normalizing parameters by their innate variabilities. This prevents super-sensitivity of those parameters whose values are expressed by numbers which are numerically small (as is often the case for recharge in a groundwater model). If log transformation is not possible because parameters may become zero or negative, then the SCALE control variable available in the “parameter data” section of the PEST control file can be used to reduce the sensitivities of individual super-sensitive parameters. The BOUNDSCALE variable that resides in the “control data” section of the PEST control file introduces global normalization of parameters with respect to their innate variabilities.\n5.5.6 Excessive Number of Model Runs\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 4. The PEST Control File\n- **Subsection:** 4.19 Covariance Matrix Files\n\n### Additional Summaries\n- **Higher-Level Summary:** Figure 4.2 in PEST software displays control data section variables. The text details options for writing matrices, files, and parameters, including settings for matrix and file saving, operational modes, precision, derivative handling, and convergence criteria. Optional features like sensitivity reuse and LSQR algorithm for solving inverse problems are discussed.\n- **Detailed Summary:** COVFLE specifies covariance matrix files for observation groups, overriding individual weights. PEST supports various ASCII covariance matrix file formats. Different PEST versions may produce varied results for ill-posed problems. PEST run commands include switches for different functionalities and modes. Parameter estimation results include objective function, estimates, confidence limits, observations, and statistics.\n\n### Related Context\n- **Previous Summary:** PPAUSE, PUNPAUSE, PSTOP, and PSTOPST (Part II) control PEST execution via pest.stp.  <Ctrl-C> also stops PEST.  User termination is common due to poor fit, unrealistic parameters, or erratic objective function behavior. Ill-posed inverse problems are addressed using regularization, SVD, or LSQR, and RLAMFAC=-3.\n- **Next Summary:** For highly parameterized models, excessive model runs for derivative calculations can be reduced by preventing premature higher-order derivative calculations (NOPTSWITCH), widening parameter bounds, using Tikhonov regularization, and setting an appropriate target objective function (Chapter 9).  Discontinuous model outputs may require global optimization methods (Chapter 16).  Parameter correlation/insensitivity (JtQJ non-invertible) is addressed by regularization, SVD, or LSQR.\n\n### Metadata\n- **Keywords:** BOUNDSCALE, DOAUI, FACPARMAX, RELPARMAX, SCALE\n- **Chunk ID:** 53a1defef6a5\n- **Chunk Index:** 20\n- **Previous Chunk ID:** b4b75f923100\n- **Next Chunk ID:** 993e9ef91c80\n\n---\n\n## Context\n\n### Summary\n**Tikhonov regularization provides a \"fall-back\" parameter condition (e.g., preferred values, homogeneity) and allows departures based on expert knowledge (covariance matrix, penalty functions).  In \"regularisation\" mode, PEST uses measurement (Φm) and regularization (Φr) objective functions.  Regularization constraints (assigned to \"regul\" groups) can be prior information equations or model-calculated observations.  A target measurement objective function can be set.**\n\n### Header\n**8.5 Model-Based Hypothesis Testing**\n\n### Content\n- Most natural systems are complex and heterogeneous. The use of many parameters allows better representation of system heterogeneity than parsimonious parameterisation. It is precisely because parameterisation detail is unlikely to be uniquely estimable that it must be represented when exploring predictive uncertainty; it is the parameters that cannot be estimated, rather than those which can, which are critical to this endeavour. Regularised inversion easily accommodates parameter nonuniqueness. Post-calibration predictive uncertainty analysis requires exploration of the effects of parameter nonuniqueness if it is to have integrity.\nSee Doherty (2015) for a full discussion of the advantages of highly parameterized inversion.\n9.1.2 Tikhonov Regularisation\nAs explained in detail by Doherty (2015), appropriately formulated Tikhonov regularisation\nprovides a “fall-back position” for some or all model parameters. This describes a condition that, according to expert knowledge, they should satisfy unless there is information in the calibration dataset to the contrary. This fall-back condition can be formulated as preferred values for some or all parameters, homogeneity, piecewise homogeneity, minimum curvature of parameter fields, combinations of these, or other conditions altogether.\nAs well as expressing a preferred parameter condition, Tikhonov regularisation should explicitly or implicitly express the way in which departures from this condition can arise. This can be done through a covariance matrix. Alternatively, it can be done through mechanisms such as “sharpness filters” which penalize the emergence of heterogeneity unless it has sharp edges. Another possibility is to formulate linear and nonlinear “heterogeneity penalty functions” which reward the emergence of heterogeneity at certain locations and in certain directions, and penalise its emergence at other locations and in other directions. In short, Tikhonov regularisation should comprise a mathematical formulation of expert knowledge that allows the inversion process to “join the dots” between the limited parameterisation detail that can be estimated on the basis of the calibration dataset in such a way that the parameter field which emerges from the Tikhonov-regularised inversion process is as compatible with expert knowledge as possible, while allowing the model to replicate field measurements.\nIdeally, all parameters involved in the inversion process should feature in Tikhonov regularisation. This ensures that they are all provided with both a fall-back position, and with an optimal means of departing from that fall-back position.\n9.1.3 Measurement and Regularization Objective Functions\nWhen PEST is run in “regularisation” mode it defines two objective functions instead of one. The first is the measurement objective function, designated as Φm. This is similar to the traditional objective function that PEST uses when run in “estimation” mode in that it constitutes a weighted least squares measure of the discrepancies between field measurements and their model-generated counterparts. The second is the regularisation objective function, designated as Φ. This constitutes a weighted least squares measure of the discrepancies between parameters and their preferred conditions.\nAs stated above, preferred parameter conditions can be simple or complex. The simplest form of regularisation is to assign every estimated parameter a preferred value (normally equal to its initial value). This is easily accomplished using the ADDREG1 utility described in part II of this manual. A series of prior information equations encapsulate this form of regularisation, with one prior information equation pertaining to each parameter. Each prior information equation is then of the following form.\npi1 1.0 * par1 = 10.0 1.0 regul1 or (if a parameter is log-transformed) pi1 1.0 * log(par1) = 1.0 1.0 regul1\nTo the extent that the “par1” parameter which features in the above equations differs from 10.0, a non-zero residual occurs, and the regularisation objective function itself becomes non-zero.\nPrior information can be used to express differences between parameter values or, if parameters are log-transformed, quotients between parameter values. For example pi2 1.0 * par1 – 1.0 * par2 = 0.0 1.0 regul2\nor (if “par1” and “par2” are log-transformed)\npi2 1.0 * log(par1) – 1.0 * log(par2) = 0.0 1.0 regul2\nTo the extent that “par1” differs in value from “par2”, these equations acquire a non-zero residual. The regularisation objective function is then non-zero.\nIt is not necessary that Tikhonov constraints be expressed as prior information equations. They can be calculated by the model rather than by PEST and thus be “observations”. Thus they do not need to be linear. Nor do they even need to be comprised of simple equality and difference relationships between parameters; however, of course, they must have some sensitivity to parameters and thus must all feature one or more parameters in some way.\nIn short, regularisation observations and prior information equations are just like other observations and prior information equations. They have an observed value and a model-calculated value. The difference between these constitutes a residual. Each is assigned a weight. Collectively a group of them can be assigned a covariance matrix. However the distinguishing feature of all of them is that they must be assigned to an observation group whose name begins with “regul”. The regularisation objective function is simply the component of the total objective function that is summed over all observations and prior information equations that belong to observation groups whose names begin with “regul”. In contrast, the measurement objective function is that component of the total objective function that is summed over all observations and prior information equations that belong to observation groups whose names do not begin with “regul”.\n9.1.4 Target Measurement Objective Function\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 8. Predictive Analysis\n- **Subsection:** \n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** \n\n### Related Context\n- **Previous Summary:** In \"regularisation\" mode, PEST balances prior information and measurement weights for predictive analysis (model-based hypothesis testing, section 8.5 of Doherty 2015). A \"predict\" group (one observation) helps identify parameter sets allowing an undesirable prediction while fitting historical data. Tikhonov regularization handles many parameters, minimizing error variance and ensuring numerical stability.  ASSESSPAR (Part II) assesses parameter reasonableness.\n- **Next Summary:** To avoid overfitting with many parameters, PEST's Tikhonov regularization uses a target measurement objective function (Φtm, PHIMLIM).  PEST minimizes the regularization objective function (Φr), constrained by Φm = Φtm. A global multiplier (µ) is applied to regularization weights to achieve this;  it's adjusted per iteration.  Inter-regularisation group weight adjustment occurs beforehand (IREGADJ).\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 9036138cc854\n- **Chunk Index:** 2\n- **Previous Chunk ID:** 28d98579ea1b\n- **Next Chunk ID:** d46940ffa7a8\n\n---\n\n\nAnswer strictly following the above instructions.\n"
  }
]
```