# Stream Debug - 20250206_204151

# Original Question
```
What is the role of the `opt_risk` control variable in the optimization process managed by PESTPP-OPT?
```

# Context Content
```markdown
# Search Results for: What is the role of the `opt_risk` control variable in the optimization process managed by PESTPP-OPT?

Keywords: None


## Context

### Summary
***opt_risk* (0.0-1.0) controls risk in PESTPP-OPT. 0.5 is risk-neutral (δo=0, no uncertainty calculations).  >0.5 is risk-averse; constraints are applied to *o* ± δ*o* (upper/lower bound of the confidence interval, respectively). <0.5 is risk-tolerant; constraints are applied to *o* ∓ δ*o*.  δ*o* is calculated based on the model output's standard deviation.**

### Header
**8.2.8 Risk**

### Content
Using the *opt_risk()* control variable, a user specifies his/her disposition with respect to risk. The setting of this variable determines the value of δ*o* discussed in section 8.1. This is the value that is added/subtracted to/from a model output before a constraint is applied to that output.
The value supplied for *opt_risk()* should be greater than zero and less than one. If the value supplied for *opt_risk()* is 0.5, then operation of PESTPP-OPT is risk neutral. In this case δ*o* is zero. Under these circumstances PESTPP-OPT does not calculate model output uncertainty at all. It therefore does not need to read (or calculate for itself) a prior parameter covariance matrix. Also, it does not need to read (or calculate for itself) derivatives of model outputs with respect to model parameters which are not decision-variables.
An *opt_risk()* setting of greater than 0.5 indicates risk aversion. For “less than” constraints (i.e., constraints for which a system state or flux must be less than a certain value), δ*o* is added to the model-calculated system state or flux (i.e., *o*) so that the constraint is applied to *o* + δ*o*. The opposite applies for “greater than” constraints. Suppose, for example, that *opt_risk()* is supplied as 0.95. Then, for a “less than” constraint, δ*o* is calculated to be such that there is a 95% chance that the real system state or flux is less than *o* + δ*o*. Similarly, for a “greater than” constraint, δ*o* is calculated to be such that there is a 95% chance that the real system state or flux is greater than *o* – δ*o*. In both of these cases *o* is the value that the model calculates for this quantity based on the current values of decision variables.
A setting for *opt_risk()* that is less than 0.5 indicates risk tolerance. For “less than” constraints, the constraint is applied to *o* - δ*o*. The opposite applies for “greater than” constraints. Suppose that *opt_risk()* is supplied as 0.05. Then, for a “less than” constraint, δ*o* is calculated to be such that there is a 5% chance that the real system state or flux corresponding to a certain set of decision variables is less than *o* - δ*o*. Similarly, for a “greater than” constraint, δ*o* is calculated to be such that there is a 5% chance that the real system state or flux corresponding to a certain set of decision variables is greater than *o* + δ*o*.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.2 Using PESTPP-OPT

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode, PEST maximizes/minimizes a prediction (in the "predict" group) while keeping the objective function ≤ Φ0 (requires a prior "estimation" run).  It uses the same parameters, transformations, and observations as the estimation run.  Restarting uses `/r`, `/j`, `/d`, or `/s` (parallel runs).  Change limits remain important.  Screen output shows prediction values per iteration.  Results include the optimal prediction and parameter values.

### Related Context
- **Previous Summary:** PESTPP-OPT's *parcov* control variable (used also by PESTPP-GLM and PESTPP-IES) specifies a prior parameter covariance matrix (from *.cov*, *.unc*, *.jco*, or *.jcb* files, Appendix B). Log-transformed parameters require log-based covariances. If absent, PESTPP-OPT assumes independence and calculates standard deviations as 1/4 the bound range (*par_sigma_range* modifies this).  Decision variables are not included.
- **Next Summary:** PESTPP-OPT calculates derivatives of constraint-relevant model outputs using finite differences (controlled by parameter group settings), unless using external derivatives (*base_jacobian*).  The J matrix (calibration outputs vs. parameters) and y vector (constraint outputs vs. parameters) are updated every *opt_recalc_fosm_every* iterations (default 1).  If all calibration observation weights are zero or there are no calibration observations,  PESTPP-OPT uses prior parameter uncertainties (*parcov*) for δo calculations.

### Metadata
- **Keywords:** 
- **Chunk ID:** 0d422662ecd4
- **Chunk Index:** 1
- **Previous Chunk ID:** 260f819431ee
- **Next Chunk ID:** f37e2862cb8c

---

## Context

### Summary
**This section describes PEST control file variables governing multiple command lines, model messaging, and external derivatives functionality.**

### Header
**12.5.1 General**

### Content
Variables within the PEST control file that govern PEST’s multiple command line, model messaging, and external derivatives functionality are now described.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 12. Model-Calculated Derivatives (continuación)
- **Subsection:** 12.5 PEST Control Variables

### Additional Summaries
- **Higher-Level Summary:** PEST uses pest.mmf to send messages before each run, indicating run type and parameter details. Different commands can be used for regular and derivative-calculating model runs, potentially reducing run time. Models can provide PEST with derivatives more efficiently, supporting various file formats. PEST control file variables manage model commands, messaging, and external derivatives.
- **Detailed Summary:** This section explains PEST control file variables for managing model commands, messaging, and external derivatives. Key variables include NUMCOM for the number of model commands, JACFILE for external derivatives format, and MESSFILE for message file control. Parallel PEST is not compatible with external derivatives. DERCOM specifies model commands for derivative calculations.

### Related Context
- **Previous Summary:** Parallel PEST and BEOPEST do not support receiving derivatives via external files.
- **Next Summary:** NUMCOM (integer, ≥1) specifies the number of model commands (excluding the external derivatives command). JACFILE (integer) indicates whether external derivatives are used (1=ASCII, -1=binary, 2=JUPITER format). MESSFILE (0 or 1) controls writing a PEST-to-model message file.  Parallel PEST is incompatible with external derivatives (JACFILE>0).

### Metadata
- **Keywords:** 
- **Chunk ID:** dd9539f78d9d
- **Chunk Index:** 1
- **Previous Chunk ID:** 151b01f8fd63
- **Next Chunk ID:** cb58dfd3b1b7

---

## Context

### Summary
**A "regularisation" section is required in the PEST control file only when PESTMODE is set to "regularisation" (Chapter 9).**

### Header
**4.17 Regularisation Section**

### Content
If PEST is run in “regularisation” mode, (i.e. if the PESTMODE variable residing in the “control data” section of the PEST control file is set to “regularisation”), then the PEST control file must have a “regularisation” section. Details are provided in chapter 9 of this manual.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 4. The PEST Control File
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** Figure 4.2 in PEST software displays control data section variables. The text details options for writing matrices, files, and parameters, including settings for matrix and file saving, operational modes, precision, derivative handling, and convergence criteria. Optional features like sensitivity reuse and LSQR algorithm for solving inverse problems are discussed.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** A "predictive analysis" section is required in the PEST control file only when PESTMODE is set to "prediction" (Chapter 8).
- **Next Summary:** A "pareto" section is required in the PEST control file only when PESTMODE is set to "pareto" (Chapter 13).

### Metadata
- **Keywords:** PESTMODE
- **Chunk ID:** d4b641af704e
- **Chunk Index:** 1
- **Previous Chunk ID:** 5c5b488c3e40
- **Next Chunk ID:** 2394701f7a4d

---

## Context

### Summary
**PEST reduces computational burden via parallel processing (Parallel PEST, BEOPEST), using super parameters (SVD-assist) for efficient sensitivity calculations, and employing surrogate models (observation re-referencing) for faster derivative calculations, all potentially parallelized.**

### Header
**1.6.7 Numerical Burden**

### Content
Parameter estimation and calibration-constrained parameter and predictive uncertainty analysis requires the undertaking of many model runs. Where model run times are long, and where the number of parameters requiring adjustment is large, this represents a considerable numerical burden. PEST provides three mechanisms for easing this burden.
The first mechanism is run parallelisation. Calculation of a Jacobian (i.e. sensitivity) matrix is 100 percent parallelizable. To some extent the testing of parameter upgrades calculated on the basis of these sensitivities using different values of the Marquardt lambda is also parallelizable. Parallel PEST and BEOPEST allow a modeller to parallelise runs across different processors on the same machine, across machines, across networks and across the world.
When undertaking highly parameterized inversion, the numerical burden of Jacobian matrix calculation can be greatly eased if sensitivities are calculated not to parameters themselves, but to combinations of parameters that have been identified through singular value composition as being uniquely estimable on the basis of the current calibration dataset; these combinations are referred to as “super parameters” in PEST parlance. PEST accomplishes this through its SVD-assist functionality. Model runs undertaken for super parameter sensitivity calculation can be parallelised, this achieving further increases in numerical efficiency.
Through its “observation re-referencing” functionality, PEST can use one or more surrogate models instead of the actual model when calculating finite-difference derivatives of model outputs with respect to adjustable parameters. If the run time of the surrogate model is much smaller than that of the actual model, the computational burden of the inversion process can be reduced considerably. Further gains can be made through parallelisation of surrogate and actual model runs in an SVD-assisted inversion process.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 1. Introduction
- **Subsection:** 1.6 Some Practical Considerations

### Additional Summaries
- **Higher-Level Summary:** To install PEST, copy its executables to a folder in the PATH variable for access from any directory. The suite includes PEST, Parallel PEST, BEOPEST, SENSAN, global optimizers, and utilities. PEST calibrates models by matching outputs to measurements, handling non-uniqueness through regularization. It quantifies uncertainties and supports decision-making by identifying unlikely events.
- **Detailed Summary:** PEST is a modeling tool that runs via system calls with command-line access, benefiting from the model's directory in the PATH variable. It supports batch files, pre- and post-processors, and multiple simulators. To avoid errors, batch files should delete intermediate files. PEST interacts with ASCII template and instruction files, converting binary files with a postprocessor. Gradient methods for inversion require calculable derivatives, with considerations for non-continuous model outputs and local optima. Regularization and multi-component objectives can address parameter nonuniqueness. PEST optimizes computational efficiency through parallel processing, super parameters, and surrogate models.

### Related Context
- **Previous Summary:** PEST reads model outputs ("observations") from instruction files, including predictions (weighted zero) alongside calibration data.  Predictive analysis and Pareto modes utilize predictions, while sensitivity analysis may include them with or without affecting parameter estimation.
- **Next Summary:** This section introduces PEST's capabilities by listing tasks and associated programs,  even referencing concepts explained later in the manual.  It aims to familiarize new users with PEST and its utilities.

### Metadata
- **Keywords:** 
- **Chunk ID:** 30652bfd50c7
- **Chunk Index:** 1
- **Previous Chunk ID:** 1aeee8517360
- **Next Chunk ID:** 41dda665a758

---

## Context

### Summary
**Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.**

### Header
**14.2 General Principles**

### Content
On most occasions of its deployment, PEST calculates derivatives of model outputs with respect to adjustable parameters using finite differences. In some cases it may be possible for a different model to be employed for the purpose of derivatives calculation from that which is used for the purpose of testing and upgrading parameters. This may be desirable where a simplified “surrogate model” is run for the purpose of derivatives calculation, and this model has a short run time compared with that of the model which is actually being calibrated. If this strategy is attempted, however, certain problems may arise. These will now be discussed.
The difference equation through which the derivative of observation j with respect to parameter i is calculated can be written as
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ∂oj/∂pi ≈ (ovi − orj) / (pv − pij)  (14.2.1)
In equation 14.2.1, pir is the base value (i.e. the current reference value) of parameter p while ojr is the value of the model output corresponding to observation o calculated by the model j using the base parameter set. pv is the value of parameter i when incrementally varied for the purpose of derivatives calculation while ovi is the model-calculated value of observation j when parameter i is thus varied.
Normally ojr is calculated by PEST using either the initial model run, or during the parameter upgrade process where different model runs are undertaken on the basis of different trial parameter sets calculated using different Marquardt lambdas. In the latter case the best upgrade is selected and new parameters are based on that; meanwhile model outputs calculated on the basis of the best parameter set become the base model outputs or “reference model outputs” used in the above equation for finite-difference derivatives calculation for the next PEST iteration.
A problem arises if a different model (for example a simpler and faster-running model) is to
be employed for derivatives calculation from that which is used for testing parameter upgrades. In this case reference model outputs calculated using the complex model are not appropriate for use in the finite-difference derivatives equation when applied to outputs of the simple model. The above equation is only valid when the same model is used to calculate both ovi and ojr. Hence, for finite-difference-calculated derivatives to have integrity in this case, the simple model must be run especially to calculate or using the reference parameter j set. This requires a special model run to be undertaken at the beginning of each iteration. This special model run is indeed carried out if “observation re-referencing” is activated.
In more complex cases where more than one version of the model is used for the purpose of derivatives calculation (for example if multiple simple models are employed, each used for the calculation of derivatives with respect to a different subset of parameters), then an observation re-referencing model run must be undertaken for each version of the model that is so employed.
Using the multiple command line functionality described in section 12.3 it is possible to employ different model versions for calculation of finite-difference derivatives with respect to different parameters. However use of this functionality on its own requires that the different models employed for this purpose are all components of the one large model, and that the same set of reference model outputs (namely those calculated by the total model) are applicable to all of them. Under these circumstances observation re-referencing is not required. However with implementation of observation re-referencing in conjunction with multiple model commands, it is no longer required that models used in finite-difference derivatives calculation produce the same outputs as the main model if supplied with the same set of reference parameter values.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 14. Observation Re-referencing
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** Observation re-referencing (extending section 12.3's multiple command lines) allows using simpler models for derivative calculations while applying upgrades to the complex model and modifying initial model conditions (e.g., initial heads) based on upgraded parameters to improve solver convergence time.
- **Next Summary:** With observation re-referencing (NUMCOM=1, DERCOM=1 for all adjustable parameters), three commands are used: the main model command,  a derivative calculation command ("d_" prefix), and a reference model output command ("r_" prefix). The main command is used for objective function calculations and parameter upgrades. The "d_" command calculates derivatives; the "r_" command computes reference model outputs (used in Equation 14.2.1) for the next iteration.  The "d_" and "r_" commands may be identical.

### Metadata
- **Keywords:** lambdas
- **Chunk ID:** 95c539ce2b81
- **Chunk Index:** 1
- **Previous Chunk ID:** 5ff683afff57
- **Next Chunk ID:** 89f2ddbb0470

---

```

# System Prompt
```

You are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:

**Direct Answer First:**
- Begin with a comprehensive answer that directly addresses the question
- Include all relevant details and context from the documentation
- Don't artificially limit the length - be as thorough as the documentation allows
- Use clear paragraphs and formatting for readability
- NEVER invent, infer, or add information not explicitly present in the documentation

Then, continue with the detailed structure:

1. **Detailed Analysis:**  
   - Use the following structure:

     **1) Definition/Overview**  
     - For technical terms: provide a complete definition with all relevant details
     - For broader questions: provide a thorough overview of the topic
     - Include all relevant context and relationships
     - Cite source(s) using the format "File: [filename], Section: [header]".

     **2) Possible Values**  
     - If applicable: describe all valid or recognized values in detail
     - Include defaults, ranges, and special cases if documented
     - If not applicable: state "Not applicable for this topic"
     - Cite source(s).

     **3) Implications**  
     - Provide a thorough explanation of all usage considerations and consequences
     - Include any relationships with other components or features
     - If not available, state: "Information not available in the provided content."

     **4) Practical Usage Notes**  
     - Include all usage notes, examples, and practical applications
     - Provide context for when and how to use the feature/component
     - Otherwise, state: "No usage notes found in the provided content."

     **5) Keywords**  
     - List ONLY keywords that are EXPLICITLY present in the provided documentation
     - Keywords must be copied EXACTLY as they appear in the documentation
     - DO NOT infer, generate, or create keywords that are not explicitly listed
     - If no keywords are found in the documentation, you MUST state EXACTLY: "No keywords found in the provided content"
     - DO NOT add any explanation or commentary about keywords

2. **Follow-up Questions:**  
   - After your main answer, list **exactly 3 follow-up questions**
   - Questions MUST:
     - If the original query was fully answered:
       - Be directly related to the original query "{query}"
       - Lead to deeper understanding of the main topic
     - If the original query was partially answered or not answered:
       - Focus on related topics found in the documentation
       - Help build context around the topic
     - In all cases:
       - FIRST verify that detailed information exists in the documentation to answer the question
       - ONLY ask questions about topics with substantial documented information
       - Be derived from content in Additional Summaries and Related Context sections
       - Ask ONE single thing - no "if/how/why" combinations
       - Be concise and direct
       - AVOID: 
         - "if so", "and how", "under what conditions", "and why"
         - Questions about implications/effects unless explicitly documented
         - Questions about relationships unless clearly described
         - Questions about usage impacts unless specifically detailed
       - NEVER ask about:
         - Topics that are only briefly mentioned
         - Implications that aren't explicitly documented
         - Effects or impacts not clearly described
         - Relationships between components unless documented
         - Usage scenarios not specifically outlined
   - Examples of GOOD questions (one thing only and well documented):
     - "What is the purpose of nonlinear penalty functions?"
     - "How does PEST handle parameter bounds during the regularization process?"
     - "How does PEST calculate parameter sensitivities?"
   - Examples of BAD questions (too compound or insufficient documentation):
     - "Can OBS2OBS process observations directly, and if so, how?"
     - "What are the implications of risk-averse settings if documentation only mentions they exist?"
     - "How does a feature work if only its name is mentioned?"
     - "What are the equations and when should they be used?"
     - "What effect does X have on Y?" (unless effects are explicitly documented)
     - "How does changing X impact Y?" (unless impacts are clearly described)
   - Before writing each question:
     1. Verify that substantial information exists to answer it
     2. Confirm the topic is explained in detail, not just mentioned
     3. Check that specific details and explanations are available
     4. Verify that any implications/effects/relationships mentioned in the question are explicitly documented
   - Present as a simple numbered list (1-3)
   - If you cannot find 3 questions that meet these criteria, include fewer questions or none at all

3. **Important Instructions:**  
   - **Do not mention internal processes, "chunks," or retrieval steps.**  
   - **Do not include any self-commentary or extra explanations.**
   - Use only the documentation provided in `{context}`.

Answer strictly following the structure and rules above.

```

# Full User Message
```

Question: What is the role of the `opt_risk` control variable in the optimization process managed by PESTPP-OPT?

Please provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:

1. **Cite Sources:**  
   - Use the format "File: [filename], Section: [header]" whenever you reference specific details.

2. **Include Examples:**  
   - Provide relevant examples from the documentation if available.

3. **Note Limitations:**  
   - If the documentation is incomplete or ambiguous, explicitly state: "Information not available in the provided content."

4. **Follow-up Questions:**  
   - After your main answer, list **exactly 3 follow-up questions** based primarily on:
     - "Additional Summaries" sections
     - "Related Context" sections
   - Each question must reference its source section
   - Do not provide answers to these questions
   - Present as a simple numbered list (1-3)

5. **Keywords Section:**  
   - Include a "Keywords" section if applicable.
   - If none are provided, state: "No keywords found in the provided content."

6. **Avoid Internal Details:**  
   - Do not mention internal processes or retrieval steps.
   - Do not include self-commentary or extra explanations.

7. **Be Concise and Accurate:**  
   - NEVER invent details, assumptions, or content
   - ONLY use information EXPLICITLY stated in the provided documentation
   - If information is missing, state EXACTLY: "Information not available in the provided content"
   - DO NOT try to fill gaps or make assumptions about missing information
   - When in doubt, acknowledge the limitation of the available information

**Available Documentation with Metadata:**
# Search Results for: What is the role of the `opt_risk` control variable in the optimization process managed by PESTPP-OPT?

Keywords: None


## Context

### Summary
***opt_risk* (0.0-1.0) controls risk in PESTPP-OPT. 0.5 is risk-neutral (δo=0, no uncertainty calculations).  >0.5 is risk-averse; constraints are applied to *o* ± δ*o* (upper/lower bound of the confidence interval, respectively). <0.5 is risk-tolerant; constraints are applied to *o* ∓ δ*o*.  δ*o* is calculated based on the model output's standard deviation.**

### Header
**8.2.8 Risk**

### Content
Using the *opt_risk()* control variable, a user specifies his/her disposition with respect to risk. The setting of this variable determines the value of δ*o* discussed in section 8.1. This is the value that is added/subtracted to/from a model output before a constraint is applied to that output.
The value supplied for *opt_risk()* should be greater than zero and less than one. If the value supplied for *opt_risk()* is 0.5, then operation of PESTPP-OPT is risk neutral. In this case δ*o* is zero. Under these circumstances PESTPP-OPT does not calculate model output uncertainty at all. It therefore does not need to read (or calculate for itself) a prior parameter covariance matrix. Also, it does not need to read (or calculate for itself) derivatives of model outputs with respect to model parameters which are not decision-variables.
An *opt_risk()* setting of greater than 0.5 indicates risk aversion. For “less than” constraints (i.e., constraints for which a system state or flux must be less than a certain value), δ*o* is added to the model-calculated system state or flux (i.e., *o*) so that the constraint is applied to *o* + δ*o*. The opposite applies for “greater than” constraints. Suppose, for example, that *opt_risk()* is supplied as 0.95. Then, for a “less than” constraint, δ*o* is calculated to be such that there is a 95% chance that the real system state or flux is less than *o* + δ*o*. Similarly, for a “greater than” constraint, δ*o* is calculated to be such that there is a 95% chance that the real system state or flux is greater than *o* – δ*o*. In both of these cases *o* is the value that the model calculates for this quantity based on the current values of decision variables.
A setting for *opt_risk()* that is less than 0.5 indicates risk tolerance. For “less than” constraints, the constraint is applied to *o* - δ*o*. The opposite applies for “greater than” constraints. Suppose that *opt_risk()* is supplied as 0.05. Then, for a “less than” constraint, δ*o* is calculated to be such that there is a 5% chance that the real system state or flux corresponding to a certain set of decision variables is less than *o* - δ*o*. Similarly, for a “greater than” constraint, δ*o* is calculated to be such that there is a 5% chance that the real system state or flux corresponding to a certain set of decision variables is greater than *o* + δ*o*.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis
- **Main Section:** 8. PESTPP-OPT
- **Subsection:** 8.2 Using PESTPP-OPT

### Additional Summaries
- **Higher-Level Summary:** In "predictive analysis" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.
- **Detailed Summary:** In "predictive analysis" mode, PEST maximizes/minimizes a prediction (in the "predict" group) while keeping the objective function ≤ Φ0 (requires a prior "estimation" run).  It uses the same parameters, transformations, and observations as the estimation run.  Restarting uses `/r`, `/j`, `/d`, or `/s` (parallel runs).  Change limits remain important.  Screen output shows prediction values per iteration.  Results include the optimal prediction and parameter values.

### Related Context
- **Previous Summary:** PESTPP-OPT's *parcov* control variable (used also by PESTPP-GLM and PESTPP-IES) specifies a prior parameter covariance matrix (from *.cov*, *.unc*, *.jco*, or *.jcb* files, Appendix B). Log-transformed parameters require log-based covariances. If absent, PESTPP-OPT assumes independence and calculates standard deviations as 1/4 the bound range (*par_sigma_range* modifies this).  Decision variables are not included.
- **Next Summary:** PESTPP-OPT calculates derivatives of constraint-relevant model outputs using finite differences (controlled by parameter group settings), unless using external derivatives (*base_jacobian*).  The J matrix (calibration outputs vs. parameters) and y vector (constraint outputs vs. parameters) are updated every *opt_recalc_fosm_every* iterations (default 1).  If all calibration observation weights are zero or there are no calibration observations,  PESTPP-OPT uses prior parameter uncertainties (*parcov*) for δo calculations.

### Metadata
- **Keywords:** 
- **Chunk ID:** 0d422662ecd4
- **Chunk Index:** 1
- **Previous Chunk ID:** 260f819431ee
- **Next Chunk ID:** f37e2862cb8c

---

## Context

### Summary
**This section describes PEST control file variables governing multiple command lines, model messaging, and external derivatives functionality.**

### Header
**12.5.1 General**

### Content
Variables within the PEST control file that govern PEST’s multiple command line, model messaging, and external derivatives functionality are now described.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 12. Model-Calculated Derivatives (continuación)
- **Subsection:** 12.5 PEST Control Variables

### Additional Summaries
- **Higher-Level Summary:** PEST uses pest.mmf to send messages before each run, indicating run type and parameter details. Different commands can be used for regular and derivative-calculating model runs, potentially reducing run time. Models can provide PEST with derivatives more efficiently, supporting various file formats. PEST control file variables manage model commands, messaging, and external derivatives.
- **Detailed Summary:** This section explains PEST control file variables for managing model commands, messaging, and external derivatives. Key variables include NUMCOM for the number of model commands, JACFILE for external derivatives format, and MESSFILE for message file control. Parallel PEST is not compatible with external derivatives. DERCOM specifies model commands for derivative calculations.

### Related Context
- **Previous Summary:** Parallel PEST and BEOPEST do not support receiving derivatives via external files.
- **Next Summary:** NUMCOM (integer, ≥1) specifies the number of model commands (excluding the external derivatives command). JACFILE (integer) indicates whether external derivatives are used (1=ASCII, -1=binary, 2=JUPITER format). MESSFILE (0 or 1) controls writing a PEST-to-model message file.  Parallel PEST is incompatible with external derivatives (JACFILE>0).

### Metadata
- **Keywords:** 
- **Chunk ID:** dd9539f78d9d
- **Chunk Index:** 1
- **Previous Chunk ID:** 151b01f8fd63
- **Next Chunk ID:** cb58dfd3b1b7

---

## Context

### Summary
**A "regularisation" section is required in the PEST control file only when PESTMODE is set to "regularisation" (Chapter 9).**

### Header
**4.17 Regularisation Section**

### Content
If PEST is run in “regularisation” mode, (i.e. if the PESTMODE variable residing in the “control data” section of the PEST control file is set to “regularisation”), then the PEST control file must have a “regularisation” section. Details are provided in chapter 9 of this manual.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 4. The PEST Control File
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** Figure 4.2 in PEST software displays control data section variables. The text details options for writing matrices, files, and parameters, including settings for matrix and file saving, operational modes, precision, derivative handling, and convergence criteria. Optional features like sensitivity reuse and LSQR algorithm for solving inverse problems are discussed.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** A "predictive analysis" section is required in the PEST control file only when PESTMODE is set to "prediction" (Chapter 8).
- **Next Summary:** A "pareto" section is required in the PEST control file only when PESTMODE is set to "pareto" (Chapter 13).

### Metadata
- **Keywords:** PESTMODE
- **Chunk ID:** d4b641af704e
- **Chunk Index:** 1
- **Previous Chunk ID:** 5c5b488c3e40
- **Next Chunk ID:** 2394701f7a4d

---

## Context

### Summary
**PEST reduces computational burden via parallel processing (Parallel PEST, BEOPEST), using super parameters (SVD-assist) for efficient sensitivity calculations, and employing surrogate models (observation re-referencing) for faster derivative calculations, all potentially parallelized.**

### Header
**1.6.7 Numerical Burden**

### Content
Parameter estimation and calibration-constrained parameter and predictive uncertainty analysis requires the undertaking of many model runs. Where model run times are long, and where the number of parameters requiring adjustment is large, this represents a considerable numerical burden. PEST provides three mechanisms for easing this burden.
The first mechanism is run parallelisation. Calculation of a Jacobian (i.e. sensitivity) matrix is 100 percent parallelizable. To some extent the testing of parameter upgrades calculated on the basis of these sensitivities using different values of the Marquardt lambda is also parallelizable. Parallel PEST and BEOPEST allow a modeller to parallelise runs across different processors on the same machine, across machines, across networks and across the world.
When undertaking highly parameterized inversion, the numerical burden of Jacobian matrix calculation can be greatly eased if sensitivities are calculated not to parameters themselves, but to combinations of parameters that have been identified through singular value composition as being uniquely estimable on the basis of the current calibration dataset; these combinations are referred to as “super parameters” in PEST parlance. PEST accomplishes this through its SVD-assist functionality. Model runs undertaken for super parameter sensitivity calculation can be parallelised, this achieving further increases in numerical efficiency.
Through its “observation re-referencing” functionality, PEST can use one or more surrogate models instead of the actual model when calculating finite-difference derivatives of model outputs with respect to adjustable parameters. If the run time of the surrogate model is much smaller than that of the actual model, the computational burden of the inversion process can be reduced considerably. Further gains can be made through parallelisation of surrogate and actual model runs in an SVD-assisted inversion process.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 1. Introduction
- **Subsection:** 1.6 Some Practical Considerations

### Additional Summaries
- **Higher-Level Summary:** To install PEST, copy its executables to a folder in the PATH variable for access from any directory. The suite includes PEST, Parallel PEST, BEOPEST, SENSAN, global optimizers, and utilities. PEST calibrates models by matching outputs to measurements, handling non-uniqueness through regularization. It quantifies uncertainties and supports decision-making by identifying unlikely events.
- **Detailed Summary:** PEST is a modeling tool that runs via system calls with command-line access, benefiting from the model's directory in the PATH variable. It supports batch files, pre- and post-processors, and multiple simulators. To avoid errors, batch files should delete intermediate files. PEST interacts with ASCII template and instruction files, converting binary files with a postprocessor. Gradient methods for inversion require calculable derivatives, with considerations for non-continuous model outputs and local optima. Regularization and multi-component objectives can address parameter nonuniqueness. PEST optimizes computational efficiency through parallel processing, super parameters, and surrogate models.

### Related Context
- **Previous Summary:** PEST reads model outputs ("observations") from instruction files, including predictions (weighted zero) alongside calibration data.  Predictive analysis and Pareto modes utilize predictions, while sensitivity analysis may include them with or without affecting parameter estimation.
- **Next Summary:** This section introduces PEST's capabilities by listing tasks and associated programs,  even referencing concepts explained later in the manual.  It aims to familiarize new users with PEST and its utilities.

### Metadata
- **Keywords:** 
- **Chunk ID:** 30652bfd50c7
- **Chunk Index:** 1
- **Previous Chunk ID:** 1aeee8517360
- **Next Chunk ID:** 41dda665a758

---

## Context

### Summary
**Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.**

### Header
**14.2 General Principles**

### Content
On most occasions of its deployment, PEST calculates derivatives of model outputs with respect to adjustable parameters using finite differences. In some cases it may be possible for a different model to be employed for the purpose of derivatives calculation from that which is used for the purpose of testing and upgrading parameters. This may be desirable where a simplified “surrogate model” is run for the purpose of derivatives calculation, and this model has a short run time compared with that of the model which is actually being calibrated. If this strategy is attempted, however, certain problems may arise. These will now be discussed.
The difference equation through which the derivative of observation j with respect to parameter i is calculated can be written as
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ∂oj/∂pi ≈ (ovi − orj) / (pv − pij)  (14.2.1)
In equation 14.2.1, pir is the base value (i.e. the current reference value) of parameter p while ojr is the value of the model output corresponding to observation o calculated by the model j using the base parameter set. pv is the value of parameter i when incrementally varied for the purpose of derivatives calculation while ovi is the model-calculated value of observation j when parameter i is thus varied.
Normally ojr is calculated by PEST using either the initial model run, or during the parameter upgrade process where different model runs are undertaken on the basis of different trial parameter sets calculated using different Marquardt lambdas. In the latter case the best upgrade is selected and new parameters are based on that; meanwhile model outputs calculated on the basis of the best parameter set become the base model outputs or “reference model outputs” used in the above equation for finite-difference derivatives calculation for the next PEST iteration.
A problem arises if a different model (for example a simpler and faster-running model) is to
be employed for derivatives calculation from that which is used for testing parameter upgrades. In this case reference model outputs calculated using the complex model are not appropriate for use in the finite-difference derivatives equation when applied to outputs of the simple model. The above equation is only valid when the same model is used to calculate both ovi and ojr. Hence, for finite-difference-calculated derivatives to have integrity in this case, the simple model must be run especially to calculate or using the reference parameter j set. This requires a special model run to be undertaken at the beginning of each iteration. This special model run is indeed carried out if “observation re-referencing” is activated.
In more complex cases where more than one version of the model is used for the purpose of derivatives calculation (for example if multiple simple models are employed, each used for the calculation of derivatives with respect to a different subset of parameters), then an observation re-referencing model run must be undertaken for each version of the model that is so employed.
Using the multiple command line functionality described in section 12.3 it is possible to employ different model versions for calculation of finite-difference derivatives with respect to different parameters. However use of this functionality on its own requires that the different models employed for this purpose are all components of the one large model, and that the same set of reference model outputs (namely those calculated by the total model) are applicable to all of them. Under these circumstances observation re-referencing is not required. However with implementation of observation re-referencing in conjunction with multiple model commands, it is no longer required that models used in finite-difference derivatives calculation produce the same outputs as the main model if supplied with the same set of reference parameter values.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 14. Observation Re-referencing
- **Subsection:** 

### Additional Summaries
- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.
- **Detailed Summary:** 

### Related Context
- **Previous Summary:** Observation re-referencing (extending section 12.3's multiple command lines) allows using simpler models for derivative calculations while applying upgrades to the complex model and modifying initial model conditions (e.g., initial heads) based on upgraded parameters to improve solver convergence time.
- **Next Summary:** With observation re-referencing (NUMCOM=1, DERCOM=1 for all adjustable parameters), three commands are used: the main model command,  a derivative calculation command ("d_" prefix), and a reference model output command ("r_" prefix). The main command is used for objective function calculations and parameter upgrades. The "d_" command calculates derivatives; the "r_" command computes reference model outputs (used in Equation 14.2.1) for the next iteration.  The "d_" and "r_" commands may be identical.

### Metadata
- **Keywords:** lambdas
- **Chunk ID:** 95c539ce2b81
- **Chunk Index:** 1
- **Previous Chunk ID:** 5ff683afff57
- **Next Chunk ID:** 89f2ddbb0470

---


Answer strictly following the above instructions.

```

# Complete Messages Array
```json
[
  {
    "role": "system",
    "content": "\nYou are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:\n\n**Direct Answer First:**\n- Begin with a comprehensive answer that directly addresses the question\n- Include all relevant details and context from the documentation\n- Don't artificially limit the length - be as thorough as the documentation allows\n- Use clear paragraphs and formatting for readability\n- NEVER invent, infer, or add information not explicitly present in the documentation\n\nThen, continue with the detailed structure:\n\n1. **Detailed Analysis:**  \n   - Use the following structure:\n\n     **1) Definition/Overview**  \n     - For technical terms: provide a complete definition with all relevant details\n     - For broader questions: provide a thorough overview of the topic\n     - Include all relevant context and relationships\n     - Cite source(s) using the format \"File: [filename], Section: [header]\".\n\n     **2) Possible Values**  \n     - If applicable: describe all valid or recognized values in detail\n     - Include defaults, ranges, and special cases if documented\n     - If not applicable: state \"Not applicable for this topic\"\n     - Cite source(s).\n\n     **3) Implications**  \n     - Provide a thorough explanation of all usage considerations and consequences\n     - Include any relationships with other components or features\n     - If not available, state: \"Information not available in the provided content.\"\n\n     **4) Practical Usage Notes**  \n     - Include all usage notes, examples, and practical applications\n     - Provide context for when and how to use the feature/component\n     - Otherwise, state: \"No usage notes found in the provided content.\"\n\n     **5) Keywords**  \n     - List ONLY keywords that are EXPLICITLY present in the provided documentation\n     - Keywords must be copied EXACTLY as they appear in the documentation\n     - DO NOT infer, generate, or create keywords that are not explicitly listed\n     - If no keywords are found in the documentation, you MUST state EXACTLY: \"No keywords found in the provided content\"\n     - DO NOT add any explanation or commentary about keywords\n\n2. **Follow-up Questions:**  \n   - After your main answer, list **exactly 3 follow-up questions**\n   - Questions MUST:\n     - If the original query was fully answered:\n       - Be directly related to the original query \"{query}\"\n       - Lead to deeper understanding of the main topic\n     - If the original query was partially answered or not answered:\n       - Focus on related topics found in the documentation\n       - Help build context around the topic\n     - In all cases:\n       - FIRST verify that detailed information exists in the documentation to answer the question\n       - ONLY ask questions about topics with substantial documented information\n       - Be derived from content in Additional Summaries and Related Context sections\n       - Ask ONE single thing - no \"if/how/why\" combinations\n       - Be concise and direct\n       - AVOID: \n         - \"if so\", \"and how\", \"under what conditions\", \"and why\"\n         - Questions about implications/effects unless explicitly documented\n         - Questions about relationships unless clearly described\n         - Questions about usage impacts unless specifically detailed\n       - NEVER ask about:\n         - Topics that are only briefly mentioned\n         - Implications that aren't explicitly documented\n         - Effects or impacts not clearly described\n         - Relationships between components unless documented\n         - Usage scenarios not specifically outlined\n   - Examples of GOOD questions (one thing only and well documented):\n     - \"What is the purpose of nonlinear penalty functions?\"\n     - \"How does PEST handle parameter bounds during the regularization process?\"\n     - \"How does PEST calculate parameter sensitivities?\"\n   - Examples of BAD questions (too compound or insufficient documentation):\n     - \"Can OBS2OBS process observations directly, and if so, how?\"\n     - \"What are the implications of risk-averse settings if documentation only mentions they exist?\"\n     - \"How does a feature work if only its name is mentioned?\"\n     - \"What are the equations and when should they be used?\"\n     - \"What effect does X have on Y?\" (unless effects are explicitly documented)\n     - \"How does changing X impact Y?\" (unless impacts are clearly described)\n   - Before writing each question:\n     1. Verify that substantial information exists to answer it\n     2. Confirm the topic is explained in detail, not just mentioned\n     3. Check that specific details and explanations are available\n     4. Verify that any implications/effects/relationships mentioned in the question are explicitly documented\n   - Present as a simple numbered list (1-3)\n   - If you cannot find 3 questions that meet these criteria, include fewer questions or none at all\n\n3. **Important Instructions:**  \n   - **Do not mention internal processes, \"chunks,\" or retrieval steps.**  \n   - **Do not include any self-commentary or extra explanations.**\n   - Use only the documentation provided in `{context}`.\n\nAnswer strictly following the structure and rules above.\n"
  },
  {
    "role": "user",
    "content": "\nQuestion: What is the role of the `opt_risk` control variable in the optimization process managed by PESTPP-OPT?\n\nPlease provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:\n\n1. **Cite Sources:**  \n   - Use the format \"File: [filename], Section: [header]\" whenever you reference specific details.\n\n2. **Include Examples:**  \n   - Provide relevant examples from the documentation if available.\n\n3. **Note Limitations:**  \n   - If the documentation is incomplete or ambiguous, explicitly state: \"Information not available in the provided content.\"\n\n4. **Follow-up Questions:**  \n   - After your main answer, list **exactly 3 follow-up questions** based primarily on:\n     - \"Additional Summaries\" sections\n     - \"Related Context\" sections\n   - Each question must reference its source section\n   - Do not provide answers to these questions\n   - Present as a simple numbered list (1-3)\n\n5. **Keywords Section:**  \n   - Include a \"Keywords\" section if applicable.\n   - If none are provided, state: \"No keywords found in the provided content.\"\n\n6. **Avoid Internal Details:**  \n   - Do not mention internal processes or retrieval steps.\n   - Do not include self-commentary or extra explanations.\n\n7. **Be Concise and Accurate:**  \n   - NEVER invent details, assumptions, or content\n   - ONLY use information EXPLICITLY stated in the provided documentation\n   - If information is missing, state EXACTLY: \"Information not available in the provided content\"\n   - DO NOT try to fill gaps or make assumptions about missing information\n   - When in doubt, acknowledge the limitation of the available information\n\n**Available Documentation with Metadata:**\n# Search Results for: What is the role of the `opt_risk` control variable in the optimization process managed by PESTPP-OPT?\n\nKeywords: None\n\n\n## Context\n\n### Summary\n***opt_risk* (0.0-1.0) controls risk in PESTPP-OPT. 0.5 is risk-neutral (δo=0, no uncertainty calculations).  >0.5 is risk-averse; constraints are applied to *o* ± δ*o* (upper/lower bound of the confidence interval, respectively). <0.5 is risk-tolerant; constraints are applied to *o* ∓ δ*o*.  δ*o* is calculated based on the model output's standard deviation.**\n\n### Header\n**8.2.8 Risk**\n\n### Content\nUsing the *opt_risk()* control variable, a user specifies his/her disposition with respect to risk. The setting of this variable determines the value of δ*o* discussed in section 8.1. This is the value that is added/subtracted to/from a model output before a constraint is applied to that output.\nThe value supplied for *opt_risk()* should be greater than zero and less than one. If the value supplied for *opt_risk()* is 0.5, then operation of PESTPP-OPT is risk neutral. In this case δ*o* is zero. Under these circumstances PESTPP-OPT does not calculate model output uncertainty at all. It therefore does not need to read (or calculate for itself) a prior parameter covariance matrix. Also, it does not need to read (or calculate for itself) derivatives of model outputs with respect to model parameters which are not decision-variables.\nAn *opt_risk()* setting of greater than 0.5 indicates risk aversion. For “less than” constraints (i.e., constraints for which a system state or flux must be less than a certain value), δ*o* is added to the model-calculated system state or flux (i.e., *o*) so that the constraint is applied to *o* + δ*o*. The opposite applies for “greater than” constraints. Suppose, for example, that *opt_risk()* is supplied as 0.95. Then, for a “less than” constraint, δ*o* is calculated to be such that there is a 95% chance that the real system state or flux is less than *o* + δ*o*. Similarly, for a “greater than” constraint, δ*o* is calculated to be such that there is a 95% chance that the real system state or flux is greater than *o* – δ*o*. In both of these cases *o* is the value that the model calculates for this quantity based on the current values of decision variables.\nA setting for *opt_risk()* that is less than 0.5 indicates risk tolerance. For “less than” constraints, the constraint is applied to *o* - δ*o*. The opposite applies for “greater than” constraints. Suppose that *opt_risk()* is supplied as 0.05. Then, for a “less than” constraint, δ*o* is calculated to be such that there is a 5% chance that the real system state or flux corresponding to a certain set of decision variables is less than *o* - δ*o*. Similarly, for a “greater than” constraint, δ*o* is calculated to be such that there is a 5% chance that the real system state or flux corresponding to a certain set of decision variables is greater than *o* + δ*o*.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation: PEST++ a Software Suite for Parameter Estimation, Uncertainty Analysis, Management Optimization and Sensitivity Analysis\n- **Main Section:** 8. PESTPP-OPT\n- **Subsection:** 8.2 Using PESTPP-OPT\n\n### Additional Summaries\n- **Higher-Level Summary:** In \"predictive analysis\" mode, PEST optimizes predictions while maintaining the objective function below a threshold, considering post-calibration uncertainty. It requires accurate derivatives, a prior calibration process, and parameter consistency with the estimation run. Users can adjust Marquardt lambda, search parameters, and incorporate predictive noise for improved analysis.\n- **Detailed Summary:** In \"predictive analysis\" mode, PEST maximizes/minimizes a prediction (in the \"predict\" group) while keeping the objective function ≤ Φ0 (requires a prior \"estimation\" run).  It uses the same parameters, transformations, and observations as the estimation run.  Restarting uses `/r`, `/j`, `/d`, or `/s` (parallel runs).  Change limits remain important.  Screen output shows prediction values per iteration.  Results include the optimal prediction and parameter values.\n\n### Related Context\n- **Previous Summary:** PESTPP-OPT's *parcov* control variable (used also by PESTPP-GLM and PESTPP-IES) specifies a prior parameter covariance matrix (from *.cov*, *.unc*, *.jco*, or *.jcb* files, Appendix B). Log-transformed parameters require log-based covariances. If absent, PESTPP-OPT assumes independence and calculates standard deviations as 1/4 the bound range (*par_sigma_range* modifies this).  Decision variables are not included.\n- **Next Summary:** PESTPP-OPT calculates derivatives of constraint-relevant model outputs using finite differences (controlled by parameter group settings), unless using external derivatives (*base_jacobian*).  The J matrix (calibration outputs vs. parameters) and y vector (constraint outputs vs. parameters) are updated every *opt_recalc_fosm_every* iterations (default 1).  If all calibration observation weights are zero or there are no calibration observations,  PESTPP-OPT uses prior parameter uncertainties (*parcov*) for δo calculations.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 0d422662ecd4\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 260f819431ee\n- **Next Chunk ID:** f37e2862cb8c\n\n---\n\n## Context\n\n### Summary\n**This section describes PEST control file variables governing multiple command lines, model messaging, and external derivatives functionality.**\n\n### Header\n**12.5.1 General**\n\n### Content\nVariables within the PEST control file that govern PEST’s multiple command line, model messaging, and external derivatives functionality are now described.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 12. Model-Calculated Derivatives (continuación)\n- **Subsection:** 12.5 PEST Control Variables\n\n### Additional Summaries\n- **Higher-Level Summary:** PEST uses pest.mmf to send messages before each run, indicating run type and parameter details. Different commands can be used for regular and derivative-calculating model runs, potentially reducing run time. Models can provide PEST with derivatives more efficiently, supporting various file formats. PEST control file variables manage model commands, messaging, and external derivatives.\n- **Detailed Summary:** This section explains PEST control file variables for managing model commands, messaging, and external derivatives. Key variables include NUMCOM for the number of model commands, JACFILE for external derivatives format, and MESSFILE for message file control. Parallel PEST is not compatible with external derivatives. DERCOM specifies model commands for derivative calculations.\n\n### Related Context\n- **Previous Summary:** Parallel PEST and BEOPEST do not support receiving derivatives via external files.\n- **Next Summary:** NUMCOM (integer, ≥1) specifies the number of model commands (excluding the external derivatives command). JACFILE (integer) indicates whether external derivatives are used (1=ASCII, -1=binary, 2=JUPITER format). MESSFILE (0 or 1) controls writing a PEST-to-model message file.  Parallel PEST is incompatible with external derivatives (JACFILE>0).\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** dd9539f78d9d\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 151b01f8fd63\n- **Next Chunk ID:** cb58dfd3b1b7\n\n---\n\n## Context\n\n### Summary\n**A \"regularisation\" section is required in the PEST control file only when PESTMODE is set to \"regularisation\" (Chapter 9).**\n\n### Header\n**4.17 Regularisation Section**\n\n### Content\nIf PEST is run in “regularisation” mode, (i.e. if the PESTMODE variable residing in the “control data” section of the PEST control file is set to “regularisation”), then the PEST control file must have a “regularisation” section. Details are provided in chapter 9 of this manual.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 4. The PEST Control File\n- **Subsection:** \n\n### Additional Summaries\n- **Higher-Level Summary:** Figure 4.2 in PEST software displays control data section variables. The text details options for writing matrices, files, and parameters, including settings for matrix and file saving, operational modes, precision, derivative handling, and convergence criteria. Optional features like sensitivity reuse and LSQR algorithm for solving inverse problems are discussed.\n- **Detailed Summary:** \n\n### Related Context\n- **Previous Summary:** A \"predictive analysis\" section is required in the PEST control file only when PESTMODE is set to \"prediction\" (Chapter 8).\n- **Next Summary:** A \"pareto\" section is required in the PEST control file only when PESTMODE is set to \"pareto\" (Chapter 13).\n\n### Metadata\n- **Keywords:** PESTMODE\n- **Chunk ID:** d4b641af704e\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 5c5b488c3e40\n- **Next Chunk ID:** 2394701f7a4d\n\n---\n\n## Context\n\n### Summary\n**PEST reduces computational burden via parallel processing (Parallel PEST, BEOPEST), using super parameters (SVD-assist) for efficient sensitivity calculations, and employing surrogate models (observation re-referencing) for faster derivative calculations, all potentially parallelized.**\n\n### Header\n**1.6.7 Numerical Burden**\n\n### Content\nParameter estimation and calibration-constrained parameter and predictive uncertainty analysis requires the undertaking of many model runs. Where model run times are long, and where the number of parameters requiring adjustment is large, this represents a considerable numerical burden. PEST provides three mechanisms for easing this burden.\nThe first mechanism is run parallelisation. Calculation of a Jacobian (i.e. sensitivity) matrix is 100 percent parallelizable. To some extent the testing of parameter upgrades calculated on the basis of these sensitivities using different values of the Marquardt lambda is also parallelizable. Parallel PEST and BEOPEST allow a modeller to parallelise runs across different processors on the same machine, across machines, across networks and across the world.\nWhen undertaking highly parameterized inversion, the numerical burden of Jacobian matrix calculation can be greatly eased if sensitivities are calculated not to parameters themselves, but to combinations of parameters that have been identified through singular value composition as being uniquely estimable on the basis of the current calibration dataset; these combinations are referred to as “super parameters” in PEST parlance. PEST accomplishes this through its SVD-assist functionality. Model runs undertaken for super parameter sensitivity calculation can be parallelised, this achieving further increases in numerical efficiency.\nThrough its “observation re-referencing” functionality, PEST can use one or more surrogate models instead of the actual model when calculating finite-difference derivatives of model outputs with respect to adjustable parameters. If the run time of the surrogate model is much smaller than that of the actual model, the computational burden of the inversion process can be reduced considerably. Further gains can be made through parallelisation of surrogate and actual model runs in an SVD-assisted inversion process.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 1. Introduction\n- **Subsection:** 1.6 Some Practical Considerations\n\n### Additional Summaries\n- **Higher-Level Summary:** To install PEST, copy its executables to a folder in the PATH variable for access from any directory. The suite includes PEST, Parallel PEST, BEOPEST, SENSAN, global optimizers, and utilities. PEST calibrates models by matching outputs to measurements, handling non-uniqueness through regularization. It quantifies uncertainties and supports decision-making by identifying unlikely events.\n- **Detailed Summary:** PEST is a modeling tool that runs via system calls with command-line access, benefiting from the model's directory in the PATH variable. It supports batch files, pre- and post-processors, and multiple simulators. To avoid errors, batch files should delete intermediate files. PEST interacts with ASCII template and instruction files, converting binary files with a postprocessor. Gradient methods for inversion require calculable derivatives, with considerations for non-continuous model outputs and local optima. Regularization and multi-component objectives can address parameter nonuniqueness. PEST optimizes computational efficiency through parallel processing, super parameters, and surrogate models.\n\n### Related Context\n- **Previous Summary:** PEST reads model outputs (\"observations\") from instruction files, including predictions (weighted zero) alongside calibration data.  Predictive analysis and Pareto modes utilize predictions, while sensitivity analysis may include them with or without affecting parameter estimation.\n- **Next Summary:** This section introduces PEST's capabilities by listing tasks and associated programs,  even referencing concepts explained later in the manual.  It aims to familiarize new users with PEST and its utilities.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 30652bfd50c7\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 1aeee8517360\n- **Next Chunk ID:** 41dda665a758\n\n---\n\n## Context\n\n### Summary\n**Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.**\n\n### Header\n**14.2 General Principles**\n\n### Content\nOn most occasions of its deployment, PEST calculates derivatives of model outputs with respect to adjustable parameters using finite differences. In some cases it may be possible for a different model to be employed for the purpose of derivatives calculation from that which is used for the purpose of testing and upgrading parameters. This may be desirable where a simplified “surrogate model” is run for the purpose of derivatives calculation, and this model has a short run time compared with that of the model which is actually being calibrated. If this strategy is attempted, however, certain problems may arise. These will now be discussed.\nThe difference equation through which the derivative of observation j with respect to parameter i is calculated can be written as\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ∂oj/∂pi ≈ (ovi − orj) / (pv − pij)  (14.2.1)\nIn equation 14.2.1, pir is the base value (i.e. the current reference value) of parameter p while ojr is the value of the model output corresponding to observation o calculated by the model j using the base parameter set. pv is the value of parameter i when incrementally varied for the purpose of derivatives calculation while ovi is the model-calculated value of observation j when parameter i is thus varied.\nNormally ojr is calculated by PEST using either the initial model run, or during the parameter upgrade process where different model runs are undertaken on the basis of different trial parameter sets calculated using different Marquardt lambdas. In the latter case the best upgrade is selected and new parameters are based on that; meanwhile model outputs calculated on the basis of the best parameter set become the base model outputs or “reference model outputs” used in the above equation for finite-difference derivatives calculation for the next PEST iteration.\nA problem arises if a different model (for example a simpler and faster-running model) is to\nbe employed for derivatives calculation from that which is used for testing parameter upgrades. In this case reference model outputs calculated using the complex model are not appropriate for use in the finite-difference derivatives equation when applied to outputs of the simple model. The above equation is only valid when the same model is used to calculate both ovi and ojr. Hence, for finite-difference-calculated derivatives to have integrity in this case, the simple model must be run especially to calculate or using the reference parameter j set. This requires a special model run to be undertaken at the beginning of each iteration. This special model run is indeed carried out if “observation re-referencing” is activated.\nIn more complex cases where more than one version of the model is used for the purpose of derivatives calculation (for example if multiple simple models are employed, each used for the calculation of derivatives with respect to a different subset of parameters), then an observation re-referencing model run must be undertaken for each version of the model that is so employed.\nUsing the multiple command line functionality described in section 12.3 it is possible to employ different model versions for calculation of finite-difference derivatives with respect to different parameters. However use of this functionality on its own requires that the different models employed for this purpose are all components of the one large model, and that the same set of reference model outputs (namely those calculated by the total model) are applicable to all of them. Under these circumstances observation re-referencing is not required. However with implementation of observation re-referencing in conjunction with multiple model commands, it is no longer required that models used in finite-difference derivatives calculation produce the same outputs as the main model if supplied with the same set of reference parameter values.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 14. Observation Re-referencing\n- **Subsection:** \n\n### Additional Summaries\n- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.\n- **Detailed Summary:** \n\n### Related Context\n- **Previous Summary:** Observation re-referencing (extending section 12.3's multiple command lines) allows using simpler models for derivative calculations while applying upgrades to the complex model and modifying initial model conditions (e.g., initial heads) based on upgraded parameters to improve solver convergence time.\n- **Next Summary:** With observation re-referencing (NUMCOM=1, DERCOM=1 for all adjustable parameters), three commands are used: the main model command,  a derivative calculation command (\"d_\" prefix), and a reference model output command (\"r_\" prefix). The main command is used for objective function calculations and parameter upgrades. The \"d_\" command calculates derivatives; the \"r_\" command computes reference model outputs (used in Equation 14.2.1) for the next iteration.  The \"d_\" and \"r_\" commands may be identical.\n\n### Metadata\n- **Keywords:** lambdas\n- **Chunk ID:** 95c539ce2b81\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 5ff683afff57\n- **Next Chunk ID:** 89f2ddbb0470\n\n---\n\n\nAnswer strictly following the above instructions.\n"
  }
]
```