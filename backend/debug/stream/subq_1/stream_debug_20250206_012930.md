# Stream Debug - 20250206_012930

# Original Question
```
How does PEST perform model calibration?
```

# Context Content
```markdown
# Search Results for: How does PEST perform model calibration?

Keywords: None


## Context

### Summary
**Parallel PEST's efficiency decreases with short model run times due to file I/O and message passing latency. BEOPEST, using TCP/IP, minimizes these overheads because agents perform file I/O locally.**

### Header
**11.1.4 Communication Overheads**

### Content
If model run times are short, gains in computational efficiency that are achievable using Parallel PEST will not be as great as when model times are large, for the time taken in writing and reading (possibly lengthy) model input and output files across a local area network may then become large in comparison with model run times. Another contributor to parallelisation latency is the use of message files for communication between manager and agents. It may take a number of seconds before a message issued by one is received by the other.
Because it uses TCP/IP for messaging, and because the BEOPEST agent writes model input files and reads model output files locally, manager/agent communication overheads are very low for BEOPEST.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 11. Parallel PEST and BEOPEST (continuación)
- **Subsection:** 11.1 General (continuación)

### Additional Summaries
- **Higher-Level Summary:** Parallel PEST and BEOPEST parallelize model runs to reduce run time. Parallel PEST needs a run management file, while BEOPEST's is optional. Both distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Parallel PEST uses PAGENT agents, requires separate folders for agents, and shared signal files for communication. BEOPEST offers ease of use, faster communication, flexibility, and support for multiple command lines and surrogate models.
- **Detailed Summary:** Parallel PEST and BEOPEST parallelize model runs, reducing PEST run time. Parallel PEST requires a run management file, while BEOPEST's is optional. They distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Both store data in binary files for reduced memory needs.

### Related Context
- **Previous Summary:** Parallel PEST/BEOPEST partially parallelizes Marquardt lambda testing by running models with multiple lambdas (related by RLAMFAC) simultaneously.  Some runs may be wasted, but idle processors are avoided.  Parallel lambda testing may be disabled in "predictive analysis" mode (line search) or if parameters hit bounds.
- **Next Summary:** Parallel PEST (ppest.exe, i64ppest.exe) and BEOPEST (beopest32.exe, beopest64.exe) are automatically installed.  PAGENT.exe is required for Parallel PEST on each agent machine; BEOPEST uses its own executable as the agent.  Model programs and files must also be copied to agent machines before running Parallel PEST or BEOPEST.

### Metadata
- **Keywords:** 
- **Chunk ID:** cb0f0bfcff07
- **Chunk Index:** 1
- **Previous Chunk ID:** df6c96c24b07
- **Next Chunk ID:** 3de0f3c0071a

---

## Context

### Summary
**Verify the DSI2-generated PEST control file (case.pst) using PESTCHEK (it will not approve case_sd.pst if created). Run PESTPP-IES using `pestpp-ies case` or `pestpp-ies case_sd` (depending on whether standard deviations are provided). Monitor case.phi.actual.csv;  accept results at or near the target objective function value (≈number of non-zero-weighted observations). Use case.J.obs.csv (N realizations) to create posterior prediction histograms.**

### Header
**18.3.7 Running PESTPP-IES**

### Content
Once DSI2 has written its PEST input dataset, the entire dataset can be checked using PESTCHEK. Suppose that the DSI2‑produced PEST control file is named case.pst. Then PESTCHEK can be run using the command:
pestchek case
Note, however, that if a secondary PESTPP‑IES‑only PEST control file is written, then PESTCHECK will not approve of this file, for it does not support the use of external observation data files. (However PESTPP‑IES will happily read this file.)
PESTPP‑IES can then be run using the command:
pestpp-ies case
or
pestpp-ies case_sd
depending on whether or not a user specifically provides standard deviations of measurement noise.
If measurement noise standard deviations are “correct”, or if only weights are supplied and they are equal to the inverse standard deviations of measurement noise, the objective function should be reduced to a value that is about equal to the number of non‑zero‑weighted
observations. PESTPP‑IES should be prevented from reducing the objective function below this. Monitor file case.phi.actual.csv to see the iteration number at which the desired value of the objective function is achieved. If necessary, accept results from a few iterations before the last iteration which PESTPP‑IES undertakes (or halt PESTPP‑IES execution when the objective function is lowered to the desired value).
Suppose that a suitable objective function value is achieved at iteration J. Posterior predictive histograms can be constructed using the contents of file case.J.obs.csv. This contains N realisations of all predictions, where N is the number of user‑requested PESTPP‑IES realisations.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 18. Data Space Inversion
- **Subsection:** 18.3 DSI2, DSIMOD and POSTDSIMOD

### Additional Summaries
- **Higher-Level Summary:** The text describes using soil clod shrinkage data to fit two straight lines using Equation 18.1.1 with parameters s1, s2, y1, and xc in the pestex subfolder. The TWOLINE program reads parameters and water contents from in.dat, adjusts parameters using PEST, and generates input files for calculations. The final prediction value is 0.786.
- **Detailed Summary:** DSI2 creates files for data space inversion using PESTPP-IES or PEST_HP, computing an empirical covariance matrix from a CSV file of model outputs. It uses a PEST control file's weights for observations, creating a new control file for history-matching. Posterior predictive uncertainty analysis with PEST_HP involves multiple steps, including running the model NREAL times and calibrating with regularization. Linear analysis is an alternative method.

### Related Context
- **Previous Summary:** DSIMOD (a surrogate model) calculates model outputs.  It's run using `dsimod infile parfile outfile`, where infile (binary, from DSI2) contains transformation variables, d, and C½(d); parfile lists PCA parameter values; and outfile contains the calculated outputs.  Filenames share a common base (from DSI2).
- **Next Summary:** To get posterior prediction means, add regularization to case.pst using ADDREG2 (`addreg2 case case1 target continue`), run PEST (stopping when the solution is deemed sufficient), and obtain predictions from case1.rec or case1.res. For better results, use PEST_HP (`addreg2 case case1 target continue hp`, UPTESTMIN=25), adjusting PHIMLIM until outputs are satisfactory.  Use PARREP to create case_soln.pst (NOPTMAX=0) for a final model run using `pest case_soln /hpstart`.

### Metadata
- **Keywords:** 
- **Chunk ID:** 09cd4afd25d3
- **Chunk Index:** 1
- **Previous Chunk ID:** ac464f91a7cb
- **Next Chunk ID:** 40c1a16585ed

---

## Context

### Summary
**Bounds-sticking (IBOUNDSTICK) prevents wasted model runs by fixing parameters at bounds after a specified number of iterations.  Upgrade vector bending (UPVECBEND) avoids shortening the upgrade vector when parameter change limits are reached, potentially improving performance but may degrade it.  Parameter change limits maintain inversion stability.**

### Header
**3.4.5 Optional Alternative Bounds Accommodation**

### Content
If a model takes a long time to run, then any measures that can be taken to reduce the number of runs required for estimation of its parameters makes that model more useable with PEST. Parameter “bounds-sticking” functionality is one such measure.
When one or more parameters are at their bounds, the procedure by which the parameter upgrade vector is calculated is modified to accommodate this situation. If, for one such parameter, the parameter upgrade vector is such that the parameter is directed away from its bound back into “allowed parameter space”, then that parameter is free to move as it normally would. However parameters for which the upgrade vector points outside of allowed parameter space (i.e. above or below the upper or lower bound at which the parameter currently resides) are sequentially frozen; the sequence in which these parameters are frozen is important; see Doherty (2015). On each occasion that a parameter is frozen, the parameter upgrade vector is re-calculated with currently frozen parameters omitted from the parameter upgrade calculation. At the beginning of each new iteration, all frozen parameters are freed. The whole process is then repeated during the next iteration of the inversion process.
Sometimes a parameter can move to its bound, and then back again into allowed parameter space, during the course of a single inversion process. However if a parameter is at its bound for more than a few iterations, it is more likely than not that the parameter is there to stay. However PEST will continue to calculate derivatives with respect to this parameter in order to attempt an upgrade calculation for it, even though there is a diminishing likelihood that the parameter will ever move from its bounds. Thus one model run per iteration (more if PEST is engaged in higher order finite-difference derivatives calculation) is wasted. Where more than one parameter is at its bound the number of wasted model runs rises in proportion to the number of such parameters.
Through use of the IBOUNDSTICK control variable residing in the “control data” section of the PEST control file, this wastage of model runs can be prevented. PEST can be instructed to permanently “glue” a parameter to its upper or lower bound if that parameter has been residing there for a user-specified number of iterations. Once a parameter is “glued” to its bound it will never move again, for PEST will no longer include this parameter in its upgrade vector calculations. Nor will it calculate derivatives with respect to this parameter, thus reducing the number of model runs required per iteration.
Despite the potential for model run economy that it offers, bounds-sticking functionality should be used with caution.
The UPVECBEND variable (which follows the IBOUNDSTICK variable in the “control data” section of the PEST control file) activates “upgrade parameter vector bending” functionality. Experience has demonstrated that, while this may result in a slight reduction in
the number of model runs required for completion of the parameter estimation process in some situations, it can seriously degrade PEST’s performance in other situations. Hence it should be used only with extreme caution.
As is described by Doherty (2015), and also below, the length of the parameter upgrade vector is limited during any one PEST iteration by the action of factor, relative and/or absolute parameter change limits. Imposition of limits prevents parameter changes from exceeding by too great a margin the range of the linearity assumption upon which their calculation is based. In doing so, it brings stability to the inversion process.
If PEST calculates that a particular parameter must incur a factor, relative or absolute change which is greater than that permitted by pertinent user-supplied limits, then the changes incurred by all parameters are reduced so that the change incurred by the maximally-changed parameter does not exceed its limit; that is, the length of the upgrade vector is reduced to respect this limit while its direction remains unchanged. As it is often the most insensitive parameters for which the largest change is calculated (especially if regularisation is omitted from a PEST control file), it is on behalf of these parameters that the parameter upgrade vector may thus be shortened. If this is the case, then changes incurred by the more important, sensitive, parameters can thus be curtailed by this shortening of the parameter upgrade vector. This may slow the inversion process.
The UPVECBEND variable can instruct PEST not to shorten the parameter upgrade vector in its observance of parameter change limits. Instead it will “bend” this vector so that, while individual parameters are forced to respect their change limits, other parameters can move by the amount dictated by the parameter upgrade vector. Hence changes calculated for sensitive parameters are not restricted by the change limits imposed on more insensitive parameters.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 3. What PEST Does
- **Subsection:** 3.4 Parameter Adjustment

### Additional Summaries
- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.
- **Detailed Summary:** The PEST control file's "parameter data" section manages parameter adjustments, including logarithmic transformations for stability. PARTRANS specifies parameter transformations, with options for fixed, log-transformed, or tied parameters. Bounds, scaling, and offsetting are used to prevent model errors and enhance stability. Parameter changes are limited to prevent over-adjustment. Dampening methods reduce oscillations during optimization.

### Related Context
- **Previous Summary:** PARLBND and PARUBND variables in the PEST control file specify parameter upper and lower bounds.  Wise bound selection prevents model errors (e.g., negative values where logarithms are used).  Bound enforcement enhances inversion stability (see Doherty 2015, section 5.4.2.7).
- **Next Summary:** SCALE and OFFSET (in the "parameter data" section) are applied to parameter values before writing to model input files.  They are useful for parameter transformations (e.g., elevation to thickness) and handling negative parameters.  SCALE=1 and OFFSET=0 indicate no scaling or offsetting.  These are applied only when writing to model input files.

### Metadata
- **Keywords:** IBOUNDSTICK, UPVECBEND
- **Chunk ID:** ac9101194d69
- **Chunk Index:** 1
- **Previous Chunk ID:** 4531f5bdc764
- **Next Chunk ID:** 30c3fca934b4

---

## Context

### Summary
**CMAES_P prompts for CMA-ES variables: λ, μ, recombination weights, seed, and whether to read a covariance matrix. It then prompts for SVD hybridisation (number of thresholds, "soft" or "hard"), model run failure forgiveness, and termination criteria (objective function change, parameter change, objective function difference, maximum iterations).  A final prompt asks whether to run the model with initial parameters.  It can be stopped via PSTOP, PSTOPST, or <Ctrl-C>.  Parallel runs don't automatically shut down agents if stopped via PSTOP.**

### Header
**16.1.5 Running CMAES_P**

### Content
The hybridisation scheme is further explained below. At the time of writing, the default is set to “no”. However you are urged to try this scheme at some stage, especially if you suspect that derivatives of model outputs with respect to adjustable parameters are not too bad. If a response of “y” is provided to this question, CMAES_P next asks two further questions:
How many trial singular value thresholds? (&lt;Enter&gt; if 3):
Use "soft" or "hard" hybridization? [s/h] (&lt;Enter&gt; if "s"):
These are further explained below.
CMAES_P next asks:
Forgive model run failure? [y/n]: (&lt;Enter&gt; if "y"):
If a response of “n” is provided to this prompt, then a failure on the part of CMAES_P to read any part of any model output file after completion of any model run will precipitate cessation of CMAES_P execution with an appropriate error message. However if the response to the above prompt is “y”, CMAES_P will interpret an error in reading model output files as evidence of a model-indigestible parameter set. Internally, it will attribute a very high objective function to this parameter set, thus providing a disincentive to the optimisation process from generating a similar set of parameters.
CMAES_P’s next seven prompts are as follows:
Termination Criteria:
Min rel obj fn change over N itns (&lt;Enter&gt; if 1.00000E-03):
No of itns (N) over which this applies (&lt;Enter&gt; if 40):
Min rel param change over N itns (&lt;Enter&gt; if 1.00000E-03):
No of itns (N) over which this applies (&lt;Enter&gt; if 40):
Rel high-low generated obj fn diff over N itns (&lt;Enter&gt; if 1.0000E-02):
No of itns (N) over which this applies (&lt;Enter&gt; if 10):
Maximum number of iterations (&lt;Enter&gt; if 1000):
A number of CMAES_P termination criteria are similar to those employed by PEST. However the default values of variables governing those criteria are different from those commonly employed by PEST.
The first two of the above prompts pertain to the objective function. If it fails to fall by a
relative amount provided in response to the first of the above prompts over the number of iterations provided in response to the second of the above prompts, then the optimisation process will be deemed to have reached completion.
The third and fourth of the above prompts pertain to parameter changes. If no parameter undergoes a relative change given by the response to the third of the above prompts over a number of iterations provided in response to the fourth of the above prompts, then the optimisation process will be deemed to have reached completion.
The fifth and sixth of the above prompts pertain to objective functions computed during any iteration on the basis of the λ trial parameter sets generated during that iteration. If the relative difference between the highest and lowest of these objective functions is small over a number of successive iterations, this indicates that the covariance matrix used to generate parameter realisations contains small parameter variances (hopefully as an outcome of convergence to the global objective function minimum). As time progress, it becomes more and more unlikely that even a small lowering of the objective function will occur under these conditions.
The maximum number of iterations is provided in response to the seventh of the above prompts. If this is supplied as zero, then CMAES_P will undertake just one model run, this being on the basis of initial parameter values as supplied in the PEST control file. This can be useful when the PARREP utility (see part II of this manual) is employed to create a new PEST control file on the basis of values optimised from a previous CMAES_P or PEST run. A single model run can then be undertaken on the basis of these optimised parameter values.
As soon as one of its termination criteria is satisfied, CMAES_P ceases execution, informing you why it has decided to do this.
CMAES_P’s final prompt is
Run model with initial parameters? [y/n] (<Enter> if "y):
While the default response to the above prompt is “y”, you may prefer to answer “n” in circumstances where model run times are long, especially if CMAES_P undertakes model runs in parallel. In the latter case all machines but one stand idle until this first model run is completed. There is no real advantage to undertaking this run except for the fact that it then “sets the standard” with respect to which objective function outcomes of model runs performed under the control of CMAES_P can be measured. Improvements in the objective function achieved through the calibration process are thereby readily apparent.
Stopping and Restarting
Like PEST, CMAES_P can be stopped by issuing the PSTOP or PSTOPST command from another command line window, opened in the same working folder as CMAES_P. Cessation of execution is instantaneous if CMAES_P is run in parallel mode; however orphaned model runs will continue in their own windows unless halted by the user. When undertaking runs in serial, cessation of CMAES_P execution takes place upon completion of the current model run.
When operating in parallel mode, agents will not automatically shut down if CMAES_P is halted using the PSTOP command (for often a user-instigated stop is followed by a user-instigated re-commencement of the optimisation process). In contrast, if CMAES_P stops of its own accord because a convergence criterion has been met, of if execution is halted using the PSTOPST command, then agents automatically shut down.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 16. PEST-Compatible Global Optimisers
- **Subsection:** 16.1 CMAES_P

### Additional Summaries
- **Higher-Level Summary:** CMAES_P is a global optimizer for unstable/nonlinear models without derivatives, using PEST input files, supporting multiple observation groups, and running in serial/parallel mode. It lacks IREGADJ and sensitivity calculations but prompts for hybridization parameters. SCEUA_P is a PEST-compatible optimizer for discontinuous/noisy models, with termination criteria and parallelization via `/p` switch.
- **Detailed Summary:** CMAES_P is a global optimizer based on CMA-ES, suitable for unstable or nonlinear models without derivatives. It lacks IREGADJ and sensitivity calculations. It uses PEST input files, supports multiple observation groups, and can run in serial or parallel mode. It prompts for CMA and SVD hybridization parameters, outputs various files, and can be restarted with optimized parameters.

### Related Context
- **Previous Summary:** CMAES_P uses PEST's input dataset but prompts for CMA control variables:  λ (population size, Equation 16.1.1), μ (number of parents, Equation 16.1.2), recombination weights ("superlin", "linear", "equal"), random seed, and whether to read a parameter covariance matrix from a file.  It minimizes a weighted least-squares objective function or a single model output (if only one observation and no prior information are present).  It prompts whether to use SVD hybridisation if observations outnumber parameters.
- **Next Summary:** CMAES_P restarts via the `/r` switch; PPAUSE pauses execution until the next model run. A final model run (using optimized parameters) is performed unless stopped in parallel mode via PSTOPST; use PARREP to perform a final run manually.

### Metadata
- **Keywords:** 
- **Chunk ID:** 1460082d8080
- **Chunk Index:** 2
- **Previous Chunk ID:** 7f10120dc35b
- **Next Chunk ID:** 5b337276c98a

---

## Context

### Summary
**PARREDUCE assesses the impact of parameter reduction strategies (removing, fixing, or tying parameters) on model-data misfit. It estimates objective function increases resulting from simplification, helping optimize model complexity.  Calculations are approximate, ignoring measurement noise and pre-existing model simplification; they assume linearity.**

### Header
**14.2.1 General**

### Content
“PARREDUCE” stands for “parameter reduction”. This utility can be used to ascertain the cost, in terms of model‑to‑measurement misfit, of a reduction in the number of parameters employed by a model. Better still, it can be used to compare the effectiveness of different parameter reduction strategies, where “effectiveness” is based on the assumption that those parameter reduction strategies are better which incur simplification‑induced misfit the least.
Use of PARREDUCE assumes that parameter reduction can occur in one of three ways:
- Through removal of parameters from a PEST control file;
- Through fixing parameters within a PEST control file (which is the same as removing them); and/or
- Through tying certain parameters to other parameters, so that the parent parameters are estimated with their child parameters “riding on their backs”. (This is effectively the same as parameter amalgamation.)
Reduction in the number of parameters employed by a model has the obvious advantage that the time required for PEST to calibrate the model is thereby reduced. However savings in computational burden come at a cost; in particular, when the number of parameters employed by a model is reduced, the objective function achieved through the calibration process may increase. Generally, the extent to which this occurs will only be known after PEST has been run to calibrate the simplified model. It is possible that PEST can achieve just as good a fit with a simplified parameter set as with a complex parameter set by adjusting simplified parameter values appropriately. However if the simplified parameter set does not span the calibration solution space of the complex model, model‑to‑measurement fit will be compromised.
The PARREDUCE utility can be used not just for optimisation of model simplification; it can also be used to examine how best to add parameters to a model. A modeller may commence the complexifying processing by adding many parameters to a model – more than he/she
ultimately wishes to add. He/she can then test different ways of amalgamating the supplementary parameters in ways that reflect expert knowledge of, for example, underlying geological variability, before deciding on an ultimate parameter complexification strategy that achieves most reduction in the objective function with the least number of additional parameters. Parameter simplification thus takes place as the second step of an overall parameter complexification process.
PARREDUCE provides information on the relative cost of different simplification strategies. It does this by providing an indication of the expected increase in the objective function incurred by use of fewer model parameters. It must be pointed out however, that the numbers which it calculates are indicative only. No account is taken of the contribution made by measurement noise to the objective function. Nor is account taken of simplification that has already been undertaken in building the original, pre‑simplified model. Furthermore calculations undertaken by PARREDUCE rely on a linearity assumption. Sensitivities on which linear analysis is based are calculated using the parameter set currently employed by the model.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 14. Miscellaneous Utilities
- **Subsection:** 14.2 PARREDUCE

### Additional Summaries
- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.
- **Detailed Summary:** Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.

### Related Context
- **Previous Summary:** This chapter describes miscellaneous PEST utilities: PARREDUCE (parameter reduction), CALMAINTAIN (maintains calibration after parameter changes), PESTLIN/GENLIN (creates linear surrogate models), and DERCOMB (combines model-calculated derivatives).  These utilities are used in contexts where model runtimes are high or when dealing with nonlinear models.
- **Next Summary:** PARREDUCE assesses parameter simplification's impact on model-data misfit using a complex and simplified model (Equation 14.2.4: r=Zk-Xp). It calculates uncalibrated (Equation 14.2.5: C<sub>u</sub>(r)=ZC(k)Z<sup>T</sup>) and calibrated (Equation 14.2.9: C<sub>z</sub>(r)=U₂S₂²U₂<sup>T</sup>, assuming C(k)=I, Equation 14.2.11) residual covariance matrices (using SVD of Z).  It uses two PEST control files (complex and simplified) and assumes zero measurement noise and a perfect model.

### Metadata
- **Keywords:** 
- **Chunk ID:** 696930d301b8
- **Chunk Index:** 1
- **Previous Chunk ID:** 41f273d6b42f
- **Next Chunk ID:** 6ad64ffdaa14

---

```

# System Prompt
```

You are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:

1. **Direct Answer First:**  
   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.
   - Use the following structure:

     **1) Definition**  
     - Provide a concise definition.  
     - Cite source(s) using the format "File: [filename], Section: [header]".

     **2) Possible Values**  
     - Describe valid or recognized values (including defaults if specified).  
     - Cite source(s).

     **3) Implications**  
     - Explain usage considerations or consequences for each value.  
     - If the documentation does not provide this information, state: "Information not available in the provided content. "

     **4) Practical Usage Notes**  
     - Include usage notes or examples only if explicitly provided in the documentation.  
     - Otherwise, state: "No usage notes found in the provided content."

     **5) Keywords**  
     - List any associated keywords as found in the documentation.  
     - If none are provided, state: "No keywords found in the provided content"

     **6) Follow-up References**  
     - Point out additional references or relevant sections from the documentation, if applicable.

2. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.
   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.
   - Each question should reference specific sections from the documentation if available.

3. **Important Instructions:**  
   - **Do not mention internal processes, "chunks," or retrieval steps.**  
   - **Do not include any self-commentary or extra explanations beyond the structure above.**  
   - Use only the documentation provided in `{context}`.

Answer strictly following the structure and rules above.

```

# Full User Message
```

Question: How does PEST perform model calibration?

Please provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:

1. **Cite Sources:**  
   - Use the format "File: [filename], Section: [header]" whenever you reference specific details.

2. **Include Examples:**  
   - Provide relevant examples from the documentation if available.

3. **Note Limitations:**  
   - If the documentation is incomplete or ambiguous, explicitly state: "Information not available in the provided content. I don't know."

4. **Follow-up Questions:**  
   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.
   - **Do not provide answers to these follow-up questions.**
   - Each question should reference specific sections from the documentation if applicable.

5. **Keywords Section:**  
   - Include a "Keywords" section if applicable, listing any associated keywords as found in the documentation.
   - If none are provided, state: "No keywords found in the provided content. I don't know."

6. **Avoid Internal Details:**  
   - Do not mention internal processes, such as "chunks" or retrieval steps.
   - Do not include any self-commentary or extra explanations beyond what is requested.

7. **Be Concise and Accurate:**  
   - Do not invent details or assumptions. If information is missing, state: "Information not available in the provided content. I don't know."

**Available Documentation with Metadata:**
# Search Results for: How does PEST perform model calibration?

Keywords: None


## Context

### Summary
**Parallel PEST's efficiency decreases with short model run times due to file I/O and message passing latency. BEOPEST, using TCP/IP, minimizes these overheads because agents perform file I/O locally.**

### Header
**11.1.4 Communication Overheads**

### Content
If model run times are short, gains in computational efficiency that are achievable using Parallel PEST will not be as great as when model times are large, for the time taken in writing and reading (possibly lengthy) model input and output files across a local area network may then become large in comparison with model run times. Another contributor to parallelisation latency is the use of message files for communication between manager and agents. It may take a number of seconds before a message issued by one is received by the other.
Because it uses TCP/IP for messaging, and because the BEOPEST agent writes model input files and reads model output files locally, manager/agent communication overheads are very low for BEOPEST.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 11. Parallel PEST and BEOPEST (continuación)
- **Subsection:** 11.1 General (continuación)

### Additional Summaries
- **Higher-Level Summary:** Parallel PEST and BEOPEST parallelize model runs to reduce run time. Parallel PEST needs a run management file, while BEOPEST's is optional. Both distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Parallel PEST uses PAGENT agents, requires separate folders for agents, and shared signal files for communication. BEOPEST offers ease of use, faster communication, flexibility, and support for multiple command lines and surrogate models.
- **Detailed Summary:** Parallel PEST and BEOPEST parallelize model runs, reducing PEST run time. Parallel PEST requires a run management file, while BEOPEST's is optional. They distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Both store data in binary files for reduced memory needs.

### Related Context
- **Previous Summary:** Parallel PEST/BEOPEST partially parallelizes Marquardt lambda testing by running models with multiple lambdas (related by RLAMFAC) simultaneously.  Some runs may be wasted, but idle processors are avoided.  Parallel lambda testing may be disabled in "predictive analysis" mode (line search) or if parameters hit bounds.
- **Next Summary:** Parallel PEST (ppest.exe, i64ppest.exe) and BEOPEST (beopest32.exe, beopest64.exe) are automatically installed.  PAGENT.exe is required for Parallel PEST on each agent machine; BEOPEST uses its own executable as the agent.  Model programs and files must also be copied to agent machines before running Parallel PEST or BEOPEST.

### Metadata
- **Keywords:** 
- **Chunk ID:** cb0f0bfcff07
- **Chunk Index:** 1
- **Previous Chunk ID:** df6c96c24b07
- **Next Chunk ID:** 3de0f3c0071a

---

## Context

### Summary
**Verify the DSI2-generated PEST control file (case.pst) using PESTCHEK (it will not approve case_sd.pst if created). Run PESTPP-IES using `pestpp-ies case` or `pestpp-ies case_sd` (depending on whether standard deviations are provided). Monitor case.phi.actual.csv;  accept results at or near the target objective function value (≈number of non-zero-weighted observations). Use case.J.obs.csv (N realizations) to create posterior prediction histograms.**

### Header
**18.3.7 Running PESTPP-IES**

### Content
Once DSI2 has written its PEST input dataset, the entire dataset can be checked using PESTCHEK. Suppose that the DSI2‑produced PEST control file is named case.pst. Then PESTCHEK can be run using the command:
pestchek case
Note, however, that if a secondary PESTPP‑IES‑only PEST control file is written, then PESTCHECK will not approve of this file, for it does not support the use of external observation data files. (However PESTPP‑IES will happily read this file.)
PESTPP‑IES can then be run using the command:
pestpp-ies case
or
pestpp-ies case_sd
depending on whether or not a user specifically provides standard deviations of measurement noise.
If measurement noise standard deviations are “correct”, or if only weights are supplied and they are equal to the inverse standard deviations of measurement noise, the objective function should be reduced to a value that is about equal to the number of non‑zero‑weighted
observations. PESTPP‑IES should be prevented from reducing the objective function below this. Monitor file case.phi.actual.csv to see the iteration number at which the desired value of the objective function is achieved. If necessary, accept results from a few iterations before the last iteration which PESTPP‑IES undertakes (or halt PESTPP‑IES execution when the objective function is lowered to the desired value).
Suppose that a suitable objective function value is achieved at iteration J. Posterior predictive histograms can be constructed using the contents of file case.J.obs.csv. This contains N realisations of all predictions, where N is the number of user‑requested PESTPP‑IES realisations.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 18. Data Space Inversion
- **Subsection:** 18.3 DSI2, DSIMOD and POSTDSIMOD

### Additional Summaries
- **Higher-Level Summary:** The text describes using soil clod shrinkage data to fit two straight lines using Equation 18.1.1 with parameters s1, s2, y1, and xc in the pestex subfolder. The TWOLINE program reads parameters and water contents from in.dat, adjusts parameters using PEST, and generates input files for calculations. The final prediction value is 0.786.
- **Detailed Summary:** DSI2 creates files for data space inversion using PESTPP-IES or PEST_HP, computing an empirical covariance matrix from a CSV file of model outputs. It uses a PEST control file's weights for observations, creating a new control file for history-matching. Posterior predictive uncertainty analysis with PEST_HP involves multiple steps, including running the model NREAL times and calibrating with regularization. Linear analysis is an alternative method.

### Related Context
- **Previous Summary:** DSIMOD (a surrogate model) calculates model outputs.  It's run using `dsimod infile parfile outfile`, where infile (binary, from DSI2) contains transformation variables, d, and C½(d); parfile lists PCA parameter values; and outfile contains the calculated outputs.  Filenames share a common base (from DSI2).
- **Next Summary:** To get posterior prediction means, add regularization to case.pst using ADDREG2 (`addreg2 case case1 target continue`), run PEST (stopping when the solution is deemed sufficient), and obtain predictions from case1.rec or case1.res. For better results, use PEST_HP (`addreg2 case case1 target continue hp`, UPTESTMIN=25), adjusting PHIMLIM until outputs are satisfactory.  Use PARREP to create case_soln.pst (NOPTMAX=0) for a final model run using `pest case_soln /hpstart`.

### Metadata
- **Keywords:** 
- **Chunk ID:** 09cd4afd25d3
- **Chunk Index:** 1
- **Previous Chunk ID:** ac464f91a7cb
- **Next Chunk ID:** 40c1a16585ed

---

## Context

### Summary
**Bounds-sticking (IBOUNDSTICK) prevents wasted model runs by fixing parameters at bounds after a specified number of iterations.  Upgrade vector bending (UPVECBEND) avoids shortening the upgrade vector when parameter change limits are reached, potentially improving performance but may degrade it.  Parameter change limits maintain inversion stability.**

### Header
**3.4.5 Optional Alternative Bounds Accommodation**

### Content
If a model takes a long time to run, then any measures that can be taken to reduce the number of runs required for estimation of its parameters makes that model more useable with PEST. Parameter “bounds-sticking” functionality is one such measure.
When one or more parameters are at their bounds, the procedure by which the parameter upgrade vector is calculated is modified to accommodate this situation. If, for one such parameter, the parameter upgrade vector is such that the parameter is directed away from its bound back into “allowed parameter space”, then that parameter is free to move as it normally would. However parameters for which the upgrade vector points outside of allowed parameter space (i.e. above or below the upper or lower bound at which the parameter currently resides) are sequentially frozen; the sequence in which these parameters are frozen is important; see Doherty (2015). On each occasion that a parameter is frozen, the parameter upgrade vector is re-calculated with currently frozen parameters omitted from the parameter upgrade calculation. At the beginning of each new iteration, all frozen parameters are freed. The whole process is then repeated during the next iteration of the inversion process.
Sometimes a parameter can move to its bound, and then back again into allowed parameter space, during the course of a single inversion process. However if a parameter is at its bound for more than a few iterations, it is more likely than not that the parameter is there to stay. However PEST will continue to calculate derivatives with respect to this parameter in order to attempt an upgrade calculation for it, even though there is a diminishing likelihood that the parameter will ever move from its bounds. Thus one model run per iteration (more if PEST is engaged in higher order finite-difference derivatives calculation) is wasted. Where more than one parameter is at its bound the number of wasted model runs rises in proportion to the number of such parameters.
Through use of the IBOUNDSTICK control variable residing in the “control data” section of the PEST control file, this wastage of model runs can be prevented. PEST can be instructed to permanently “glue” a parameter to its upper or lower bound if that parameter has been residing there for a user-specified number of iterations. Once a parameter is “glued” to its bound it will never move again, for PEST will no longer include this parameter in its upgrade vector calculations. Nor will it calculate derivatives with respect to this parameter, thus reducing the number of model runs required per iteration.
Despite the potential for model run economy that it offers, bounds-sticking functionality should be used with caution.
The UPVECBEND variable (which follows the IBOUNDSTICK variable in the “control data” section of the PEST control file) activates “upgrade parameter vector bending” functionality. Experience has demonstrated that, while this may result in a slight reduction in
the number of model runs required for completion of the parameter estimation process in some situations, it can seriously degrade PEST’s performance in other situations. Hence it should be used only with extreme caution.
As is described by Doherty (2015), and also below, the length of the parameter upgrade vector is limited during any one PEST iteration by the action of factor, relative and/or absolute parameter change limits. Imposition of limits prevents parameter changes from exceeding by too great a margin the range of the linearity assumption upon which their calculation is based. In doing so, it brings stability to the inversion process.
If PEST calculates that a particular parameter must incur a factor, relative or absolute change which is greater than that permitted by pertinent user-supplied limits, then the changes incurred by all parameters are reduced so that the change incurred by the maximally-changed parameter does not exceed its limit; that is, the length of the upgrade vector is reduced to respect this limit while its direction remains unchanged. As it is often the most insensitive parameters for which the largest change is calculated (especially if regularisation is omitted from a PEST control file), it is on behalf of these parameters that the parameter upgrade vector may thus be shortened. If this is the case, then changes incurred by the more important, sensitive, parameters can thus be curtailed by this shortening of the parameter upgrade vector. This may slow the inversion process.
The UPVECBEND variable can instruct PEST not to shorten the parameter upgrade vector in its observance of parameter change limits. Instead it will “bend” this vector so that, while individual parameters are forced to respect their change limits, other parameters can move by the amount dictated by the parameter upgrade vector. Hence changes calculated for sensitive parameters are not restricted by the change limits imposed on more insensitive parameters.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 3. What PEST Does
- **Subsection:** 3.4 Parameter Adjustment

### Additional Summaries
- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: "estimation", "predictive analysis", "regularisation", and "pareto". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.
- **Detailed Summary:** The PEST control file's "parameter data" section manages parameter adjustments, including logarithmic transformations for stability. PARTRANS specifies parameter transformations, with options for fixed, log-transformed, or tied parameters. Bounds, scaling, and offsetting are used to prevent model errors and enhance stability. Parameter changes are limited to prevent over-adjustment. Dampening methods reduce oscillations during optimization.

### Related Context
- **Previous Summary:** PARLBND and PARUBND variables in the PEST control file specify parameter upper and lower bounds.  Wise bound selection prevents model errors (e.g., negative values where logarithms are used).  Bound enforcement enhances inversion stability (see Doherty 2015, section 5.4.2.7).
- **Next Summary:** SCALE and OFFSET (in the "parameter data" section) are applied to parameter values before writing to model input files.  They are useful for parameter transformations (e.g., elevation to thickness) and handling negative parameters.  SCALE=1 and OFFSET=0 indicate no scaling or offsetting.  These are applied only when writing to model input files.

### Metadata
- **Keywords:** IBOUNDSTICK, UPVECBEND
- **Chunk ID:** ac9101194d69
- **Chunk Index:** 1
- **Previous Chunk ID:** 4531f5bdc764
- **Next Chunk ID:** 30c3fca934b4

---

## Context

### Summary
**CMAES_P prompts for CMA-ES variables: λ, μ, recombination weights, seed, and whether to read a covariance matrix. It then prompts for SVD hybridisation (number of thresholds, "soft" or "hard"), model run failure forgiveness, and termination criteria (objective function change, parameter change, objective function difference, maximum iterations).  A final prompt asks whether to run the model with initial parameters.  It can be stopped via PSTOP, PSTOPST, or <Ctrl-C>.  Parallel runs don't automatically shut down agents if stopped via PSTOP.**

### Header
**16.1.5 Running CMAES_P**

### Content
The hybridisation scheme is further explained below. At the time of writing, the default is set to “no”. However you are urged to try this scheme at some stage, especially if you suspect that derivatives of model outputs with respect to adjustable parameters are not too bad. If a response of “y” is provided to this question, CMAES_P next asks two further questions:
How many trial singular value thresholds? (&lt;Enter&gt; if 3):
Use "soft" or "hard" hybridization? [s/h] (&lt;Enter&gt; if "s"):
These are further explained below.
CMAES_P next asks:
Forgive model run failure? [y/n]: (&lt;Enter&gt; if "y"):
If a response of “n” is provided to this prompt, then a failure on the part of CMAES_P to read any part of any model output file after completion of any model run will precipitate cessation of CMAES_P execution with an appropriate error message. However if the response to the above prompt is “y”, CMAES_P will interpret an error in reading model output files as evidence of a model-indigestible parameter set. Internally, it will attribute a very high objective function to this parameter set, thus providing a disincentive to the optimisation process from generating a similar set of parameters.
CMAES_P’s next seven prompts are as follows:
Termination Criteria:
Min rel obj fn change over N itns (&lt;Enter&gt; if 1.00000E-03):
No of itns (N) over which this applies (&lt;Enter&gt; if 40):
Min rel param change over N itns (&lt;Enter&gt; if 1.00000E-03):
No of itns (N) over which this applies (&lt;Enter&gt; if 40):
Rel high-low generated obj fn diff over N itns (&lt;Enter&gt; if 1.0000E-02):
No of itns (N) over which this applies (&lt;Enter&gt; if 10):
Maximum number of iterations (&lt;Enter&gt; if 1000):
A number of CMAES_P termination criteria are similar to those employed by PEST. However the default values of variables governing those criteria are different from those commonly employed by PEST.
The first two of the above prompts pertain to the objective function. If it fails to fall by a
relative amount provided in response to the first of the above prompts over the number of iterations provided in response to the second of the above prompts, then the optimisation process will be deemed to have reached completion.
The third and fourth of the above prompts pertain to parameter changes. If no parameter undergoes a relative change given by the response to the third of the above prompts over a number of iterations provided in response to the fourth of the above prompts, then the optimisation process will be deemed to have reached completion.
The fifth and sixth of the above prompts pertain to objective functions computed during any iteration on the basis of the λ trial parameter sets generated during that iteration. If the relative difference between the highest and lowest of these objective functions is small over a number of successive iterations, this indicates that the covariance matrix used to generate parameter realisations contains small parameter variances (hopefully as an outcome of convergence to the global objective function minimum). As time progress, it becomes more and more unlikely that even a small lowering of the objective function will occur under these conditions.
The maximum number of iterations is provided in response to the seventh of the above prompts. If this is supplied as zero, then CMAES_P will undertake just one model run, this being on the basis of initial parameter values as supplied in the PEST control file. This can be useful when the PARREP utility (see part II of this manual) is employed to create a new PEST control file on the basis of values optimised from a previous CMAES_P or PEST run. A single model run can then be undertaken on the basis of these optimised parameter values.
As soon as one of its termination criteria is satisfied, CMAES_P ceases execution, informing you why it has decided to do this.
CMAES_P’s final prompt is
Run model with initial parameters? [y/n] (<Enter> if "y):
While the default response to the above prompt is “y”, you may prefer to answer “n” in circumstances where model run times are long, especially if CMAES_P undertakes model runs in parallel. In the latter case all machines but one stand idle until this first model run is completed. There is no real advantage to undertaking this run except for the fact that it then “sets the standard” with respect to which objective function outcomes of model runs performed under the control of CMAES_P can be measured. Improvements in the objective function achieved through the calibration process are thereby readily apparent.
Stopping and Restarting
Like PEST, CMAES_P can be stopped by issuing the PSTOP or PSTOPST command from another command line window, opened in the same working folder as CMAES_P. Cessation of execution is instantaneous if CMAES_P is run in parallel mode; however orphaned model runs will continue in their own windows unless halted by the user. When undertaking runs in serial, cessation of CMAES_P execution takes place upon completion of the current model run.
When operating in parallel mode, agents will not automatically shut down if CMAES_P is halted using the PSTOP command (for often a user-instigated stop is followed by a user-instigated re-commencement of the optimisation process). In contrast, if CMAES_P stops of its own accord because a convergence criterion has been met, of if execution is halted using the PSTOPST command, then agents automatically shut down.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers
- **Main Section:** 16. PEST-Compatible Global Optimisers
- **Subsection:** 16.1 CMAES_P

### Additional Summaries
- **Higher-Level Summary:** CMAES_P is a global optimizer for unstable/nonlinear models without derivatives, using PEST input files, supporting multiple observation groups, and running in serial/parallel mode. It lacks IREGADJ and sensitivity calculations but prompts for hybridization parameters. SCEUA_P is a PEST-compatible optimizer for discontinuous/noisy models, with termination criteria and parallelization via `/p` switch.
- **Detailed Summary:** CMAES_P is a global optimizer based on CMA-ES, suitable for unstable or nonlinear models without derivatives. It lacks IREGADJ and sensitivity calculations. It uses PEST input files, supports multiple observation groups, and can run in serial or parallel mode. It prompts for CMA and SVD hybridization parameters, outputs various files, and can be restarted with optimized parameters.

### Related Context
- **Previous Summary:** CMAES_P uses PEST's input dataset but prompts for CMA control variables:  λ (population size, Equation 16.1.1), μ (number of parents, Equation 16.1.2), recombination weights ("superlin", "linear", "equal"), random seed, and whether to read a parameter covariance matrix from a file.  It minimizes a weighted least-squares objective function or a single model output (if only one observation and no prior information are present).  It prompts whether to use SVD hybridisation if observations outnumber parameters.
- **Next Summary:** CMAES_P restarts via the `/r` switch; PPAUSE pauses execution until the next model run. A final model run (using optimized parameters) is performed unless stopped in parallel mode via PSTOPST; use PARREP to perform a final run manually.

### Metadata
- **Keywords:** 
- **Chunk ID:** 1460082d8080
- **Chunk Index:** 2
- **Previous Chunk ID:** 7f10120dc35b
- **Next Chunk ID:** 5b337276c98a

---

## Context

### Summary
**PARREDUCE assesses the impact of parameter reduction strategies (removing, fixing, or tying parameters) on model-data misfit. It estimates objective function increases resulting from simplification, helping optimize model complexity.  Calculations are approximate, ignoring measurement noise and pre-existing model simplification; they assume linearity.**

### Header
**14.2.1 General**

### Content
“PARREDUCE” stands for “parameter reduction”. This utility can be used to ascertain the cost, in terms of model‑to‑measurement misfit, of a reduction in the number of parameters employed by a model. Better still, it can be used to compare the effectiveness of different parameter reduction strategies, where “effectiveness” is based on the assumption that those parameter reduction strategies are better which incur simplification‑induced misfit the least.
Use of PARREDUCE assumes that parameter reduction can occur in one of three ways:
- Through removal of parameters from a PEST control file;
- Through fixing parameters within a PEST control file (which is the same as removing them); and/or
- Through tying certain parameters to other parameters, so that the parent parameters are estimated with their child parameters “riding on their backs”. (This is effectively the same as parameter amalgamation.)
Reduction in the number of parameters employed by a model has the obvious advantage that the time required for PEST to calibrate the model is thereby reduced. However savings in computational burden come at a cost; in particular, when the number of parameters employed by a model is reduced, the objective function achieved through the calibration process may increase. Generally, the extent to which this occurs will only be known after PEST has been run to calibrate the simplified model. It is possible that PEST can achieve just as good a fit with a simplified parameter set as with a complex parameter set by adjusting simplified parameter values appropriately. However if the simplified parameter set does not span the calibration solution space of the complex model, model‑to‑measurement fit will be compromised.
The PARREDUCE utility can be used not just for optimisation of model simplification; it can also be used to examine how best to add parameters to a model. A modeller may commence the complexifying processing by adding many parameters to a model – more than he/she
ultimately wishes to add. He/she can then test different ways of amalgamating the supplementary parameters in ways that reflect expert knowledge of, for example, underlying geological variability, before deciding on an ultimate parameter complexification strategy that achieves most reduction in the objective function with the least number of additional parameters. Parameter simplification thus takes place as the second step of an overall parameter complexification process.
PARREDUCE provides information on the relative cost of different simplification strategies. It does this by providing an indication of the expected increase in the objective function incurred by use of fewer model parameters. It must be pointed out however, that the numbers which it calculates are indicative only. No account is taken of the contribution made by measurement noise to the objective function. Nor is account taken of simplification that has already been undertaken in building the original, pre‑simplified model. Furthermore calculations undertaken by PARREDUCE rely on a linearity assumption. Sensitivities on which linear analysis is based are calculated using the parameter set currently employed by the model.

### Source
- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software
- **Main Section:** 14. Miscellaneous Utilities
- **Subsection:** 14.2 PARREDUCE

### Additional Summaries
- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.
- **Detailed Summary:** Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.

### Related Context
- **Previous Summary:** This chapter describes miscellaneous PEST utilities: PARREDUCE (parameter reduction), CALMAINTAIN (maintains calibration after parameter changes), PESTLIN/GENLIN (creates linear surrogate models), and DERCOMB (combines model-calculated derivatives).  These utilities are used in contexts where model runtimes are high or when dealing with nonlinear models.
- **Next Summary:** PARREDUCE assesses parameter simplification's impact on model-data misfit using a complex and simplified model (Equation 14.2.4: r=Zk-Xp). It calculates uncalibrated (Equation 14.2.5: C<sub>u</sub>(r)=ZC(k)Z<sup>T</sup>) and calibrated (Equation 14.2.9: C<sub>z</sub>(r)=U₂S₂²U₂<sup>T</sup>, assuming C(k)=I, Equation 14.2.11) residual covariance matrices (using SVD of Z).  It uses two PEST control files (complex and simplified) and assumes zero measurement noise and a perfect model.

### Metadata
- **Keywords:** 
- **Chunk ID:** 696930d301b8
- **Chunk Index:** 1
- **Previous Chunk ID:** 41f273d6b42f
- **Next Chunk ID:** 6ad64ffdaa14

---


Answer strictly following the above instructions.

```

# Complete Messages Array
```json
[
  {
    "role": "system",
    "content": "\nYou are a **PEST Documentation Expert**. Your task is to answer questions about PEST documentation using only the provided documentation (in `{context}`). Follow these rules strictly:\n\n1. **Direct Answer First:**  \n   - Provide a concise and direct answer in Markdown format. Use clear line breaks to separate sections.\n   - Use the following structure:\n\n     **1) Definition**  \n     - Provide a concise definition.  \n     - Cite source(s) using the format \"File: [filename], Section: [header]\".\n\n     **2) Possible Values**  \n     - Describe valid or recognized values (including defaults if specified).  \n     - Cite source(s).\n\n     **3) Implications**  \n     - Explain usage considerations or consequences for each value.  \n     - If the documentation does not provide this information, state: \"Information not available in the provided content. \"\n\n     **4) Practical Usage Notes**  \n     - Include usage notes or examples only if explicitly provided in the documentation.  \n     - Otherwise, state: \"No usage notes found in the provided content.\"\n\n     **5) Keywords**  \n     - List any associated keywords as found in the documentation.  \n     - If none are provided, state: \"No keywords found in the provided content\"\n\n     **6) Follow-up References**  \n     - Point out additional references or relevant sections from the documentation, if applicable.\n\n2. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) that help the user explore the parameter further.\n   - **Do not provide any answers, commentary, or additional text** with these follow-up questions; simply list the questions.\n   - Each question should reference specific sections from the documentation if available.\n\n3. **Important Instructions:**  \n   - **Do not mention internal processes, \"chunks,\" or retrieval steps.**  \n   - **Do not include any self-commentary or extra explanations beyond the structure above.**  \n   - Use only the documentation provided in `{context}`.\n\nAnswer strictly following the structure and rules above.\n"
  },
  {
    "role": "user",
    "content": "\nQuestion: How does PEST perform model calibration?\n\nPlease provide a clear and concise answer using only the information from the documentation below. Follow these rules strictly:\n\n1. **Cite Sources:**  \n   - Use the format \"File: [filename], Section: [header]\" whenever you reference specific details.\n\n2. **Include Examples:**  \n   - Provide relevant examples from the documentation if available.\n\n3. **Note Limitations:**  \n   - If the documentation is incomplete or ambiguous, explicitly state: \"Information not available in the provided content. I don't know.\"\n\n4. **Follow-up Questions:**  \n   - After your main answer, list **exactly 5 follow-up questions** (numbered 1 to 5) for further exploration.\n   - **Do not provide answers to these follow-up questions.**\n   - Each question should reference specific sections from the documentation if applicable.\n\n5. **Keywords Section:**  \n   - Include a \"Keywords\" section if applicable, listing any associated keywords as found in the documentation.\n   - If none are provided, state: \"No keywords found in the provided content. I don't know.\"\n\n6. **Avoid Internal Details:**  \n   - Do not mention internal processes, such as \"chunks\" or retrieval steps.\n   - Do not include any self-commentary or extra explanations beyond what is requested.\n\n7. **Be Concise and Accurate:**  \n   - Do not invent details or assumptions. If information is missing, state: \"Information not available in the provided content. I don't know.\"\n\n**Available Documentation with Metadata:**\n# Search Results for: How does PEST perform model calibration?\n\nKeywords: None\n\n\n## Context\n\n### Summary\n**Parallel PEST's efficiency decreases with short model run times due to file I/O and message passing latency. BEOPEST, using TCP/IP, minimizes these overheads because agents perform file I/O locally.**\n\n### Header\n**11.1.4 Communication Overheads**\n\n### Content\nIf model run times are short, gains in computational efficiency that are achievable using Parallel PEST will not be as great as when model times are large, for the time taken in writing and reading (possibly lengthy) model input and output files across a local area network may then become large in comparison with model run times. Another contributor to parallelisation latency is the use of message files for communication between manager and agents. It may take a number of seconds before a message issued by one is received by the other.\nBecause it uses TCP/IP for messaging, and because the BEOPEST agent writes model input files and reads model output files locally, manager/agent communication overheads are very low for BEOPEST.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 11. Parallel PEST and BEOPEST (continuación)\n- **Subsection:** 11.1 General (continuación)\n\n### Additional Summaries\n- **Higher-Level Summary:** Parallel PEST and BEOPEST parallelize model runs to reduce run time. Parallel PEST needs a run management file, while BEOPEST's is optional. Both distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Parallel PEST uses PAGENT agents, requires separate folders for agents, and shared signal files for communication. BEOPEST offers ease of use, faster communication, flexibility, and support for multiple command lines and surrogate models.\n- **Detailed Summary:** Parallel PEST and BEOPEST parallelize model runs, reducing PEST run time. Parallel PEST requires a run management file, while BEOPEST's is optional. They distribute runs to available machines, with BEOPEST using faster TCP/IP communication. Both store data in binary files for reduced memory needs.\n\n### Related Context\n- **Previous Summary:** Parallel PEST/BEOPEST partially parallelizes Marquardt lambda testing by running models with multiple lambdas (related by RLAMFAC) simultaneously.  Some runs may be wasted, but idle processors are avoided.  Parallel lambda testing may be disabled in \"predictive analysis\" mode (line search) or if parameters hit bounds.\n- **Next Summary:** Parallel PEST (ppest.exe, i64ppest.exe) and BEOPEST (beopest32.exe, beopest64.exe) are automatically installed.  PAGENT.exe is required for Parallel PEST on each agent machine; BEOPEST uses its own executable as the agent.  Model programs and files must also be copied to agent machines before running Parallel PEST or BEOPEST.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** cb0f0bfcff07\n- **Chunk Index:** 1\n- **Previous Chunk ID:** df6c96c24b07\n- **Next Chunk ID:** 3de0f3c0071a\n\n---\n\n## Context\n\n### Summary\n**Verify the DSI2-generated PEST control file (case.pst) using PESTCHEK (it will not approve case_sd.pst if created). Run PESTPP-IES using `pestpp-ies case` or `pestpp-ies case_sd` (depending on whether standard deviations are provided). Monitor case.phi.actual.csv;  accept results at or near the target objective function value (≈number of non-zero-weighted observations). Use case.J.obs.csv (N realizations) to create posterior prediction histograms.**\n\n### Header\n**18.3.7 Running PESTPP-IES**\n\n### Content\nOnce DSI2 has written its PEST input dataset, the entire dataset can be checked using PESTCHEK. Suppose that the DSI2‑produced PEST control file is named case.pst. Then PESTCHEK can be run using the command:\npestchek case\nNote, however, that if a secondary PESTPP‑IES‑only PEST control file is written, then PESTCHECK will not approve of this file, for it does not support the use of external observation data files. (However PESTPP‑IES will happily read this file.)\nPESTPP‑IES can then be run using the command:\npestpp-ies case\nor\npestpp-ies case_sd\ndepending on whether or not a user specifically provides standard deviations of measurement noise.\nIf measurement noise standard deviations are “correct”, or if only weights are supplied and they are equal to the inverse standard deviations of measurement noise, the objective function should be reduced to a value that is about equal to the number of non‑zero‑weighted\nobservations. PESTPP‑IES should be prevented from reducing the objective function below this. Monitor file case.phi.actual.csv to see the iteration number at which the desired value of the objective function is achieved. If necessary, accept results from a few iterations before the last iteration which PESTPP‑IES undertakes (or halt PESTPP‑IES execution when the objective function is lowered to the desired value).\nSuppose that a suitable objective function value is achieved at iteration J. Posterior predictive histograms can be constructed using the contents of file case.J.obs.csv. This contains N realisations of all predictions, where N is the number of user‑requested PESTPP‑IES realisations.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software\n- **Main Section:** 18. Data Space Inversion\n- **Subsection:** 18.3 DSI2, DSIMOD and POSTDSIMOD\n\n### Additional Summaries\n- **Higher-Level Summary:** The text describes using soil clod shrinkage data to fit two straight lines using Equation 18.1.1 with parameters s1, s2, y1, and xc in the pestex subfolder. The TWOLINE program reads parameters and water contents from in.dat, adjusts parameters using PEST, and generates input files for calculations. The final prediction value is 0.786.\n- **Detailed Summary:** DSI2 creates files for data space inversion using PESTPP-IES or PEST_HP, computing an empirical covariance matrix from a CSV file of model outputs. It uses a PEST control file's weights for observations, creating a new control file for history-matching. Posterior predictive uncertainty analysis with PEST_HP involves multiple steps, including running the model NREAL times and calibrating with regularization. Linear analysis is an alternative method.\n\n### Related Context\n- **Previous Summary:** DSIMOD (a surrogate model) calculates model outputs.  It's run using `dsimod infile parfile outfile`, where infile (binary, from DSI2) contains transformation variables, d, and C½(d); parfile lists PCA parameter values; and outfile contains the calculated outputs.  Filenames share a common base (from DSI2).\n- **Next Summary:** To get posterior prediction means, add regularization to case.pst using ADDREG2 (`addreg2 case case1 target continue`), run PEST (stopping when the solution is deemed sufficient), and obtain predictions from case1.rec or case1.res. For better results, use PEST_HP (`addreg2 case case1 target continue hp`, UPTESTMIN=25), adjusting PHIMLIM until outputs are satisfactory.  Use PARREP to create case_soln.pst (NOPTMAX=0) for a final model run using `pest case_soln /hpstart`.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 09cd4afd25d3\n- **Chunk Index:** 1\n- **Previous Chunk ID:** ac464f91a7cb\n- **Next Chunk ID:** 40c1a16585ed\n\n---\n\n## Context\n\n### Summary\n**Bounds-sticking (IBOUNDSTICK) prevents wasted model runs by fixing parameters at bounds after a specified number of iterations.  Upgrade vector bending (UPVECBEND) avoids shortening the upgrade vector when parameter change limits are reached, potentially improving performance but may degrade it.  Parameter change limits maintain inversion stability.**\n\n### Header\n**3.4.5 Optional Alternative Bounds Accommodation**\n\n### Content\nIf a model takes a long time to run, then any measures that can be taken to reduce the number of runs required for estimation of its parameters makes that model more useable with PEST. Parameter “bounds-sticking” functionality is one such measure.\nWhen one or more parameters are at their bounds, the procedure by which the parameter upgrade vector is calculated is modified to accommodate this situation. If, for one such parameter, the parameter upgrade vector is such that the parameter is directed away from its bound back into “allowed parameter space”, then that parameter is free to move as it normally would. However parameters for which the upgrade vector points outside of allowed parameter space (i.e. above or below the upper or lower bound at which the parameter currently resides) are sequentially frozen; the sequence in which these parameters are frozen is important; see Doherty (2015). On each occasion that a parameter is frozen, the parameter upgrade vector is re-calculated with currently frozen parameters omitted from the parameter upgrade calculation. At the beginning of each new iteration, all frozen parameters are freed. The whole process is then repeated during the next iteration of the inversion process.\nSometimes a parameter can move to its bound, and then back again into allowed parameter space, during the course of a single inversion process. However if a parameter is at its bound for more than a few iterations, it is more likely than not that the parameter is there to stay. However PEST will continue to calculate derivatives with respect to this parameter in order to attempt an upgrade calculation for it, even though there is a diminishing likelihood that the parameter will ever move from its bounds. Thus one model run per iteration (more if PEST is engaged in higher order finite-difference derivatives calculation) is wasted. Where more than one parameter is at its bound the number of wasted model runs rises in proportion to the number of such parameters.\nThrough use of the IBOUNDSTICK control variable residing in the “control data” section of the PEST control file, this wastage of model runs can be prevented. PEST can be instructed to permanently “glue” a parameter to its upper or lower bound if that parameter has been residing there for a user-specified number of iterations. Once a parameter is “glued” to its bound it will never move again, for PEST will no longer include this parameter in its upgrade vector calculations. Nor will it calculate derivatives with respect to this parameter, thus reducing the number of model runs required per iteration.\nDespite the potential for model run economy that it offers, bounds-sticking functionality should be used with caution.\nThe UPVECBEND variable (which follows the IBOUNDSTICK variable in the “control data” section of the PEST control file) activates “upgrade parameter vector bending” functionality. Experience has demonstrated that, while this may result in a slight reduction in\nthe number of model runs required for completion of the parameter estimation process in some situations, it can seriously degrade PEST’s performance in other situations. Hence it should be used only with extreme caution.\nAs is described by Doherty (2015), and also below, the length of the parameter upgrade vector is limited during any one PEST iteration by the action of factor, relative and/or absolute parameter change limits. Imposition of limits prevents parameter changes from exceeding by too great a margin the range of the linearity assumption upon which their calculation is based. In doing so, it brings stability to the inversion process.\nIf PEST calculates that a particular parameter must incur a factor, relative or absolute change which is greater than that permitted by pertinent user-supplied limits, then the changes incurred by all parameters are reduced so that the change incurred by the maximally-changed parameter does not exceed its limit; that is, the length of the upgrade vector is reduced to respect this limit while its direction remains unchanged. As it is often the most insensitive parameters for which the largest change is calculated (especially if regularisation is omitted from a PEST control file), it is on behalf of these parameters that the parameter upgrade vector may thus be shortened. If this is the case, then changes incurred by the more important, sensitive, parameters can thus be curtailed by this shortening of the parameter upgrade vector. This may slow the inversion process.\nThe UPVECBEND variable can instruct PEST not to shorten the parameter upgrade vector in its observance of parameter change limits. Instead it will “bend” this vector so that, while individual parameters are forced to respect their change limits, other parameters can move by the amount dictated by the parameter upgrade vector. Hence changes calculated for sensitive parameters are not restricted by the change limits imposed on more insensitive parameters.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 3. What PEST Does\n- **Subsection:** 3.4 Parameter Adjustment\n\n### Additional Summaries\n- **Higher-Level Summary:** This chapter introduces PEST, a tool for solving inverse problems in four modes: \"estimation\", \"predictive analysis\", \"regularisation\", and \"pareto\". It uses control files with specific sections and options for parameter adjustments, transformations, and derivative calculations. PEST generates Jacobian matrices and offers utilities for file manipulation and sensitivity analysis.\n- **Detailed Summary:** The PEST control file's \"parameter data\" section manages parameter adjustments, including logarithmic transformations for stability. PARTRANS specifies parameter transformations, with options for fixed, log-transformed, or tied parameters. Bounds, scaling, and offsetting are used to prevent model errors and enhance stability. Parameter changes are limited to prevent over-adjustment. Dampening methods reduce oscillations during optimization.\n\n### Related Context\n- **Previous Summary:** PARLBND and PARUBND variables in the PEST control file specify parameter upper and lower bounds.  Wise bound selection prevents model errors (e.g., negative values where logarithms are used).  Bound enforcement enhances inversion stability (see Doherty 2015, section 5.4.2.7).\n- **Next Summary:** SCALE and OFFSET (in the \"parameter data\" section) are applied to parameter values before writing to model input files.  They are useful for parameter transformations (e.g., elevation to thickness) and handling negative parameters.  SCALE=1 and OFFSET=0 indicate no scaling or offsetting.  These are applied only when writing to model input files.\n\n### Metadata\n- **Keywords:** IBOUNDSTICK, UPVECBEND\n- **Chunk ID:** ac9101194d69\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 4531f5bdc764\n- **Next Chunk ID:** 30c3fca934b4\n\n---\n\n## Context\n\n### Summary\n**CMAES_P prompts for CMA-ES variables: λ, μ, recombination weights, seed, and whether to read a covariance matrix. It then prompts for SVD hybridisation (number of thresholds, \"soft\" or \"hard\"), model run failure forgiveness, and termination criteria (objective function change, parameter change, objective function difference, maximum iterations).  A final prompt asks whether to run the model with initial parameters.  It can be stopped via PSTOP, PSTOPST, or <Ctrl-C>.  Parallel runs don't automatically shut down agents if stopped via PSTOP.**\n\n### Header\n**16.1.5 Running CMAES_P**\n\n### Content\nThe hybridisation scheme is further explained below. At the time of writing, the default is set to “no”. However you are urged to try this scheme at some stage, especially if you suspect that derivatives of model outputs with respect to adjustable parameters are not too bad. If a response of “y” is provided to this question, CMAES_P next asks two further questions:\nHow many trial singular value thresholds? (&lt;Enter&gt; if 3):\nUse \"soft\" or \"hard\" hybridization? [s/h] (&lt;Enter&gt; if \"s\"):\nThese are further explained below.\nCMAES_P next asks:\nForgive model run failure? [y/n]: (&lt;Enter&gt; if \"y\"):\nIf a response of “n” is provided to this prompt, then a failure on the part of CMAES_P to read any part of any model output file after completion of any model run will precipitate cessation of CMAES_P execution with an appropriate error message. However if the response to the above prompt is “y”, CMAES_P will interpret an error in reading model output files as evidence of a model-indigestible parameter set. Internally, it will attribute a very high objective function to this parameter set, thus providing a disincentive to the optimisation process from generating a similar set of parameters.\nCMAES_P’s next seven prompts are as follows:\nTermination Criteria:\nMin rel obj fn change over N itns (&lt;Enter&gt; if 1.00000E-03):\nNo of itns (N) over which this applies (&lt;Enter&gt; if 40):\nMin rel param change over N itns (&lt;Enter&gt; if 1.00000E-03):\nNo of itns (N) over which this applies (&lt;Enter&gt; if 40):\nRel high-low generated obj fn diff over N itns (&lt;Enter&gt; if 1.0000E-02):\nNo of itns (N) over which this applies (&lt;Enter&gt; if 10):\nMaximum number of iterations (&lt;Enter&gt; if 1000):\nA number of CMAES_P termination criteria are similar to those employed by PEST. However the default values of variables governing those criteria are different from those commonly employed by PEST.\nThe first two of the above prompts pertain to the objective function. If it fails to fall by a\nrelative amount provided in response to the first of the above prompts over the number of iterations provided in response to the second of the above prompts, then the optimisation process will be deemed to have reached completion.\nThe third and fourth of the above prompts pertain to parameter changes. If no parameter undergoes a relative change given by the response to the third of the above prompts over a number of iterations provided in response to the fourth of the above prompts, then the optimisation process will be deemed to have reached completion.\nThe fifth and sixth of the above prompts pertain to objective functions computed during any iteration on the basis of the λ trial parameter sets generated during that iteration. If the relative difference between the highest and lowest of these objective functions is small over a number of successive iterations, this indicates that the covariance matrix used to generate parameter realisations contains small parameter variances (hopefully as an outcome of convergence to the global objective function minimum). As time progress, it becomes more and more unlikely that even a small lowering of the objective function will occur under these conditions.\nThe maximum number of iterations is provided in response to the seventh of the above prompts. If this is supplied as zero, then CMAES_P will undertake just one model run, this being on the basis of initial parameter values as supplied in the PEST control file. This can be useful when the PARREP utility (see part II of this manual) is employed to create a new PEST control file on the basis of values optimised from a previous CMAES_P or PEST run. A single model run can then be undertaken on the basis of these optimised parameter values.\nAs soon as one of its termination criteria is satisfied, CMAES_P ceases execution, informing you why it has decided to do this.\nCMAES_P’s final prompt is\nRun model with initial parameters? [y/n] (<Enter> if \"y):\nWhile the default response to the above prompt is “y”, you may prefer to answer “n” in circumstances where model run times are long, especially if CMAES_P undertakes model runs in parallel. In the latter case all machines but one stand idle until this first model run is completed. There is no real advantage to undertaking this run except for the fact that it then “sets the standard” with respect to which objective function outcomes of model runs performed under the control of CMAES_P can be measured. Improvements in the objective function achieved through the calibration process are thereby readily apparent.\nStopping and Restarting\nLike PEST, CMAES_P can be stopped by issuing the PSTOP or PSTOPST command from another command line window, opened in the same working folder as CMAES_P. Cessation of execution is instantaneous if CMAES_P is run in parallel mode; however orphaned model runs will continue in their own windows unless halted by the user. When undertaking runs in serial, cessation of CMAES_P execution takes place upon completion of the current model run.\nWhen operating in parallel mode, agents will not automatically shut down if CMAES_P is halted using the PSTOP command (for often a user-instigated stop is followed by a user-instigated re-commencement of the optimisation process). In contrast, if CMAES_P stops of its own accord because a convergence criterion has been met, of if execution is halted using the PSTOPST command, then agents automatically shut down.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation. User Manual Part I: PEST, SENSAN and Global Optimisers\n- **Main Section:** 16. PEST-Compatible Global Optimisers\n- **Subsection:** 16.1 CMAES_P\n\n### Additional Summaries\n- **Higher-Level Summary:** CMAES_P is a global optimizer for unstable/nonlinear models without derivatives, using PEST input files, supporting multiple observation groups, and running in serial/parallel mode. It lacks IREGADJ and sensitivity calculations but prompts for hybridization parameters. SCEUA_P is a PEST-compatible optimizer for discontinuous/noisy models, with termination criteria and parallelization via `/p` switch.\n- **Detailed Summary:** CMAES_P is a global optimizer based on CMA-ES, suitable for unstable or nonlinear models without derivatives. It lacks IREGADJ and sensitivity calculations. It uses PEST input files, supports multiple observation groups, and can run in serial or parallel mode. It prompts for CMA and SVD hybridization parameters, outputs various files, and can be restarted with optimized parameters.\n\n### Related Context\n- **Previous Summary:** CMAES_P uses PEST's input dataset but prompts for CMA control variables:  λ (population size, Equation 16.1.1), μ (number of parents, Equation 16.1.2), recombination weights (\"superlin\", \"linear\", \"equal\"), random seed, and whether to read a parameter covariance matrix from a file.  It minimizes a weighted least-squares objective function or a single model output (if only one observation and no prior information are present).  It prompts whether to use SVD hybridisation if observations outnumber parameters.\n- **Next Summary:** CMAES_P restarts via the `/r` switch; PPAUSE pauses execution until the next model run. A final model run (using optimized parameters) is performed unless stopped in parallel mode via PSTOPST; use PARREP to perform a final run manually.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 1460082d8080\n- **Chunk Index:** 2\n- **Previous Chunk ID:** 7f10120dc35b\n- **Next Chunk ID:** 5b337276c98a\n\n---\n\n## Context\n\n### Summary\n**PARREDUCE assesses the impact of parameter reduction strategies (removing, fixing, or tying parameters) on model-data misfit. It estimates objective function increases resulting from simplification, helping optimize model complexity.  Calculations are approximate, ignoring measurement noise and pre-existing model simplification; they assume linearity.**\n\n### Header\n**14.2.1 General**\n\n### Content\n“PARREDUCE” stands for “parameter reduction”. This utility can be used to ascertain the cost, in terms of model‑to‑measurement misfit, of a reduction in the number of parameters employed by a model. Better still, it can be used to compare the effectiveness of different parameter reduction strategies, where “effectiveness” is based on the assumption that those parameter reduction strategies are better which incur simplification‑induced misfit the least.\nUse of PARREDUCE assumes that parameter reduction can occur in one of three ways:\n- Through removal of parameters from a PEST control file;\n- Through fixing parameters within a PEST control file (which is the same as removing them); and/or\n- Through tying certain parameters to other parameters, so that the parent parameters are estimated with their child parameters “riding on their backs”. (This is effectively the same as parameter amalgamation.)\nReduction in the number of parameters employed by a model has the obvious advantage that the time required for PEST to calibrate the model is thereby reduced. However savings in computational burden come at a cost; in particular, when the number of parameters employed by a model is reduced, the objective function achieved through the calibration process may increase. Generally, the extent to which this occurs will only be known after PEST has been run to calibrate the simplified model. It is possible that PEST can achieve just as good a fit with a simplified parameter set as with a complex parameter set by adjusting simplified parameter values appropriately. However if the simplified parameter set does not span the calibration solution space of the complex model, model‑to‑measurement fit will be compromised.\nThe PARREDUCE utility can be used not just for optimisation of model simplification; it can also be used to examine how best to add parameters to a model. A modeller may commence the complexifying processing by adding many parameters to a model – more than he/she\nultimately wishes to add. He/she can then test different ways of amalgamating the supplementary parameters in ways that reflect expert knowledge of, for example, underlying geological variability, before deciding on an ultimate parameter complexification strategy that achieves most reduction in the objective function with the least number of additional parameters. Parameter simplification thus takes place as the second step of an overall parameter complexification process.\nPARREDUCE provides information on the relative cost of different simplification strategies. It does this by providing an indication of the expected increase in the objective function incurred by use of fewer model parameters. It must be pointed out however, that the numbers which it calculates are indicative only. No account is taken of the contribution made by measurement noise to the objective function. Nor is account taken of simplification that has already been undertaken in building the original, pre‑simplified model. Furthermore calculations undertaken by PARREDUCE rely on a linearity assumption. Sensitivities on which linear analysis is based are calculated using the parameter set currently employed by the model.\n\n### Source\n- **File Name:** PEST Model-Independent Parameter Estimation User Manual Part II: PEST Utility Support Software\n- **Main Section:** 14. Miscellaneous Utilities\n- **Subsection:** 14.2 PARREDUCE\n\n### Additional Summaries\n- **Higher-Level Summary:** Observation re-referencing simplifies derivative calculations by adjusting initial model conditions based on upgraded parameters, improving solver convergence time. It involves creating reference model outputs for accurate derivatives, with specific commands and activation steps. SVDAPREP and BEOPEST support this feature, enhancing model accuracy and efficiency.\n- **Detailed Summary:** Observation re-referencing addresses issues when using different models for parameter upgrades and derivative calculations (Equation 14.2.1).  It requires a special model run per model version at each iteration to calculate reference model outputs (ojr) for accurate derivative calculations.  Multiple model commands (section 12.3) are possible, but observation re-referencing is needed if models produce different outputs with the same parameters.\n\n### Related Context\n- **Previous Summary:** This chapter describes miscellaneous PEST utilities: PARREDUCE (parameter reduction), CALMAINTAIN (maintains calibration after parameter changes), PESTLIN/GENLIN (creates linear surrogate models), and DERCOMB (combines model-calculated derivatives).  These utilities are used in contexts where model runtimes are high or when dealing with nonlinear models.\n- **Next Summary:** PARREDUCE assesses parameter simplification's impact on model-data misfit using a complex and simplified model (Equation 14.2.4: r=Zk-Xp). It calculates uncalibrated (Equation 14.2.5: C<sub>u</sub>(r)=ZC(k)Z<sup>T</sup>) and calibrated (Equation 14.2.9: C<sub>z</sub>(r)=U₂S₂²U₂<sup>T</sup>, assuming C(k)=I, Equation 14.2.11) residual covariance matrices (using SVD of Z).  It uses two PEST control files (complex and simplified) and assumes zero measurement noise and a perfect model.\n\n### Metadata\n- **Keywords:** \n- **Chunk ID:** 696930d301b8\n- **Chunk Index:** 1\n- **Previous Chunk ID:** 41f273d6b42f\n- **Next Chunk ID:** 6ad64ffdaa14\n\n---\n\n\nAnswer strictly following the above instructions.\n"
  }
]
```